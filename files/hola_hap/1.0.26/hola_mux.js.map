{
  "version": 3,
  "sources": [
    "node_modules/browser-pack/_prelude.js",
    "node_modules/@hola.org/mux.js/lib/aac/index.js",
    "node_modules/@hola.org/mux.js/lib/codecs/adts.js",
    "node_modules/@hola.org/mux.js/lib/codecs/h264.js",
    "node_modules/@hola.org/mux.js/lib/codecs/index.js",
    "node_modules/@hola.org/mux.js/lib/flv/flv-tag.js",
    "node_modules/@hola.org/mux.js/lib/flv/index.js",
    "node_modules/@hola.org/mux.js/lib/flv/transmuxer.js",
    "node_modules/@hola.org/mux.js/lib/index.js",
    "node_modules/@hola.org/mux.js/lib/m2ts/caption-stream.js",
    "node_modules/@hola.org/mux.js/lib/m2ts/index.js",
    "node_modules/@hola.org/mux.js/lib/m2ts/m2ts.js",
    "node_modules/@hola.org/mux.js/lib/m2ts/metadata-stream.js",
    "node_modules/@hola.org/mux.js/lib/m2ts/stream-types.js",
    "node_modules/@hola.org/mux.js/lib/m2ts/timestamp-rollover-stream.js",
    "node_modules/@hola.org/mux.js/lib/mp4/index.js",
    "node_modules/@hola.org/mux.js/lib/mp4/mp4-generator.js",
    "node_modules/@hola.org/mux.js/lib/mp4/mp4-parser.js",
    "node_modules/@hola.org/mux.js/lib/mp4/transmuxer.js",
    "node_modules/@hola.org/mux.js/lib/tools/flv-inspector.js",
    "node_modules/@hola.org/mux.js/lib/tools/mp4-inspector.js",
    "node_modules/@hola.org/mux.js/lib/utils/exp-golomb.js",
    "node_modules/@hola.org/mux.js/lib/utils/stream.js",
    "src/hola_mux.js"
  ],
  "names": [],
  "mappings": "AAAA;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrZA;AACA;AACA;AACA;AACA;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACl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lk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bA;AACA;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzcA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9yBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1lCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACtNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC1zBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvHA;AACA",
  "file": "generated.js",
  "sourceRoot": "",
  "sourcesContent": [
    "(function e(t,n,r){function s(o,u){if(!n[o]){if(!t[o]){var a=typeof require==\"function\"&&require;if(!u&&a)return a(o,!0);if(i)return i(o,!0);var f=new Error(\"Cannot find module '\"+o+\"'\");throw f.code=\"MODULE_NOT_FOUND\",f}var l=n[o]={exports:{}};t[o][0].call(l.exports,function(e){var n=t[o][1][e];return s(n?n:e)},l,l.exports,e,t,n,r)}return n[o].exports}var i=typeof require==\"function\"&&require;for(var o=0;o<r.length;o++)s(r[o]);return s})",
    "/**\n * mux.js\n *\n * Copyright (c) 2016 Brightcove\n * All rights reserved.\n *\n * A stream-based aac to mp4 converter. This utility can be used to\n * deliver mp4s to a SourceBuffer on platforms that support native\n * Media Source Extensions.\n */\n'use strict';\nvar Stream = require('../utils/stream.js');\n\n// Constants\nvar AacStream;\n\n/**\n * Splits an incoming stream of binary data into ADTS and ID3 Frames.\n */\n\nAacStream = function() {\n  var\n    everything = new Uint8Array(),\n    timeStamp = 0;\n\n  AacStream.prototype.init.call(this);\n\n  this.setTimestamp = function(timestamp) {\n    timeStamp = timestamp;\n  };\n\n  this.parseId3TagSize = function(header, byteIndex) {\n    var\n      returnSize = (header[byteIndex + 6] << 21) |\n                   (header[byteIndex + 7] << 14) |\n                   (header[byteIndex + 8] << 7) |\n                   (header[byteIndex + 9]),\n      flags = header[byteIndex + 5],\n      footerPresent = (flags & 16) >> 4;\n\n    if (footerPresent) {\n      return returnSize + 20;\n    }\n    return returnSize + 10;\n  };\n\n  this.parseAdtsSize = function(header, byteIndex) {\n    var\n      lowThree = (header[byteIndex + 5] & 0xE0) >> 5,\n      middle = header[byteIndex + 4] << 3,\n      highTwo = header[byteIndex + 3] & 0x3 << 11;\n\n    return (highTwo | middle) | lowThree;\n  };\n\n  this.push = function(bytes) {\n    var\n      frameSize = 0,\n      byteIndex = 0,\n      bytesLeft,\n      chunk,\n      packet,\n      tempLength;\n\n    // If there are bytes remaining from the last segment, prepend them to the\n    // bytes that were pushed in\n    if (everything.length) {\n      tempLength = everything.length;\n      everything = new Uint8Array(bytes.byteLength + tempLength);\n      everything.set(everything.subarray(0, tempLength));\n      everything.set(bytes, tempLength);\n    } else {\n      everything = bytes;\n    }\n\n    while (everything.length - byteIndex >= 3) {\n      if ((everything[byteIndex] === 'I'.charCodeAt(0)) &&\n          (everything[byteIndex + 1] === 'D'.charCodeAt(0)) &&\n          (everything[byteIndex + 2] === '3'.charCodeAt(0))) {\n\n        // Exit early because we don't have enough to parse\n        // the ID3 tag header\n        if (everything.length - byteIndex < 10) {\n          break;\n        }\n\n        // check framesize\n        frameSize = this.parseId3TagSize(everything, byteIndex);\n\n        // Exit early if we don't have enough in the buffer\n        // to emit a full packet\n        if (frameSize > everything.length) {\n          break;\n        }\n        chunk = {\n          type: 'timed-metadata',\n          data: everything.subarray(byteIndex, byteIndex + frameSize)\n        };\n        this.trigger('data', chunk);\n        byteIndex += frameSize;\n        continue;\n      } else if ((everything[byteIndex] & 0xff === 0xff) &&\n                 ((everything[byteIndex + 1] & 0xf0) === 0xf0)) {\n\n        // Exit early because we don't have enough to parse\n        // the ADTS frame header\n        if (everything.length - byteIndex < 7) {\n          break;\n        }\n\n        frameSize = this.parseAdtsSize(everything, byteIndex);\n\n        // Exit early if we don't have enough in the buffer\n        // to emit a full packet\n        if (frameSize > everything.length) {\n          break;\n        }\n\n        packet = {\n          type: 'audio',\n          data: everything.subarray(byteIndex, byteIndex + frameSize),\n          pts: timeStamp,\n          dts: timeStamp\n        };\n        this.trigger('data', packet);\n        byteIndex += frameSize;\n        continue;\n      }\n      byteIndex++;\n    }\n    bytesLeft = everything.length - byteIndex;\n\n    if (bytesLeft > 0) {\n      everything = everything.subarray(byteIndex);\n    } else {\n      everything = new Uint8Array();\n    }\n  };\n};\n\nAacStream.prototype = new Stream();\n\nmodule.exports = AacStream;\n",
    "'use strict';\n\nvar Stream = require('../utils/stream.js');\n\nvar AdtsStream;\n\nvar\n  ADTS_SAMPLING_FREQUENCIES = [\n    96000,\n    88200,\n    64000,\n    48000,\n    44100,\n    32000,\n    24000,\n    22050,\n    16000,\n    12000,\n    11025,\n    8000,\n    7350\n  ];\n\n/*\n * Accepts a ElementaryStream and emits data events with parsed\n * AAC Audio Frames of the individual packets. Input audio in ADTS\n * format is unpacked and re-emitted as AAC frames.\n *\n * @see http://wiki.multimedia.cx/index.php?title=ADTS\n * @see http://wiki.multimedia.cx/?title=Understanding_AAC\n */\nAdtsStream = function() {\n  var buffer;\n\n  AdtsStream.prototype.init.call(this);\n\n  this.push = function(packet) {\n    var\n      i = 0,\n      frameNum = 0,\n      frameLength,\n      protectionSkipBytes,\n      frameEnd,\n      oldBuffer,\n      sampleCount,\n      adtsFrameDuration;\n\n    if (packet.type !== 'audio') {\n      // ignore non-audio data\n      return;\n    }\n\n    // Prepend any data in the buffer to the input data so that we can parse\n    // aac frames the cross a PES packet boundary\n    if (buffer) {\n      oldBuffer = buffer;\n      buffer = new Uint8Array(oldBuffer.byteLength + packet.data.byteLength);\n      buffer.set(oldBuffer);\n      buffer.set(packet.data, oldBuffer.byteLength);\n    } else {\n      buffer = packet.data;\n    }\n\n    // unpack any ADTS frames which have been fully received\n    // for details on the ADTS header, see http://wiki.multimedia.cx/index.php?title=ADTS\n    while (i + 5 < buffer.length) {\n\n      // Loook for the start of an ADTS header..\n      if (buffer[i] !== 0xFF || (buffer[i + 1] & 0xF6) !== 0xF0) {\n        // If a valid header was not found,  jump one forward and attempt to\n        // find a valid ADTS header starting at the next byte\n        i++;\n        continue;\n      }\n\n      // The protection skip bit tells us if we have 2 bytes of CRC data at the\n      // end of the ADTS header\n      protectionSkipBytes = (~buffer[i + 1] & 0x01) * 2;\n\n      // Frame length is a 13 bit integer starting 16 bits from the\n      // end of the sync sequence\n      frameLength = ((buffer[i + 3] & 0x03) << 11) |\n        (buffer[i + 4] << 3) |\n        ((buffer[i + 5] & 0xe0) >> 5);\n\n      sampleCount = ((buffer[i + 6] & 0x03) + 1) * 1024;\n      adtsFrameDuration = (sampleCount * 90000) /\n        ADTS_SAMPLING_FREQUENCIES[(buffer[i + 2] & 0x3c) >>> 2];\n\n      frameEnd = i + frameLength;\n\n      // If we don't have enough data to actually finish this ADTS frame, return\n      // and wait for more data\n      if (buffer.byteLength < frameEnd) {\n        return;\n      }\n\n      // Otherwise, deliver the complete AAC frame\n      this.trigger('data', {\n        pts: packet.pts + (frameNum * adtsFrameDuration),\n        dts: packet.dts + (frameNum * adtsFrameDuration),\n        sampleCount: sampleCount,\n        audioobjecttype: ((buffer[i + 2] >>> 6) & 0x03) + 1,\n        channelcount: ((buffer[i + 2] & 1) << 2) |\n          ((buffer[i + 3] & 0xc0) >>> 6),\n        samplerate: ADTS_SAMPLING_FREQUENCIES[(buffer[i + 2] & 0x3c) >>> 2],\n        samplingfrequencyindex: (buffer[i + 2] & 0x3c) >>> 2,\n        // assume ISO/IEC 14496-12 AudioSampleEntry default of 16\n        samplesize: 16,\n        data: buffer.subarray(i + 7 + protectionSkipBytes, frameEnd)\n      });\n\n      // If the buffer is empty, clear it and return\n      if (buffer.byteLength === frameEnd) {\n        buffer = undefined;\n        return;\n      }\n\n      frameNum++;\n\n      // Remove the finished frame from the buffer and start the process again\n      buffer = buffer.subarray(frameEnd);\n    }\n  };\n  this.flush = function() {\n    this.trigger('done');\n  };\n};\n\nAdtsStream.prototype = new Stream();\n\nmodule.exports = AdtsStream;\n",
    "'use strict';\n\nvar Stream = require('../utils/stream.js');\nvar ExpGolomb = require('../utils/exp-golomb.js');\n\nvar H264Stream, NalByteStream;\n// values of profile_idc that indicate additional fields are included in the SPS\n// see Recommendation ITU-T H.264 (4/2013),\n// 7.3.2.1.1 Sequence parameter set data syntax\nvar PROFILES_WITH_OPTIONAL_SPS_DATA = {\n  100: true,\n  110: true,\n  122: true,\n  244: true,\n  44: true,\n  83: true,\n  86: true,\n  118: true,\n  128: true,\n  138: true,\n  139: true,\n  134: true\n};\nvar unitTypes = {\n    slice_layer_without_partitioning_rbsp: 1,\n    slice_layer_without_partitioning_rbsp_idr: 5,\n    sei_rbsp: 6,\n    seq_parameter_set_rbsp: 7,\n    pic_parameter_set_rbsp: 8,\n    access_unit_delimiter_rbsp: 9,\n};\n\n/**\n * Accepts a NAL unit byte stream and unpacks the embedded NAL units.\n */\nNalByteStream = function() {\n  var\n    syncPoint = 0,\n    i,\n    buffer;\n  NalByteStream.prototype.init.call(this);\n\n  this.push = function(data) {\n    var swapBuffer;\n\n    if (!buffer) {\n      buffer = data.data;\n    } else {\n      swapBuffer = new Uint8Array(buffer.byteLength + data.data.byteLength);\n      swapBuffer.set(buffer);\n      swapBuffer.set(data.data, buffer.byteLength);\n      buffer = swapBuffer;\n    }\n\n    // Rec. ITU-T H.264, Annex B\n    // scan for NAL unit boundaries\n\n    // a match looks like this:\n    // 0 0 1 .. NAL .. 0 0 1\n    // ^ sync point        ^ i\n    // or this:\n    // 0 0 1 .. NAL .. 0 0 0\n    // ^ sync point        ^ i\n\n    // advance the sync point to a NAL start, if necessary\n    for (; syncPoint < buffer.byteLength - 3; syncPoint++) {\n      if (buffer[syncPoint + 2] === 1) {\n        // the sync point is properly aligned\n        i = syncPoint + 5;\n        break;\n      }\n    }\n\n    while (i < buffer.byteLength) {\n      // look at the current byte to determine if we've hit the end of\n      // a NAL unit boundary\n      switch (buffer[i]) {\n      case 0:\n        // skip past non-sync sequences\n        if (buffer[i - 1] !== 0) {\n          i += 2;\n          break;\n        } else if (buffer[i - 2] !== 0) {\n          i++;\n          break;\n        }\n\n        // deliver the NAL unit if it isn't empty\n        if (syncPoint + 3 !== i - 2) {\n          this.trigger('data', buffer.subarray(syncPoint + 3, i - 2));\n        }\n\n        // drop trailing zeroes\n        do {\n          i++;\n        } while (buffer[i] !== 1 && i < buffer.length);\n        syncPoint = i - 2;\n        i += 3;\n        break;\n      case 1:\n        // skip past non-sync sequences\n        if (buffer[i - 1] !== 0 ||\n            buffer[i - 2] !== 0) {\n          i += 3;\n          break;\n        }\n\n        // deliver the NAL unit\n        this.trigger('data', buffer.subarray(syncPoint + 3, i - 2));\n        syncPoint = i - 2;\n        i += 3;\n        break;\n      default:\n        // the current byte isn't a one or zero, so it cannot be part\n        // of a sync sequence\n        i += 3;\n        break;\n      }\n    }\n    // filter out the NAL units that were delivered\n    buffer = buffer.subarray(syncPoint);\n    i -= syncPoint;\n    syncPoint = 0;\n  };\n\n  this.flush = function() {\n    // deliver the last buffered NAL unit\n    if (buffer && buffer.byteLength > 3) {\n      this.trigger('data', buffer.subarray(syncPoint + 3));\n    }\n    // reset the stream state\n    buffer = null;\n    syncPoint = 0;\n    this.trigger('done');\n  };\n};\nNalByteStream.prototype = new Stream();\n\n/**\n * Accepts input from a ElementaryStream and produces H.264 NAL unit data\n * events.\n */\nH264Stream = function() {\n  var\n    nalByteStream = new NalByteStream(),\n    self,\n    trackId,\n    currentPts,\n    currentDts,\n\n    discardEmulationPreventionBytes,\n    readSequenceParameterSet,\n    skipScalingList;\n\n  H264Stream.prototype.init.call(this);\n  self = this;\n\n  this.push = function(packet) {\n    if (packet.type !== 'video') {\n      return;\n    }\n    trackId = packet.trackId;\n    currentPts = packet.pts;\n    currentDts = packet.dts;\n\n    nalByteStream.push(packet);\n  };\n\n  nalByteStream.on('data', function(data) {\n    var\n      event = {\n        trackId: trackId,\n        pts: currentPts,\n        dts: currentDts,\n        data: data\n      };\n    var ev_type = data[0] & 0x1f;\n\n    if (ev_type==1 || ev_type>=5 && ev_type<=9) {\n        event.nalUnitType = ev_type;\n    }\n    if (ev_type==7 || ev_type==6) {\n      event.escapedRBSP = discardEmulationPreventionBytes(data.subarray(1));\n      event.config = ev_type==7 ? readSequenceParameterSet(event.escapedRBSP) : null;\n    }\n    self.trigger('data', event);\n  });\n  nalByteStream.on('done', function() { self.trigger('done'); });\n  this.flush = function() { nalByteStream.flush(); };\n\n  /**\n   * Advance the ExpGolomb decoder past a scaling list. The scaling\n   * list is optionally transmitted as part of a sequence parameter\n   * set and is not relevant to transmuxing.\n   * @param count {number} the number of entries in this scaling list\n   * @param expGolombDecoder {object} an ExpGolomb pointed to the\n   * start of a scaling list\n   * @see Recommendation ITU-T H.264, Section 7.3.2.1.1.1\n   */\n  skipScalingList = function(count, expGolombDecoder) {\n    var\n      lastScale = 8,\n      nextScale = 8,\n      j,\n      deltaScale;\n\n    for (j = 0; j < count; j++) {\n      if (nextScale !== 0) {\n        deltaScale = expGolombDecoder.readExpGolomb();\n        nextScale = (lastScale + deltaScale + 256) % 256;\n      }\n\n      lastScale = (nextScale === 0) ? lastScale : nextScale;\n    }\n  };\n\n  /**\n   * Expunge any \"Emulation Prevention\" bytes from a \"Raw Byte\n   * Sequence Payload\"\n   * @param data {Uint8Array} the bytes of a RBSP from a NAL\n   * unit\n   * @return {Uint8Array} the RBSP without any Emulation\n   * Prevention Bytes\n   */\n  discardEmulationPreventionBytes = function(data) {\n    var\n      length = data.byteLength,\n      emulationPreventionBytesPositions = [],\n      i = 1,\n      newLength, newData;\n\n    // Find all `Emulation Prevention Bytes`\n    while (i < length - 2) {\n      if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {\n        emulationPreventionBytesPositions.push(i + 2);\n        i += 2;\n      } else {\n        i++;\n      }\n    }\n\n    // If no Emulation Prevention Bytes were found just return the original\n    // array\n    if (emulationPreventionBytesPositions.length === 0) {\n      return data;\n    }\n\n    // Create a new array to hold the NAL unit data\n    newLength = length - emulationPreventionBytesPositions.length;\n    newData = new Uint8Array(newLength);\n    var sourceIndex = 0;\n\n    for (i = 0; i < newLength; sourceIndex++, i++) {\n      if (sourceIndex === emulationPreventionBytesPositions[0]) {\n        // Skip this byte\n        sourceIndex++;\n        // Remove this position index\n        emulationPreventionBytesPositions.shift();\n      }\n      newData[i] = data[sourceIndex];\n    }\n\n    return newData;\n  };\n\n  /**\n   * Read a sequence parameter set and return some interesting video\n   * properties. A sequence parameter set is the H264 metadata that\n   * describes the properties of upcoming video frames.\n   * @param data {Uint8Array} the bytes of a sequence parameter set\n   * @return {object} an object with configuration parsed from the\n   * sequence parameter set, including the dimensions of the\n   * associated video frames.\n   */\n  readSequenceParameterSet = function(data) {\n    var\n      frameCropLeftOffset = 0,\n      frameCropRightOffset = 0,\n      frameCropTopOffset = 0,\n      frameCropBottomOffset = 0,\n      sarScale = 1,\n      expGolombDecoder, profileIdc, levelIdc, profileCompatibility,\n      chromaFormatIdc, picOrderCntType,\n      numRefFramesInPicOrderCntCycle, picWidthInMbsMinus1,\n      picHeightInMapUnitsMinus1,\n      frameMbsOnlyFlag,\n      scalingListCount,\n      sarRatio,\n      aspectRatioIdc,\n      i;\n\n    expGolombDecoder = new ExpGolomb(data);\n    profileIdc = expGolombDecoder.readUnsignedByte(); // profile_idc\n    profileCompatibility = expGolombDecoder.readUnsignedByte(); // constraint_set[0-5]_flag\n    levelIdc = expGolombDecoder.readUnsignedByte(); // level_idc u(8)\n    expGolombDecoder.skipUnsignedExpGolomb(); // seq_parameter_set_id\n\n    // some profiles have more optional data we don't need\n    if (PROFILES_WITH_OPTIONAL_SPS_DATA[profileIdc]) {\n      chromaFormatIdc = expGolombDecoder.readUnsignedExpGolomb();\n      if (chromaFormatIdc === 3) {\n        expGolombDecoder.skipBits(1); // separate_colour_plane_flag\n      }\n      expGolombDecoder.skipUnsignedExpGolomb(); // bit_depth_luma_minus8\n      expGolombDecoder.skipUnsignedExpGolomb(); // bit_depth_chroma_minus8\n      expGolombDecoder.skipBits(1); // qpprime_y_zero_transform_bypass_flag\n      if (expGolombDecoder.readBoolean()) { // seq_scaling_matrix_present_flag\n        scalingListCount = (chromaFormatIdc !== 3) ? 8 : 12;\n        for (i = 0; i < scalingListCount; i++) {\n          if (expGolombDecoder.readBoolean()) { // seq_scaling_list_present_flag[ i ]\n            if (i < 6) {\n              skipScalingList(16, expGolombDecoder);\n            } else {\n              skipScalingList(64, expGolombDecoder);\n            }\n          }\n        }\n      }\n    }\n\n    expGolombDecoder.skipUnsignedExpGolomb(); // log2_max_frame_num_minus4\n    picOrderCntType = expGolombDecoder.readUnsignedExpGolomb();\n\n    if (picOrderCntType === 0) {\n      expGolombDecoder.readUnsignedExpGolomb(); // log2_max_pic_order_cnt_lsb_minus4\n    } else if (picOrderCntType === 1) {\n      expGolombDecoder.skipBits(1); // delta_pic_order_always_zero_flag\n      expGolombDecoder.skipExpGolomb(); // offset_for_non_ref_pic\n      expGolombDecoder.skipExpGolomb(); // offset_for_top_to_bottom_field\n      numRefFramesInPicOrderCntCycle = expGolombDecoder.readUnsignedExpGolomb();\n      for (i = 0; i < numRefFramesInPicOrderCntCycle; i++) {\n        expGolombDecoder.skipExpGolomb(); // offset_for_ref_frame[ i ]\n      }\n    }\n\n    expGolombDecoder.skipUnsignedExpGolomb(); // max_num_ref_frames\n    expGolombDecoder.skipBits(1); // gaps_in_frame_num_value_allowed_flag\n\n    picWidthInMbsMinus1 = expGolombDecoder.readUnsignedExpGolomb();\n    picHeightInMapUnitsMinus1 = expGolombDecoder.readUnsignedExpGolomb();\n\n    frameMbsOnlyFlag = expGolombDecoder.readBits(1);\n    if (frameMbsOnlyFlag === 0) {\n      expGolombDecoder.skipBits(1); // mb_adaptive_frame_field_flag\n    }\n\n    expGolombDecoder.skipBits(1); // direct_8x8_inference_flag\n    if (expGolombDecoder.readBoolean()) { // frame_cropping_flag\n      frameCropLeftOffset = expGolombDecoder.readUnsignedExpGolomb();\n      frameCropRightOffset = expGolombDecoder.readUnsignedExpGolomb();\n      frameCropTopOffset = expGolombDecoder.readUnsignedExpGolomb();\n      frameCropBottomOffset = expGolombDecoder.readUnsignedExpGolomb();\n    }\n    if (expGolombDecoder.readBoolean()) {\n      // vui_parameters_present_flag\n      if (expGolombDecoder.readBoolean()) {\n        // aspect_ratio_info_present_flag\n        aspectRatioIdc = expGolombDecoder.readUnsignedByte();\n        switch (aspectRatioIdc) {\n          case 1: sarRatio = [1, 1]; break;\n          case 2: sarRatio = [12, 11]; break;\n          case 3: sarRatio = [10, 11]; break;\n          case 4: sarRatio = [16, 11]; break;\n          case 5: sarRatio = [40, 33]; break;\n          case 6: sarRatio = [24, 11]; break;\n          case 7: sarRatio = [20, 11]; break;\n          case 8: sarRatio = [32, 11]; break;\n          case 9: sarRatio = [80, 33]; break;\n          case 10: sarRatio = [18, 11]; break;\n          case 11: sarRatio = [15, 11]; break;\n          case 12: sarRatio = [64, 33]; break;\n          case 13: sarRatio = [160, 99]; break;\n          case 14: sarRatio = [4, 3]; break;\n          case 15: sarRatio = [3, 2]; break;\n          case 16: sarRatio = [2, 1]; break;\n          case 255: {\n            sarRatio = [expGolombDecoder.readUnsignedByte() << 8 |\n                        expGolombDecoder.readUnsignedByte(),\n                        expGolombDecoder.readUnsignedByte() << 8 |\n                        expGolombDecoder.readUnsignedByte() ];\n            break;\n          }\n        }\n        if (sarRatio) {\n          sarScale = sarRatio[0] / sarRatio[1];\n        }\n      }\n    }\n    return {\n      profileIdc: profileIdc,\n      levelIdc: levelIdc,\n      profileCompatibility: profileCompatibility,\n      width: Math.ceil((((picWidthInMbsMinus1 + 1) * 16) - frameCropLeftOffset * 2 - frameCropRightOffset * 2) * sarScale),\n      height: ((2 - frameMbsOnlyFlag) * (picHeightInMapUnitsMinus1 + 1) * 16) - (frameCropTopOffset * 2) - (frameCropBottomOffset * 2)\n    };\n  };\n\n};\nH264Stream.prototype = new Stream();\n\nmodule.exports = {\n  H264Stream: H264Stream,\n  NalByteStream: NalByteStream,\n  unitTypes: unitTypes,\n};\n",
    "module.exports = {\n  adts: require('./adts'),\n  h264: require('./h264'),\n};\n",
    "/**\n * An object that stores the bytes of an FLV tag and methods for\n * querying and manipulating that data.\n * @see http://download.macromedia.com/f4v/video_file_format_spec_v10_1.pdf\n */\n'use strict';\n\nvar FlvTag;\n\n// (type:uint, extraData:Boolean = false) extends ByteArray\nFlvTag = function(type, extraData) {\n  var\n    // Counter if this is a metadata tag, nal start marker if this is a video\n    // tag. unused if this is an audio tag\n    adHoc = 0, // :uint\n\n    // The default size is 16kb but this is not enough to hold iframe\n    // data and the resizing algorithm costs a bit so we create a larger\n    // starting buffer for video tags\n    bufferStartSize = 16384,\n\n    // checks whether the FLV tag has enough capacity to accept the proposed\n    // write and re-allocates the internal buffers if necessary\n    prepareWrite = function(flv, count) {\n      var\n        bytes,\n        minLength = flv.position + count;\n      if (minLength < flv.bytes.byteLength) {\n        // there's enough capacity so do nothing\n        return;\n      }\n\n      // allocate a new buffer and copy over the data that will not be modified\n      bytes = new Uint8Array(minLength * 2);\n      bytes.set(flv.bytes.subarray(0, flv.position), 0);\n      flv.bytes = bytes;\n      flv.view = new DataView(flv.bytes.buffer);\n    },\n\n    // commonly used metadata properties\n    widthBytes = FlvTag.widthBytes || new Uint8Array('width'.length),\n    heightBytes = FlvTag.heightBytes || new Uint8Array('height'.length),\n    videocodecidBytes = FlvTag.videocodecidBytes || new Uint8Array('videocodecid'.length),\n    i;\n\n  if (!FlvTag.widthBytes) {\n    // calculating the bytes of common metadata names ahead of time makes the\n    // corresponding writes faster because we don't have to loop over the\n    // characters\n    // re-test with test/perf.html if you're planning on changing this\n    for (i = 0; i < 'width'.length; i++) {\n      widthBytes[i] = 'width'.charCodeAt(i);\n    }\n    for (i = 0; i < 'height'.length; i++) {\n      heightBytes[i] = 'height'.charCodeAt(i);\n    }\n    for (i = 0; i < 'videocodecid'.length; i++) {\n      videocodecidBytes[i] = 'videocodecid'.charCodeAt(i);\n    }\n\n    FlvTag.widthBytes = widthBytes;\n    FlvTag.heightBytes = heightBytes;\n    FlvTag.videocodecidBytes = videocodecidBytes;\n  }\n\n  this.keyFrame = false; // :Boolean\n\n  switch(type) {\n  case FlvTag.VIDEO_TAG:\n    this.length = 16;\n    // Start the buffer at 256k\n    bufferStartSize *= 6;\n    break;\n  case FlvTag.AUDIO_TAG:\n    this.length = 13;\n    this.keyFrame = true;\n    break;\n  case FlvTag.METADATA_TAG:\n    this.length = 29;\n    this.keyFrame = true;\n    break;\n  default:\n    throw(\"Error Unknown TagType\");\n  }\n\n  this.bytes = new Uint8Array(bufferStartSize);\n  this.view = new DataView(this.bytes.buffer);\n  this.bytes[0] = type;\n  this.position = this.length;\n  this.keyFrame = extraData; // Defaults to false\n\n  // presentation timestamp\n  this.pts = 0;\n  // decoder timestamp\n  this.dts = 0;\n\n  // ByteArray#writeBytes(bytes:ByteArray, offset:uint = 0, length:uint = 0)\n  this.writeBytes = function(bytes, offset, length) {\n    var\n      start = offset || 0,\n      end;\n    length = length || bytes.byteLength;\n    end = start + length;\n\n    prepareWrite(this, length);\n    this.bytes.set(bytes.subarray(start, end), this.position);\n\n    this.position += length;\n    this.length = Math.max(this.length, this.position);\n  };\n\n  // ByteArray#writeByte(value:int):void\n  this.writeByte = function(byte) {\n    prepareWrite(this, 1);\n    this.bytes[this.position] = byte;\n    this.position++;\n    this.length = Math.max(this.length, this.position);\n  };\n\n  // ByteArray#writeShort(value:int):void\n  this.writeShort = function(short) {\n    prepareWrite(this, 2);\n    this.view.setUint16(this.position, short);\n    this.position += 2;\n    this.length = Math.max(this.length, this.position);\n  };\n\n  // Negative index into array\n  // (pos:uint):int\n  this.negIndex = function(pos) {\n    return this.bytes[this.length - pos];\n  };\n\n  // The functions below ONLY work when this[0] == VIDEO_TAG.\n  // We are not going to check for that because we dont want the overhead\n  // (nal:ByteArray = null):int\n  this.nalUnitSize = function() {\n    if (adHoc === 0) {\n      return 0;\n    }\n\n    return this.length - (adHoc + 4);\n  };\n\n  this.startNalUnit = function() {\n    // remember position and add 4 bytes\n    if (adHoc > 0) {\n      throw new Error(\"Attempted to create new NAL wihout closing the old one\");\n    }\n\n    // reserve 4 bytes for nal unit size\n    adHoc = this.length;\n    this.length += 4;\n    this.position = this.length;\n  };\n\n  // (nal:ByteArray = null):void\n  this.endNalUnit = function(nalContainer) {\n    var\n      nalStart, // :uint\n      nalLength; // :uint\n\n    // Rewind to the marker and write the size\n    if (this.length === adHoc + 4) {\n      // we started a nal unit, but didnt write one, so roll back the 4 byte size value\n      this.length -= 4;\n    } else if (adHoc > 0) {\n      nalStart = adHoc + 4;\n      nalLength = this.length - nalStart;\n\n      this.position = adHoc;\n      this.view.setUint32(this.position, nalLength);\n      this.position = this.length;\n\n      if (nalContainer) {\n        // Add the tag to the NAL unit\n        nalContainer.push(this.bytes.subarray(nalStart, nalStart + nalLength));\n      }\n    }\n\n    adHoc = 0;\n  };\n\n  /**\n   * Write out a 64-bit floating point valued metadata property. This method is\n   * called frequently during a typical parse and needs to be fast.\n   */\n  // (key:String, val:Number):void\n  this.writeMetaDataDouble = function(key, val) {\n    var i;\n    prepareWrite(this, 2 + key.length + 9);\n\n    // write size of property name\n    this.view.setUint16(this.position, key.length);\n    this.position += 2;\n\n    // this next part looks terrible but it improves parser throughput by\n    // 10kB/s in my testing\n\n    // write property name\n    if (key === 'width') {\n      this.bytes.set(widthBytes, this.position);\n      this.position += 5;\n    } else if (key === 'height') {\n      this.bytes.set(heightBytes, this.position);\n      this.position += 6;\n    } else if (key === 'videocodecid') {\n      this.bytes.set(videocodecidBytes, this.position);\n      this.position += 12;\n    } else {\n      for (i = 0; i < key.length; i++) {\n        this.bytes[this.position] = key.charCodeAt(i);\n        this.position++;\n      }\n    }\n\n    // skip null byte\n    this.position++;\n\n    // write property value\n    this.view.setFloat64(this.position, val);\n    this.position += 8;\n\n    // update flv tag length\n    this.length = Math.max(this.length, this.position);\n    ++adHoc;\n  };\n\n  // (key:String, val:Boolean):void\n  this.writeMetaDataBoolean = function(key, val) {\n    var i;\n    prepareWrite(this, 2);\n    this.view.setUint16(this.position, key.length);\n    this.position += 2;\n    for (i = 0; i < key.length; i++) {\n      // if key.charCodeAt(i) >= 255, handle error\n      prepareWrite(this, 1);\n      this.bytes[this.position] = key.charCodeAt(i);\n      this.position++;\n    }\n    prepareWrite(this, 2);\n    this.view.setUint8(this.position, 0x01);\n    this.position++;\n    this.view.setUint8(this.position, val ? 0x01 : 0x00);\n    this.position++;\n    this.length = Math.max(this.length, this.position);\n    ++adHoc;\n  };\n\n  // ():ByteArray\n  this.finalize = function() {\n    var\n      dtsDelta, // :int\n      len; // :int\n\n    switch(this.bytes[0]) {\n      // Video Data\n    case FlvTag.VIDEO_TAG:\n      this.bytes[11] = ((this.keyFrame || extraData) ? 0x10 : 0x20 ) | 0x07; // We only support AVC, 1 = key frame (for AVC, a seekable frame), 2 = inter frame (for AVC, a non-seekable frame)\n      this.bytes[12] = extraData ?  0x00 : 0x01;\n\n      dtsDelta = this.pts - this.dts;\n      this.bytes[13] = (dtsDelta & 0x00FF0000) >>> 16;\n      this.bytes[14] = (dtsDelta & 0x0000FF00) >>>  8;\n      this.bytes[15] = (dtsDelta & 0x000000FF) >>>  0;\n      break;\n\n    case FlvTag.AUDIO_TAG:\n      this.bytes[11] = 0xAF; // 44 kHz, 16-bit stereo\n      this.bytes[12] = extraData ? 0x00 : 0x01;\n      break;\n\n    case FlvTag.METADATA_TAG:\n      this.position = 11;\n      this.view.setUint8(this.position, 0x02); // String type\n      this.position++;\n      this.view.setUint16(this.position, 0x0A); // 10 Bytes\n      this.position += 2;\n      // set \"onMetaData\"\n      this.bytes.set([0x6f, 0x6e, 0x4d, 0x65,\n                      0x74, 0x61, 0x44, 0x61,\n                      0x74, 0x61], this.position);\n      this.position += 10;\n      this.bytes[this.position] = 0x08; // Array type\n      this.position++;\n      this.view.setUint32(this.position, adHoc);\n      this.position = this.length;\n      this.bytes.set([0, 0, 9], this.position);\n      this.position += 3; // End Data Tag\n      this.length = this.position;\n      break;\n    }\n\n    len = this.length - 11;\n\n    // write the DataSize field\n    this.bytes[ 1] = (len & 0x00FF0000) >>> 16;\n    this.bytes[ 2] = (len & 0x0000FF00) >>>  8;\n    this.bytes[ 3] = (len & 0x000000FF) >>>  0;\n    // write the Timestamp\n    this.bytes[ 4] = (this.dts & 0x00FF0000) >>> 16;\n    this.bytes[ 5] = (this.dts & 0x0000FF00) >>>  8;\n    this.bytes[ 6] = (this.dts & 0x000000FF) >>>  0;\n    this.bytes[ 7] = (this.dts & 0xFF000000) >>> 24;\n    // write the StreamID\n    this.bytes[ 8] = 0;\n    this.bytes[ 9] = 0;\n    this.bytes[10] = 0;\n\n    // Sometimes we're at the end of the view and have one slot to write a\n    // uint32, so, prepareWrite of count 4, since, view is uint8\n    prepareWrite(this, 4);\n    this.view.setUint32(this.length, this.length);\n    this.length += 4;\n    this.position += 4;\n\n    // trim down the byte buffer to what is actually being used\n    this.bytes = this.bytes.subarray(0, this.length);\n    this.frameTime = FlvTag.frameTime(this.bytes);\n    // if bytes.bytelength isn't equal to this.length, handle error\n    return this;\n  };\n};\n\nFlvTag.AUDIO_TAG = 0x08; // == 8, :uint\nFlvTag.VIDEO_TAG = 0x09; // == 9, :uint\nFlvTag.METADATA_TAG = 0x12; // == 18, :uint\n\n// (tag:ByteArray):Boolean {\nFlvTag.isAudioFrame = function(tag) {\n  return FlvTag.AUDIO_TAG === tag[0];\n};\n\n// (tag:ByteArray):Boolean {\nFlvTag.isVideoFrame = function(tag) {\n  return FlvTag.VIDEO_TAG === tag[0];\n};\n\n// (tag:ByteArray):Boolean {\nFlvTag.isMetaData = function(tag) {\n  return FlvTag.METADATA_TAG === tag[0];\n};\n\n// (tag:ByteArray):Boolean {\nFlvTag.isKeyFrame = function(tag) {\n  if (FlvTag.isVideoFrame(tag)) {\n    return tag[11] === 0x17;\n  }\n\n  if (FlvTag.isAudioFrame(tag)) {\n    return true;\n  }\n\n  if (FlvTag.isMetaData(tag)) {\n    return true;\n  }\n\n  return false;\n};\n\n// (tag:ByteArray):uint {\nFlvTag.frameTime = function(tag) {\n  var pts = tag[ 4] << 16; // :uint\n  pts |= tag[ 5] <<  8;\n  pts |= tag[ 6] <<  0;\n  pts |= tag[ 7] << 24;\n  return pts;\n};\n\nmodule.exports = FlvTag;\n",
    "module.exports = {\n  tag: require('./flv-tag'),\n  Transmuxer: require('./transmuxer'),\n  tools: require('../tools/flv-inspector'),\n};\n",
    "'use strict';\n\nvar Stream = require('../utils/stream.js');\nvar FlvTag = require('./flv-tag.js');\nvar m2ts = require('../m2ts/m2ts.js');\nvar codecs = require('../codecs');\nvar AdtsStream = codecs.adts;\nvar H264Stream = codecs.h264.H264Stream;\n\nvar\n  MetadataStream,\n  Transmuxer,\n  VideoSegmentStream,\n  AudioSegmentStream,\n  CoalesceStream,\n  collectTimelineInfo,\n  metaDataTag,\n  extraDataTag;\n\n/**\n * Store information about the start and end of the tracka and the\n * duration for each frame/sample we process in order to calculate\n * the baseMediaDecodeTime\n */\ncollectTimelineInfo = function (track, data) {\n  if (typeof data.pts === 'number') {\n    if (track.timelineStartInfo.pts === undefined) {\n      track.timelineStartInfo.pts = data.pts;\n    } else {\n      track.timelineStartInfo.pts =\n        Math.min(track.timelineStartInfo.pts, data.pts);\n    }\n  }\n\n  if (typeof data.dts === 'number') {\n    if (track.timelineStartInfo.dts === undefined) {\n      track.timelineStartInfo.dts = data.dts;\n    } else {\n      track.timelineStartInfo.dts =\n        Math.min(track.timelineStartInfo.dts, data.dts);\n    }\n  }\n};\n\nmetaDataTag = function(track, pts) {\n  var\n    tag = new FlvTag(FlvTag.METADATA_TAG); // :FlvTag\n\n  tag.dts = pts;\n  tag.pts = pts;\n\n  tag.writeMetaDataDouble(\"videocodecid\", 7);\n  tag.writeMetaDataDouble(\"width\", track.width);\n  tag.writeMetaDataDouble(\"height\", track.height);\n\n  return tag;\n};\n\nextraDataTag = function(track, pts) {\n  var\n    i,\n    tag = new FlvTag(FlvTag.VIDEO_TAG, true);\n\n  tag.dts = pts;\n  tag.pts = pts;\n\n  tag.writeByte(0x01);// version\n  tag.writeByte(track.profileIdc);// profile\n  tag.writeByte(track.profileCompatibility);// compatibility\n  tag.writeByte(track.levelIdc);// level\n  tag.writeByte(0xFC | 0x03); // reserved (6 bits), NULA length size - 1 (2 bits)\n  tag.writeByte(0xE0 | 0x01 ); // reserved (3 bits), num of SPS (5 bits)\n  tag.writeShort( track.sps[0].length ); // data of SPS\n  tag.writeBytes( track.sps[0] ); // SPS\n\n  tag.writeByte(track.pps.length); // num of PPS (will there ever be more that 1 PPS?)\n  for (i = 0 ; i < track.pps.length ; ++i) {\n    tag.writeShort(track.pps[i].length); // 2 bytes for length of PPS\n    tag.writeBytes(track.pps[i]); // data of PPS\n  }\n\n  return tag;\n};\n\n/**\n * Constructs a single-track, media segment from AAC data\n * events. The output of this stream can be fed to flash.\n */\nAudioSegmentStream = function(track) {\n  var\n    adtsFrames = [],\n    adtsFramesLength = 0,\n    sequenceNumber = 0,\n    earliestAllowedDts = 0,\n    oldExtraData;\n\n  AudioSegmentStream.prototype.init.call(this);\n\n  this.push = function(data) {\n    collectTimelineInfo(track, data);\n\n    if (track && track.channelcount === undefined) {\n      track.audioobjecttype = data.audioobjecttype;\n      track.channelcount = data.channelcount;\n      track.samplerate = data.samplerate;\n      track.samplingfrequencyindex = data.samplingfrequencyindex;\n      track.samplesize = data.samplesize;\n      track.extraData = (track.audioobjecttype << 11) |\n                        (track.samplingfrequencyindex << 7) |\n                        (track.channelcount << 3);\n    }\n\n    data.pts = Math.round(data.pts / 90);\n    data.dts = Math.round(data.dts / 90);\n\n    // buffer audio data until end() is called\n    adtsFrames.push(data);\n  };\n\n  this.flush = function() {\n    var currentFrame, adtsFrame, deltaDts,lastMetaPts, tags = [];\n    // return early if no audio data has been observed\n    if (adtsFrames.length === 0) {\n      this.trigger('done');\n      return;\n    }\n\n    lastMetaPts = -Infinity;\n\n    while (adtsFrames.length) {\n      currentFrame = adtsFrames.shift();\n\n      // write out metadata tags every 1 second so that the decoder\n      // is re-initialized quickly after seeking into a different\n      // audio configuration\n      if (track.extraData !== oldExtraData || currentFrame.pts - lastMetaPts >= 1000) {\n       adtsFrame = new FlvTag(FlvTag.METADATA_TAG);\n        adtsFrame.pts = currentFrame.pts;\n        adtsFrame.dts = currentFrame.dts;\n\n        // AAC is always 10\n        adtsFrame.writeMetaDataDouble(\"audiocodecid\", 10);\n        adtsFrame.writeMetaDataBoolean(\"stereo\", 2 === track.channelcount);\n        adtsFrame.writeMetaDataDouble (\"audiosamplerate\", track.samplerate);\n        // Is AAC always 16 bit?\n        adtsFrame.writeMetaDataDouble (\"audiosamplesize\", 16);\n\n        tags.push(adtsFrame);\n\n        oldExtraData = track.extraData;\n\n        adtsFrame = new FlvTag(FlvTag.AUDIO_TAG, true);\n        // For audio, DTS is always the same as PTS. We want to set the DTS\n        // however so we can compare with video DTS to determine approximate\n        // packet order\n        adtsFrame.pts = currentFrame.pts;\n        adtsFrame.dts = currentFrame.dts;\n\n        adtsFrame.view.setUint16(adtsFrame.position, track.extraData);\n        adtsFrame.position += 2;\n        adtsFrame.length = Math.max(adtsFrame.length, adtsFrame.position);\n\n        tags.push(adtsFrame);\n\n        lastMetaPts = currentFrame.pts;\n      }\n      adtsFrame = new FlvTag(FlvTag.AUDIO_TAG);\n      adtsFrame.pts = currentFrame.pts;\n      adtsFrame.dts = currentFrame.dts;\n\n      adtsFrame.writeBytes(currentFrame.data);\n\n      tags.push(adtsFrame);\n    }\n\n    oldExtraData = null;\n    this.trigger('data', {track: track, tags: tags});\n\n    this.trigger('done');\n  };\n};\nAudioSegmentStream.prototype = new Stream();\n\n/**\n * Store FlvTags for the h264 stream\n * @param track {object} track metadata configuration\n */\nVideoSegmentStream = function(track) {\n  var\n    sequenceNumber = 0,\n    nalUnits = [],\n    nalUnitsLength = 0,\n    config,\n    h264Frame;\n  VideoSegmentStream.prototype.init.call(this);\n\n  this.finishFrame = function(tags, frame) {\n    if (!frame) {\n      return;\n    }\n    // Check if keyframe and the length of tags.\n    // This makes sure we write metadata on the first frame of a segment.\n    if (config && track && track.newMetadata &&\n        (frame.keyFrame || tags.length === 0)) {\n      // Push extra data on every IDR frame in case we did a stream change + seek\n      tags.push(metaDataTag(config, frame.pts));\n      tags.push(extraDataTag(track, frame.pts));\n      track.newMetadata = false;\n    }\n\n    frame.endNalUnit();\n    tags.push(frame);\n  };\n\n  this.push = function(data) {\n    collectTimelineInfo(track, data);\n\n    data.pts = Math.round(data.pts / 90);\n    data.dts = Math.round(data.dts / 90);\n\n    // buffer video until flush() is called\n    nalUnits.push(data);\n  };\n\n  this.flush = function() {\n    var\n      currentNal,\n      tags = [];\n\n    // Throw away nalUnits at the start of the byte stream until we find\n    // the first AUD\n    while (nalUnits.length && nalUnits[0].nalUnitType !== codecs.h264.unitTypes.access_unit_delimiter_rbsp) {\n      nalUnits.shift();\n    }\n\n    // return early if no video data has been observed\n    if (nalUnits.length === 0) {\n      this.trigger('done');\n      return;\n    }\n\n    while (nalUnits.length) {\n      currentNal = nalUnits.shift();\n\n      // record the track config\n      switch (currentNal.nalUnitType){\n      case codecs.h264.unitTypes.seq_parameter_set_rbsp:\n        track.newMetadata = true;\n        config = currentNal.config;\n        track.width = config.width;\n        track.height = config.height;\n        track.sps = [currentNal.data];\n        track.profileIdc = config.profileIdc;\n        track.levelIdc = config.levelIdc;\n        track.profileCompatibility = config.profileCompatibility;\n        h264Frame.endNalUnit();\n        break;\n      case codecs.h264.unitTypes.pic_parameter_set_rbsp:\n        track.newMetadata = true;\n        track.pps = [currentNal.data];\n        h264Frame.endNalUnit();\n        break;\n      case codecs.h264.unitTypes.access_unit_delimiter_rbsp:\n        if (h264Frame) {\n          this.finishFrame(tags, h264Frame);\n        }\n        h264Frame = new FlvTag(FlvTag.VIDEO_TAG);\n        h264Frame.pts = currentNal.pts;\n        h264Frame.dts = currentNal.dts;\n        break;\n      case codecs.h264.unitTypes.slice_layer_without_partitioning_rbsp_idr:\n        // the current sample is a key frame\n        h264Frame.keyFrame = true;\n        h264Frame.endNalUnit();\n        break;\n      default:\n        h264Frame.endNalUnit();\n        break;\n      }\n      h264Frame.startNalUnit();\n      h264Frame.writeBytes(currentNal.data);\n    }\n    if (h264Frame) {\n      this.finishFrame(tags, h264Frame);\n    }\n\n    this.trigger('data', {track: track, tags: tags});\n\n    // Continue with the flush process now\n    this.trigger('done');\n  };\n};\n\nVideoSegmentStream.prototype = new Stream();\n\n/**\n * The final stage of the transmuxer that emits the flv tags\n * for audio, video, and metadata. Also tranlates in time and\n * outputs caption data and id3 cues.\n */\nCoalesceStream = function(options) {\n  // Number of Tracks per output segment\n  // If greater than 1, we combine multiple\n  // tracks into a single segment\n  this.numberOfTracks = 0;\n  this.metadataStream = options.metadataStream;\n\n  this.videoTags = [];\n  this.audioTags = [];\n  this.videoTrack = null;\n  this.audioTrack = null;\n  this.pendingCaptions = [];\n  this.pendingMetadata = [];\n  this.pendingTracks = 0;\n\n  CoalesceStream.prototype.init.call(this);\n\n  // Take output from multiple\n  this.push = function(output) {\n    // buffer incoming captions until the associated video segment\n    // finishes\n    if (output.text) {\n      return this.pendingCaptions.push(output);\n    }\n    // buffer incoming id3 tags until the final flush\n    if (output.frames) {\n      return this.pendingMetadata.push(output);\n    }\n\n    if (output.track.type === 'video') {\n      this.videoTrack = output.track;\n      this.videoTags = output.tags;\n      this.pendingTracks++;\n    }\n    if (output.track.type === 'audio') {\n      this.audioTrack = output.track;\n      this.audioTags = output.tags;\n      this.pendingTracks++;\n    }\n  };\n};\n\nCoalesceStream.prototype = new Stream();\nCoalesceStream.prototype.flush = function() {\n  var\n    id3,\n    caption,\n    i,\n    timelineStartPts,\n    event = {\n      tags: {},\n      captions: [],\n      metadata: []\n    };\n\n  if (this.pendingTracks < this.numberOfTracks) {\n    return;\n  }\n\n  if (this.videoTrack) {\n    timelineStartPts = this.videoTrack.timelineStartInfo.pts;\n  } else if (this.audioTrack) {\n    timelineStartPts = this.audioTrack.timelineStartInfo.pts;\n  }\n\n  event.tags.videoTags = this.videoTags;\n  event.tags.audioTags = this.audioTags;\n\n  // Translate caption PTS times into second offsets into the\n  // video timeline for the segment\n  for (i = 0; i < this.pendingCaptions.length; i++) {\n    caption = this.pendingCaptions[i];\n    caption.startTime = caption.startPts - timelineStartPts;\n    caption.startTime /= 90e3;\n    caption.endTime = caption.endPts - timelineStartPts;\n    caption.endTime /= 90e3;\n    event.captions.push(caption);\n  }\n\n  // Translate ID3 frame PTS times into second offsets into the\n  // video timeline for the segment\n  for (i = 0; i < this.pendingMetadata.length; i++) {\n    id3 = this.pendingMetadata[i];\n    id3.cueTime = id3.pts - timelineStartPts;\n    id3.cueTime /= 90e3;\n    event.metadata.push(id3);\n  }\n  // We add this to every single emitted segment even though we only need\n  // it for the first\n  event.metadata.dispatchType = this.metadataStream.dispatchType;\n\n  // Reset stream state\n  this.videoTrack = null;\n  this.audioTrack = null;\n  this.videoTags = [];\n  this.audioTags = [];\n  this.pendingCaptions.length = 0;\n  this.pendingMetadata.length = 0;\n  this.pendingTracks = 0;\n\n  // Emit the final segment\n  this.trigger('data', event);\n\n  this.trigger('done');\n};\n\n/**\n * An object that incrementally transmuxes MPEG2 Trasport Stream\n * chunks into an FLV.\n */\nTransmuxer = function(options) {\n  var\n    self = this,\n    videoTrack,\n    audioTrack,\n\n    packetStream, parseStream, elementaryStream,\n    adtsStream, h264Stream,\n    videoSegmentStream, audioSegmentStream, captionStream,\n    coalesceStream;\n\n  Transmuxer.prototype.init.call(this);\n\n  options = options || {};\n\n  // expose the metadata stream\n  this.metadataStream = new m2ts.MetadataStream();\n\n  options.metadataStream = this.metadataStream;\n\n  // set up the parsing pipeline\n  packetStream = new m2ts.TransportPacketStream();\n  parseStream = new m2ts.TransportParseStream();\n  elementaryStream = new m2ts.ElementaryStream();\n  adtsStream = new AdtsStream();\n  h264Stream = new H264Stream();\n  coalesceStream = new CoalesceStream(options);\n\n  // disassemble MPEG2-TS packets into elementary streams\n  packetStream\n    .pipe(parseStream)\n    .pipe(elementaryStream);\n\n  // !!THIS ORDER IS IMPORTANT!!\n  // demux the streams\n  elementaryStream\n    .pipe(h264Stream);\n  elementaryStream\n    .pipe(adtsStream);\n\n  elementaryStream\n    .pipe(this.metadataStream)\n    .pipe(coalesceStream);\n  // if CEA-708 parsing is available, hook up a caption stream\n  captionStream = new m2ts.CaptionStream();\n  h264Stream.pipe(captionStream)\n    .pipe(coalesceStream);\n\n  // hook up the segment streams once track metadata is delivered\n  elementaryStream.on('data', function(data) {\n    var i, videoTrack, audioTrack;\n\n    if (data.type === 'metadata') {\n      i = data.tracks.length;\n\n      // scan the tracks listed in the metadata\n      while (i--) {\n        if (data.tracks[i].type === 'video') {\n          videoTrack = data.tracks[i];\n        } else if (data.tracks[i].type === 'audio') {\n          audioTrack = data.tracks[i];\n        }\n      }\n\n      // hook up the video segment stream to the first track with h264 data\n      if (videoTrack && !videoSegmentStream) {\n        coalesceStream.numberOfTracks++;\n        videoSegmentStream = new VideoSegmentStream(videoTrack);\n\n        // Set up the final part of the video pipeline\n        h264Stream\n          .pipe(videoSegmentStream)\n          .pipe(coalesceStream);\n      }\n\n      if (audioTrack && !audioSegmentStream) {\n        // hook up the audio segment stream to the first track with aac data\n        coalesceStream.numberOfTracks++;\n        audioSegmentStream = new AudioSegmentStream(audioTrack);\n\n        // Set up the final part of the audio pipeline\n        adtsStream\n          .pipe(audioSegmentStream)\n          .pipe(coalesceStream);\n      }\n    }\n  });\n\n  // feed incoming data to the front of the parsing pipeline\n  this.push = function(data) {\n    packetStream.push(data);\n  };\n\n  // flush any buffered data\n  this.flush = function() {\n    // Start at the top of the pipeline and flush all pending work\n    packetStream.flush();\n  };\n\n  // Re-emit any data coming from the coalesce stream to the outside world\n  coalesceStream.on('data', function (event) {\n    self.trigger('data', event);\n  });\n\n  // Let the consumer know we have finished flushing the entire pipeline\n  coalesceStream.on('done', function () {\n    self.trigger('done');\n  });\n\n  // For information on the FLV format, see\n  // http://download.macromedia.com/f4v/video_file_format_spec_v10_1.pdf.\n  // Technically, this function returns the header and a metadata FLV tag\n  // if duration is greater than zero\n  // duration in seconds\n  // @return {object} the bytes of the FLV header as a Uint8Array\n  this.getFlvHeader = function(duration, audio, video) { // :ByteArray {\n    var\n      headBytes = new Uint8Array(3 + 1 + 1 + 4),\n      head = new DataView(headBytes.buffer),\n      metadata,\n      result,\n      metadataLength;\n\n    // default arguments\n    duration = duration || 0;\n    audio = audio === undefined? true : audio;\n    video = video === undefined? true : video;\n\n    // signature\n    head.setUint8(0, 0x46); // 'F'\n    head.setUint8(1, 0x4c); // 'L'\n    head.setUint8(2, 0x56); // 'V'\n\n    // version\n    head.setUint8(3, 0x01);\n\n    // flags\n    head.setUint8(4, (audio ? 0x04 : 0x00) | (video ? 0x01 : 0x00));\n\n    // data offset, should be 9 for FLV v1\n    head.setUint32(5, headBytes.byteLength);\n\n    // init the first FLV tag\n    if (duration <= 0) {\n      // no duration available so just write the first field of the first\n      // FLV tag\n      result = new Uint8Array(headBytes.byteLength + 4);\n      result.set(headBytes);\n      result.set([0, 0, 0, 0], headBytes.byteLength);\n      return result;\n    }\n\n    // write out the duration metadata tag\n    metadata = new FlvTag(FlvTag.METADATA_TAG);\n    metadata.pts = metadata.dts = 0;\n    metadata.writeMetaDataDouble(\"duration\", duration);\n    metadataLength = metadata.finalize().length;\n    result = new Uint8Array(headBytes.byteLength + metadataLength);\n    result.set(headBytes);\n    result.set(head.byteLength, metadataLength);\n\n    return result;\n  };\n};\nTransmuxer.prototype = new Stream();\n\n// forward compatibility\nmodule.exports = Transmuxer;\n",
    "'use strict';\n\nvar muxjs = {\n  codecs: require('./codecs'),\n  mp4: require('./mp4'),\n  flv: require('./flv'),\n  mp2t: require('./m2ts'),\n};\nmodule.exports = muxjs;\n",
    "/**\n * mux.js\n *\n * Copyright (c) 2015 Brightcove\n * All rights reserved.\n *\n * Reads in-band caption information from a video elementary\n * stream. Captions must follow the CEA-708 standard for injection\n * into an MPEG-2 transport streams.\n * @see https://en.wikipedia.org/wiki/CEA-708\n */\n\n'use strict';\n\n// -----------------\n// Link To Transport\n// -----------------\n\n// Supplemental enhancement information (SEI) NAL units have a\n// payload type field to indicate how they are to be\n// interpreted. CEAS-708 caption content is always transmitted with\n// payload type 0x04.\nvar USER_DATA_REGISTERED_ITU_T_T35 = 4,\n    RBSP_TRAILING_BITS = 128,\n    Stream = require('../utils/stream'),\n    codecs = require('../codecs');\n\n/**\n  * Parse a supplemental enhancement information (SEI) NAL unit.\n  * Stops parsing once a message of type ITU T T35 has been found.\n  *\n  * @param bytes {Uint8Array} the bytes of a SEI NAL unit\n  * @return {object} the parsed SEI payload\n  * @see Rec. ITU-T H.264, 7.3.2.3.1\n  */\nvar parseSei = function(bytes) {\n  var\n    i = 0,\n    result = {\n      payloadType: -1,\n      payloadSize: 0,\n    },\n    payloadType = 0,\n    payloadSize = 0;\n\n  // go through the sei_rbsp parsing each each individual sei_message\n  while (i < bytes.byteLength) {\n    // stop once we have hit the end of the sei_rbsp\n    if (bytes[i] === RBSP_TRAILING_BITS) {\n      break;\n    }\n\n    // Parse payload type\n    while (bytes[i] === 0xFF) {\n      payloadType += 255;\n      i++;\n    }\n    payloadType += bytes[i++];\n\n    // Parse payload size\n    while (bytes[i] === 0xFF) {\n      payloadSize += 255;\n      i++;\n    }\n    payloadSize += bytes[i++];\n\n    // this sei_message is a 608/708 caption so save it and break\n    // there can only ever be one caption message in a frame's sei\n    if (!result.payload && payloadType === USER_DATA_REGISTERED_ITU_T_T35) {\n      result.payloadType = payloadType;\n      result.payloadSize = payloadSize;\n      result.payload = bytes.subarray(i, i + payloadSize);\n      break;\n    }\n\n    // skip the payload and parse the next message\n    i += payloadSize;\n    payloadType = 0;\n    payloadSize = 0;\n  }\n\n  return result;\n};\n\n// see ANSI/SCTE 128-1 (2013), section 8.1\nvar parseUserData = function(sei) {\n  // itu_t_t35_contry_code must be 181 (United States) for\n  // captions\n  if (sei.payload[0] !== 181) {\n    return null;\n  }\n\n  // itu_t_t35_provider_code should be 49 (ATSC) for captions\n  if (((sei.payload[1] << 8) | sei.payload[2]) !== 49) {\n    return null;\n  }\n\n  // the user_identifier should be \"GA94\" to indicate ATSC1 data\n  if (String.fromCharCode(sei.payload[3],\n                          sei.payload[4],\n                          sei.payload[5],\n                          sei.payload[6]) !== 'GA94') {\n    return null;\n  }\n\n  // finally, user_data_type_code should be 0x03 for caption data\n  if (sei.payload[7] !== 0x03) {\n    return null;\n  }\n\n  // return the user_data_type_structure and strip the trailing\n  // marker bits\n  return sei.payload.subarray(8, sei.payload.length - 1);\n};\n\n// see CEA-708-D, section 4.4\nvar parseCaptionPackets = function(pts, userData) {\n  var results = [], i, count, offset, data;\n\n  // if this is just filler, return immediately\n  if (!(userData[0] & 0x40)) {\n    return results;\n  }\n\n  // parse out the cc_data_1 and cc_data_2 fields\n  count = userData[0] & 0x1f;\n  for (i = 0; i < count; i++) {\n    offset = i * 3;\n    data = {\n      type: userData[offset + 2] & 0x03,\n      pts: pts\n    };\n\n    // capture cc data when cc_valid is 1\n    if (userData[offset + 2] & 0x04) {\n      data.ccData = (userData[offset + 3] << 8) | userData[offset + 4];\n      results.push(data);\n    }\n  }\n  return results;\n};\n\nvar CaptionStream = function() {\n  var self = this;\n  CaptionStream.prototype.init.call(this);\n\n  this.captionPackets_ = [];\n\n  this.field1_ = new Cea608Stream();\n\n  // forward data and done events from field1_ to this CaptionStream\n  this.field1_.on('data', this.trigger.bind(this, 'data'));\n  this.field1_.on('done', this.trigger.bind(this, 'done'));\n};\nCaptionStream.prototype = new Stream();\nCaptionStream.prototype.push = function(event) {\n  var sei, userData, captionPackets;\n\n  // only examine SEI NALs\n  if (event.nalUnitType !== codecs.h264.unitTypes.sei_rbsp) {\n    return;\n  }\n\n  // parse the sei\n  sei = parseSei(event.escapedRBSP);\n\n  // ignore everything but user_data_registered_itu_t_t35\n  if (sei.payloadType !== USER_DATA_REGISTERED_ITU_T_T35) {\n    return;\n  }\n\n  // parse out the user data payload\n  userData = parseUserData(sei);\n\n  // ignore unrecognized userData\n  if (!userData) {\n    return;\n  }\n\n  // parse out CC data packets and save them for later\n  this.captionPackets_ = this.captionPackets_.concat(parseCaptionPackets(event.pts, userData));\n};\n\nCaptionStream.prototype.flush = function () {\n  // make sure we actually parsed captions before proceeding\n  if (!this.captionPackets_.length) {\n    this.field1_.flush();\n    return;\n  }\n\n  // sort caption byte-pairs based on their PTS values\n  this.captionPackets_.sort(function(a, b) {\n    return a.pts - b.pts;\n  });\n\n  // Push each caption into Cea608Stream\n  this.captionPackets_.forEach(this.field1_.push, this.field1_);\n\n  this.captionPackets_.length = 0;\n  this.field1_.flush();\n  return;\n};\n// ----------------------\n// Session to Application\n// ----------------------\n\nvar BASIC_CHARACTER_TRANSLATION = {\n  0x2a: 0xe1,\n  0x5c: 0xe9,\n  0x5e: 0xed,\n  0x5f: 0xf3,\n  0x60: 0xfa,\n  0x7b: 0xe7,\n  0x7c: 0xf7,\n  0x7d: 0xd1,\n  0x7e: 0xf1,\n  0x7f: 0x2588\n};\n\nvar getCharFromCode = function(code) {\n  if(code === null) {\n    return '';\n  }\n  code = BASIC_CHARACTER_TRANSLATION[code] || code;\n  return String.fromCharCode(code);\n};\n\n// Constants for the byte codes recognized by Cea608Stream. This\n// list is not exhaustive. For a more comprehensive listing and\n// semantics see\n// http://www.gpo.gov/fdsys/pkg/CFR-2010-title47-vol1/pdf/CFR-2010-title47-vol1-sec15-119.pdf\nvar PADDING                    = 0x0000,\n\n    // Pop-on Mode\n    RESUME_CAPTION_LOADING     = 0x1420,\n    END_OF_CAPTION             = 0x142f,\n\n    // Roll-up Mode\n    ROLL_UP_2_ROWS             = 0x1425,\n    ROLL_UP_3_ROWS             = 0x1426,\n    ROLL_UP_4_ROWS             = 0x1427,\n    RESUME_DIRECT_CAPTIONING   = 0x1429,\n    CARRIAGE_RETURN            = 0x142d,\n    // Erasure\n    BACKSPACE                  = 0x1421,\n    ERASE_DISPLAYED_MEMORY     = 0x142c,\n    ERASE_NON_DISPLAYED_MEMORY = 0x142e;\n\n// the index of the last row in a CEA-608 display buffer\nvar BOTTOM_ROW = 14;\n// CEA-608 captions are rendered onto a 34x15 matrix of character\n// cells. The \"bottom\" row is the last element in the outer array.\nvar createDisplayBuffer = function() {\n  var result = [], i = BOTTOM_ROW + 1;\n  while (i--) {\n    result.push('');\n  }\n  return result;\n};\n\nvar Cea608Stream = function() {\n  Cea608Stream.prototype.init.call(this);\n\n  this.mode_ = 'popOn';\n  // When in roll-up mode, the index of the last row that will\n  // actually display captions. If a caption is shifted to a row\n  // with a lower index than this, it is cleared from the display\n  // buffer\n  this.topRow_ = 0;\n  this.startPts_ = 0;\n  this.displayed_ = createDisplayBuffer();\n  this.nonDisplayed_ = createDisplayBuffer();\n  this.lastControlCode_ = null;\n\n  this.push = function(packet) {\n    // Ignore other channels\n    if (packet.type !== 0) {\n      return;\n    }\n    var data, swap, char0, char1;\n    // remove the parity bits\n    data = packet.ccData & 0x7f7f;\n\n    // ignore duplicate control codes\n    if (data === this.lastControlCode_) {\n      this.lastControlCode_ = null;\n      return;\n    }\n\n    // Store control codes\n    if ((data & 0xf000) === 0x1000) {\n      this.lastControlCode_ = data;\n    } else {\n      this.lastControlCode_ = null;\n    }\n\n    switch (data) {\n    case PADDING:\n      break;\n    case RESUME_CAPTION_LOADING:\n      this.mode_ = 'popOn';\n      break;\n    case END_OF_CAPTION:\n      // if a caption was being displayed, it's gone now\n      this.flushDisplayed(packet.pts);\n\n      // flip memory\n      swap = this.displayed_;\n      this.displayed_ = this.nonDisplayed_;\n      this.nonDisplayed_ = swap;\n\n      // start measuring the time to display the caption\n      this.startPts_ = packet.pts;\n      break;\n\n    case ROLL_UP_2_ROWS:\n      this.topRow_ = BOTTOM_ROW - 1;\n      this.mode_ = 'rollUp';\n      break;\n    case ROLL_UP_3_ROWS:\n      this.topRow_ = BOTTOM_ROW - 2;\n      this.mode_ = 'rollUp';\n      break;\n    case ROLL_UP_4_ROWS:\n      this.topRow_ = BOTTOM_ROW - 3;\n      this.mode_ = 'rollUp';\n      break;\n    case CARRIAGE_RETURN:\n      this.flushDisplayed(packet.pts);\n      this.shiftRowsUp_();\n      this.startPts_ = packet.pts;\n      break;\n\n    case BACKSPACE:\n      if (this.mode_ === 'popOn') {\n        this.nonDisplayed_[BOTTOM_ROW] = this.nonDisplayed_[BOTTOM_ROW].slice(0, -1);\n      } else {\n        this.displayed_[BOTTOM_ROW] = this.displayed_[BOTTOM_ROW].slice(0, -1);\n      }\n      break;\n    case ERASE_DISPLAYED_MEMORY:\n      this.flushDisplayed(packet.pts);\n      this.displayed_ = createDisplayBuffer();\n      break;\n    case ERASE_NON_DISPLAYED_MEMORY:\n      this.nonDisplayed_ = createDisplayBuffer();\n      break;\n    default:\n      char0 = data >>> 8;\n      char1 = data & 0xff;\n\n      // Look for a Channel 1 Preamble Address Code\n      if (char0 >= 0x10 && char0 <= 0x17 &&\n          char1 >= 0x40 && char1 <= 0x7F &&\n          (char0 !== 0x10 || char1 < 0x60)) {\n        // Follow Safari's lead and replace the PAC with a space\n        char0 = 0x20;\n        // we only want one space so make the second character null\n        // which will get become '' in getCharFromCode\n        char1 = null;\n      }\n\n      // Look for special character sets\n      if ((char0 === 0x11 || char0 === 0x19) &&\n          (char1 >= 0x30 && char1 <= 0x3F)) {\n        // Put in eigth note and space\n        char0 = 0x266A;\n        char1 = '';\n      }\n\n      // ignore unsupported control codes\n      if ((char0 & 0xf0) === 0x10) {\n        return;\n      }\n\n      // character handling is dependent on the current mode\n      this[this.mode_](packet.pts, char0, char1);\n      break;\n    }\n  };\n};\nCea608Stream.prototype = new Stream();\n// Trigger a cue point that captures the current state of the\n// display buffer\nCea608Stream.prototype.flushDisplayed = function(pts) {\n  var content = this.displayed_\n    // remove spaces from the start and end of the string\n    .map(function(row) { return row.trim(); })\n    // remove empty rows\n    .filter(function(row) { return row.length; })\n    // combine all text rows to display in one cue\n    .join('\\n');\n\n  if (content.length) {\n    this.trigger('data', {\n      startPts: this.startPts_,\n      endPts: pts,\n      text: content\n    });\n  }\n};\n\n// Mode Implementations\nCea608Stream.prototype.popOn = function(pts, char0, char1) {\n  var baseRow = this.nonDisplayed_[BOTTOM_ROW];\n\n  // buffer characters\n  baseRow += getCharFromCode(char0);\n  baseRow += getCharFromCode(char1);\n  this.nonDisplayed_[BOTTOM_ROW] = baseRow;\n};\n\nCea608Stream.prototype.rollUp = function(pts, char0, char1) {\n  var baseRow = this.displayed_[BOTTOM_ROW];\n  if (baseRow === '') {\n    // we're starting to buffer new display input, so flush out the\n    // current display\n    this.flushDisplayed(pts);\n\n    this.startPts_ = pts;\n  }\n\n  baseRow += getCharFromCode(char0);\n  baseRow += getCharFromCode(char1);\n\n  this.displayed_[BOTTOM_ROW] = baseRow;\n};\nCea608Stream.prototype.shiftRowsUp_ = function() {\n  var i;\n  // clear out inactive rows\n  for (i = 0; i < this.topRow_; i++) {\n    this.displayed_[i] = '';\n  }\n  // shift displayed rows up\n  for (i = this.topRow_; i < BOTTOM_ROW; i++) {\n    this.displayed_[i] = this.displayed_[i + 1];\n  }\n  // clear out the bottom row\n  this.displayed_[BOTTOM_ROW] = '';\n};\n\n// exports\nmodule.exports = {\n  CaptionStream: CaptionStream,\n  Cea608Stream: Cea608Stream,\n};\n\n",
    "module.exports = require('./m2ts');\n",
    "/**\n * mux.js\n *\n * Copyright (c) 2015 Brightcove\n * All rights reserved.\n *\n * A stream-based mp2t to mp4 converter. This utility can be used to\n * deliver mp4s to a SourceBuffer on platforms that support native\n * Media Source Extensions.\n */\n'use strict';\nvar Stream = require('../utils/stream.js'),\n  CaptionStream = require('./caption-stream'),\n  StreamTypes = require('./stream-types'),\n  TimestampRolloverStream = require('./timestamp-rollover-stream').TimestampRolloverStream;\n\nvar m2tsStreamTypes = require('./stream-types.js');\n\n// object types\nvar TransportPacketStream, TransportParseStream, ElementaryStream;\n\n// constants\nvar\n  MP2T_PACKET_LENGTH = 188, // bytes\n  SYNC_BYTE = 0x47;\n\n/**\n * Splits an incoming stream of binary data into MPEG-2 Transport\n * Stream packets.\n */\nTransportPacketStream = function() {\n  var\n    buffer = new Uint8Array(MP2T_PACKET_LENGTH),\n    bytesInBuffer = 0;\n\n  TransportPacketStream.prototype.init.call(this);\n\n   // Deliver new bytes to the stream.\n\n  this.push = function(bytes) {\n    var\n      startIndex = 0,\n      endIndex = MP2T_PACKET_LENGTH,\n      everything;\n\n    // If there are bytes remaining from the last segment, prepend them to the\n    // bytes that were pushed in\n    if (bytesInBuffer) {\n      everything = new Uint8Array(bytes.byteLength + bytesInBuffer);\n      everything.set(buffer.subarray(0, bytesInBuffer));\n      everything.set(bytes, bytesInBuffer);\n      bytesInBuffer = 0;\n    } else {\n      everything = bytes;\n    }\n\n    // While we have enough data for a packet\n    while (endIndex < everything.byteLength) {\n      // Look for a pair of start and end sync bytes in the data..\n      if (everything[startIndex] === SYNC_BYTE && everything[endIndex] === SYNC_BYTE) {\n        // We found a packet so emit it and jump one whole packet forward in\n        // the stream\n        this.trigger('data', everything.subarray(startIndex, endIndex));\n        startIndex += MP2T_PACKET_LENGTH;\n        endIndex += MP2T_PACKET_LENGTH;\n        continue;\n      }\n      // If we get here, we have somehow become de-synchronized and we need to step\n      // forward one byte at a time until we find a pair of sync bytes that denote\n      // a packet\n      startIndex++;\n      endIndex++;\n    }\n\n    // If there was some data left over at the end of the segment that couldn't\n    // possibly be a whole packet, keep it because it might be the start of a packet\n    // that continues in the next segment\n    if (startIndex < everything.byteLength) {\n      buffer.set(everything.subarray(startIndex), 0);\n      bytesInBuffer = everything.byteLength - startIndex;\n    }\n  };\n\n  this.flush = function() {\n    // If the buffer contains a whole packet when we are being flushed, emit it\n    // and empty the buffer. Otherwise hold onto the data because it may be\n    // important for decoding the next segment\n    if (bytesInBuffer === MP2T_PACKET_LENGTH && buffer[0] === SYNC_BYTE) {\n      this.trigger('data', buffer);\n      bytesInBuffer = 0;\n    }\n    this.trigger('done');\n  };\n};\nTransportPacketStream.prototype = new Stream();\n\n/**\n * Accepts an MP2T TransportPacketStream and emits data events with parsed\n * forms of the individual transport stream packets.\n */\nTransportParseStream = function() {\n  var parsePsi, parsePat, parsePmt, parsePes, self;\n  TransportParseStream.prototype.init.call(this);\n  self = this;\n\n  this.packetsWaitingForPmt = [];\n  this.programMapTable = undefined;\n\n  parsePsi = function(payload, psi) {\n    var offset = 0;\n\n    // PSI packets may be split into multiple sections and those\n    // sections may be split into multiple packets. If a PSI\n    // section starts in this packet, the payload_unit_start_indicator\n    // will be true and the first byte of the payload will indicate\n    // the offset from the current position to the start of the\n    // section.\n    if (psi.payloadUnitStartIndicator) {\n      offset += payload[offset] + 1;\n    }\n\n    if (psi.type === 'pat') {\n      parsePat(payload.subarray(offset), psi);\n    } else {\n      parsePmt(payload.subarray(offset), psi);\n    }\n  };\n\n  parsePat = function(payload, pat) {\n    pat.section_number = payload[7];\n    pat.last_section_number = payload[8];\n\n    // skip the PSI header and parse the first PMT entry\n    self.pmtPid = (payload[10] & 0x1F) << 8 | payload[11];\n    pat.pmtPid = self.pmtPid;\n  };\n\n  /**\n   * Parse out the relevant fields of a Program Map Table (PMT).\n   * @param payload {Uint8Array} the PMT-specific portion of an MP2T\n   * packet. The first byte in this array should be the table_id\n   * field.\n   * @param pmt {object} the object that should be decorated with\n   * fields parsed from the PMT.\n   */\n  parsePmt = function(payload, pmt) {\n    var sectionLength, tableEnd, programInfoLength, offset;\n\n    // PMTs can be sent ahead of the time when they should actually\n    // take effect. We don't believe this should ever be the case\n    // for HLS but we'll ignore \"forward\" PMT declarations if we see\n    // them. Future PMT declarations have the current_next_indicator\n    // set to zero.\n    if (!(payload[5] & 0x01)) {\n      return;\n    }\n\n    // overwrite any existing program map table\n    self.programMapTable = {};\n\n    // the mapping table ends at the end of the current section\n    sectionLength = (payload[1] & 0x0f) << 8 | payload[2];\n    tableEnd = 3 + sectionLength - 4;\n\n    // to determine where the table is, we have to figure out how\n    // long the program info descriptors are\n    programInfoLength = (payload[10] & 0x0f) << 8 | payload[11];\n\n    // advance the offset to the first entry in the mapping table\n    offset = 12 + programInfoLength;\n    while (offset < tableEnd) {\n      // add an entry that maps the elementary_pid to the stream_type\n      self.programMapTable[(payload[offset + 1] & 0x1F) << 8 | payload[offset + 2]] = payload[offset];\n\n      // move to the next table entry\n      // skip past the elementary stream descriptors, if present\n      offset += ((payload[offset + 3] & 0x0F) << 8 | payload[offset + 4]) + 5;\n    }\n\n    // record the map on the packet as well\n    pmt.programMapTable = self.programMapTable;\n\n    // if there are any packets waiting for a PMT to be found, process them now\n    while (self.packetsWaitingForPmt.length) {\n      self.processPes_.apply(self, self.packetsWaitingForPmt.shift());\n    }\n  };\n\n  /**\n   * Deliver a new MP2T packet to the stream.\n   */\n  this.push = function(packet) {\n    var\n      result = {},\n      offset = 4;\n\n    result.payloadUnitStartIndicator = !!(packet[1] & 0x40);\n\n    // pid is a 13-bit field starting at the last bit of packet[1]\n    result.pid = packet[1] & 0x1f;\n    result.pid <<= 8;\n    result.pid |= packet[2];\n\n    // if an adaption field is present, its length is specified by the\n    // fifth byte of the TS packet header. The adaptation field is\n    // used to add stuffing to PES packets that don't fill a complete\n    // TS packet, and to specify some forms of timing and control data\n    // that we do not currently use.\n    if (((packet[3] & 0x30) >>> 4) > 0x01) {\n      offset += packet[offset] + 1;\n    }\n\n    // parse the rest of the packet based on the type\n    if (result.pid === 0) {\n      result.type = 'pat';\n      parsePsi(packet.subarray(offset), result);\n      this.trigger('data', result);\n    } else if (result.pid === this.pmtPid) {\n      result.type = 'pmt';\n      parsePsi(packet.subarray(offset), result);\n      this.trigger('data', result);\n    } else if (this.programMapTable === undefined) {\n      // When we have not seen a PMT yet, defer further processing of\n      // PES packets until one has been parsed\n      this.packetsWaitingForPmt.push([packet, offset, result]);\n    } else {\n      this.processPes_(packet, offset, result);\n    }\n  };\n\n  this.processPes_ = function(packet, offset, result) {\n    result.streamType = this.programMapTable[result.pid];\n    result.type = 'pes';\n    result.data = packet.subarray(offset);\n\n    this.trigger('data', result);\n  };\n\n};\nTransportParseStream.prototype = new Stream();\nTransportParseStream.STREAM_TYPES  = {\n  h264: 0x1b,\n  adts: 0x0f\n};\n\n/**\n * Reconsistutes program elementary stream (PES) packets from parsed\n * transport stream packets. That is, if you pipe an\n * mp2t.TransportParseStream into a mp2t.ElementaryStream, the output\n * events will be events which capture the bytes for individual PES\n * packets plus relevant metadata that has been extracted from the\n * container.\n */\nElementaryStream = function() {\n  var\n    self = this,\n    // PES packet fragments\n    video = {\n      data: [],\n      size: 0\n    },\n    audio = {\n      data: [],\n      size: 0\n    },\n    timedMetadata = {\n      data: [],\n      size: 0\n    },\n    parsePes = function(payload, pes) {\n      var ptsDtsFlags;\n      function extract_ts(arr, index) {\n        var ts = (arr[index] & 0x0E) * 536870912 + // 1 << 29\n          (arr[index+1] & 0xFF) * 4194304 + // 1 << 22\n          (arr[index+2] & 0xFE) * 16384 + // 1 << 14\n          (arr[index+3] & 0xFF) * 128 + // 1 << 7\n          (arr[index+4] & 0xFE) / 2;\n        // check if greater than 2^32 -1\n        if (ts > 4294967295) {\n          // decrement 2^33\n          ts -= 8589934592;\n        }\n        return ts;\n      }\n\n      // find out if this packets starts a new keyframe\n      pes.dataAlignmentIndicator = (payload[6] & 0x04) !== 0;\n      // PES packets may be annotated with a PTS value, or a PTS value\n      // and a DTS value. Determine what combination of values is\n      // available to work with.\n      ptsDtsFlags = payload[7];\n\n      // PTS and DTS are normally stored as a 33-bit number.  Javascript\n      // performs all bitwise operations on 32-bit integers but javascript\n      // supports a much greater range (52-bits) of integer using standard\n      // mathematical operations.\n      // We construct a 31-bit value using bitwise operators over the 31\n      // most significant bits and then multiply by 4 (equal to a left-shift\n      // of 2) before we add the final 2 least significant bits of the\n      // timestamp (equal to an OR.)\n      if (ptsDtsFlags & 0xC0) {\n        // the PTS and DTS are not written out directly. For information\n        // on how they are encoded, see\n        // http://dvd.sourceforge.net/dvdinfo/pes-hdr.html\n        pes.pts = extract_ts(payload, 9);\n        pes.dts = ptsDtsFlags & 0x40 ? extract_ts(payload, 14) : pes.pts;\n      }\n      // the data section starts immediately after the PES header.\n      // pes_header_data_length specifies the number of header bytes\n      // that follow the last byte of the field.\n      pes.data = payload.subarray(9 + payload[8]);\n    },\n    flushStream = function(stream, type) {\n      var\n        packetData = new Uint8Array(stream.size),\n        event = {\n          type: type\n        },\n        i = 0,\n        fragment;\n\n      // do nothing if there is no buffered data\n      if (!stream.data.length) {\n        return;\n      }\n      event.trackId = stream.data[0].pid;\n\n      // reassemble the packet\n      while (stream.data.length) {\n        fragment = stream.data.shift();\n\n        packetData.set(fragment.data, i);\n        i += fragment.data.byteLength;\n      }\n\n      // parse assembled packet's PES header\n      parsePes(packetData, event);\n\n      stream.size = 0;\n\n      self.trigger('data', event);\n    };\n\n  ElementaryStream.prototype.init.call(this);\n\n  this.push = function(data) {\n    ({\n      pat: function() {\n        // we have to wait for the PMT to arrive as well before we\n        // have any meaningful metadata\n      },\n      pes: function() {\n        var stream, streamType;\n\n        switch (data.streamType) {\n        case StreamTypes.H264_STREAM_TYPE:\n        case m2tsStreamTypes.H264_STREAM_TYPE:\n          stream = video;\n          streamType = 'video';\n          break;\n        case StreamTypes.ADTS_STREAM_TYPE:\n          stream = audio;\n          streamType = 'audio';\n          break;\n        case StreamTypes.METADATA_STREAM_TYPE:\n          stream = timedMetadata;\n          streamType = 'timed-metadata';\n          break;\n        default:\n          // ignore unknown stream types\n          return;\n        }\n\n        // if a new packet is starting, we can flush the completed\n        // packet\n        if (data.payloadUnitStartIndicator) {\n          flushStream(stream, streamType);\n        }\n\n        // buffer this fragment until we are sure we've received the\n        // complete payload\n        stream.data.push(data);\n        stream.size += data.data.byteLength;\n      },\n      pmt: function() {\n        var\n          event = {\n            type: 'metadata',\n            tracks: []\n          },\n          programMapTable = data.programMapTable,\n          k,\n          track;\n\n        // translate streams to tracks\n        for (k in programMapTable) {\n          if (programMapTable.hasOwnProperty(k)) {\n            track = {\n              timelineStartInfo: {\n                baseMediaDecodeTime: 0\n              }\n            };\n            track.id = +k;\n            if (programMapTable[k] === m2tsStreamTypes.H264_STREAM_TYPE) {\n              track.codec = 'avc';\n              track.type = 'video';\n            } else if (programMapTable[k] === m2tsStreamTypes.ADTS_STREAM_TYPE) {\n              track.codec = 'adts';\n              track.type = 'audio';\n            }\n            event.tracks.push(track);\n          }\n        }\n        self.trigger('data', event);\n      }\n    })[data.type]();\n  };\n\n  /**\n   * Flush any remaining input. Video PES packets may be of variable\n   * length. Normally, the start of a new video packet can trigger the\n   * finalization of the previous packet. That is not possible if no\n   * more video is forthcoming, however. In that case, some other\n   * mechanism (like the end of the file) has to be employed. When it is\n   * clear that no additional data is forthcoming, calling this method\n   * will flush the buffered packets.\n   */\n  this.flush = function() {\n    // !!THIS ORDER IS IMPORTANT!!\n    // video first then audio\n    flushStream(video, 'video');\n    flushStream(audio, 'audio');\n    flushStream(timedMetadata, 'timed-metadata');\n    this.trigger('done');\n  };\n};\nElementaryStream.prototype = new Stream();\n\nvar m2ts = {\n  PAT_PID: 0x0000,\n  MP2T_PACKET_LENGTH: MP2T_PACKET_LENGTH,\n  TransportPacketStream: TransportPacketStream,\n  TransportParseStream: TransportParseStream,\n  ElementaryStream: ElementaryStream,\n  TimestampRolloverStream: TimestampRolloverStream,\n  CaptionStream: CaptionStream.CaptionStream,\n  Cea608Stream: CaptionStream.Cea608Stream,\n  MetadataStream: require('./metadata-stream')\n};\n\nfor (var type in StreamTypes) {\n  if (StreamTypes.hasOwnProperty(type)) {\n    m2ts[type] = StreamTypes[type];\n  }\n}\n\nmodule.exports = m2ts;\n",
    "/**\n * Accepts program elementary stream (PES) data events and parses out\n * ID3 metadata from them, if present.\n * @see http://id3.org/id3v2.3.0\n */\n'use strict';\nvar\n  Stream = require('../utils/stream'),\n  StreamTypes = require('./stream-types'),\n  // return a percent-encoded representation of the specified byte range\n  // @see http://en.wikipedia.org/wiki/Percent-encoding\n  percentEncode = function(bytes, start, end) {\n    var i, result = '';\n    for (i = start; i < end; i++) {\n      result += '%' + ('00' + bytes[i].toString(16)).slice(-2);\n    }\n    return result;\n  },\n  // return the string representation of the specified byte range,\n  // interpreted as UTf-8.\n  parseUtf8 = function(bytes, start, end) {\n    return decodeURIComponent(percentEncode(bytes, start, end));\n  },\n  // return the string representation of the specified byte range,\n  // interpreted as ISO-8859-1.\n  parseIso88591 = function(bytes, start, end) {\n    return unescape(percentEncode(bytes, start, end)); // jshint ignore:line\n  },\n  parseSyncSafeInteger = function (data) {\n    return (data[0] << 21) |\n            (data[1] << 14) |\n            (data[2] << 7) |\n            (data[3]);\n  },\n  tagParsers = {\n    'TXXX': function(tag) {\n      var i;\n      if (tag.data[0] !== 3) {\n        // ignore frames with unrecognized character encodings\n        return;\n      }\n\n      for (i = 1; i < tag.data.length; i++) {\n        if (tag.data[i] === 0) {\n          // parse the text fields\n          tag.description = parseUtf8(tag.data, 1, i);\n          // do not include the null terminator in the tag value\n          tag.value = parseUtf8(tag.data, i + 1, tag.data.length - 1);\n          break;\n        }\n      }\n      tag.data = tag.value;\n    },\n    'WXXX': function(tag) {\n      var i;\n      if (tag.data[0] !== 3) {\n        // ignore frames with unrecognized character encodings\n        return;\n      }\n\n      for (i = 1; i < tag.data.length; i++) {\n        if (tag.data[i] === 0) {\n          // parse the description and URL fields\n          tag.description = parseUtf8(tag.data, 1, i);\n          tag.url = parseUtf8(tag.data, i + 1, tag.data.length);\n          break;\n        }\n      }\n    },\n    'PRIV': function(tag) {\n      var i;\n\n      for (i = 0; i < tag.data.length; i++) {\n        if (tag.data[i] === 0) {\n          // parse the description and URL fields\n          tag.owner = parseIso88591(tag.data, 0, i);\n          break;\n        }\n      }\n      tag.privateData = tag.data.subarray(i + 1);\n      tag.data = tag.privateData;\n    }\n  },\n  MetadataStream;\n\nMetadataStream = function(options) {\n  var\n    settings = {\n      debug: !!(options && options.debug),\n\n      // the bytes of the program-level descriptor field in MP2T\n      // see ISO/IEC 13818-1:2013 (E), section 2.6 \"Program and\n      // program element descriptors\"\n      descriptor: options && options.descriptor\n    },\n    // the total size in bytes of the ID3 tag being parsed\n    tagSize = 0,\n    // tag data that is not complete enough to be parsed\n    buffer = [],\n    // the total number of bytes currently in the buffer\n    bufferSize = 0,\n    i;\n\n  MetadataStream.prototype.init.call(this);\n\n  // calculate the text track in-band metadata track dispatch type\n  // https://html.spec.whatwg.org/multipage/embedded-content.html#steps-to-expose-a-media-resource-specific-text-track\n  this.dispatchType = StreamTypes.METADATA_STREAM_TYPE.toString(16);\n  if (settings.descriptor) {\n    for (i = 0; i < settings.descriptor.length; i++) {\n      this.dispatchType += ('00' + settings.descriptor[i].toString(16)).slice(-2);\n    }\n  }\n\n  this.push = function(chunk) {\n    var tag, frameStart, frameSize, frame, i, frameHeader;\n    if (chunk.type !== 'timed-metadata') {\n      return;\n    }\n\n    // if data_alignment_indicator is set in the PES header,\n    // we must have the start of a new ID3 tag. Assume anything\n    // remaining in the buffer was malformed and throw it out\n    if (chunk.dataAlignmentIndicator) {\n      bufferSize = 0;\n      buffer.length = 0;\n    }\n\n    // ignore events that don't look like ID3 data\n    if (buffer.length === 0 &&\n        (chunk.data.length < 10 ||\n          chunk.data[0] !== 'I'.charCodeAt(0) ||\n          chunk.data[1] !== 'D'.charCodeAt(0) ||\n          chunk.data[2] !== '3'.charCodeAt(0))) {\n      if (settings.debug) {\n        console.log('Skipping unrecognized metadata packet');\n      }\n      return;\n    }\n\n    // add this chunk to the data we've collected so far\n\n    buffer.push(chunk);\n    bufferSize += chunk.data.byteLength;\n\n    // grab the size of the entire frame from the ID3 header\n    if (buffer.length === 1) {\n      // the frame size is transmitted as a 28-bit integer in the\n      // last four bytes of the ID3 header.\n      // The most significant bit of each byte is dropped and the\n      // results concatenated to recover the actual value.\n      tagSize = parseSyncSafeInteger(chunk.data.subarray(6, 10));\n\n      // ID3 reports the tag size excluding the header but it's more\n      // convenient for our comparisons to include it\n      tagSize += 10;\n    }\n\n    // if the entire frame has not arrived, wait for more data\n    if (bufferSize < tagSize) {\n      return;\n    }\n\n    // collect the entire frame so it can be parsed\n    tag = {\n      data: new Uint8Array(tagSize),\n      frames: [],\n      pts: buffer[0].pts,\n      dts: buffer[0].dts\n    };\n    for (i = 0; i < tagSize;) {\n      tag.data.set(buffer[0].data.subarray(0, tagSize - i), i);\n      i += buffer[0].data.byteLength;\n      bufferSize -= buffer[0].data.byteLength;\n      buffer.shift();\n    }\n\n    // find the start of the first frame and the end of the tag\n    frameStart = 10;\n    if (tag.data[5] & 0x40) {\n      // advance the frame start past the extended header\n      frameStart += 4; // header size field\n      frameStart += parseSyncSafeInteger(tag.data.subarray(10, 14));\n\n      // clip any padding off the end\n      tagSize -= parseSyncSafeInteger(tag.data.subarray(16, 20));\n    }\n\n    // parse one or more ID3 frames\n    // http://id3.org/id3v2.3.0#ID3v2_frame_overview\n    do {\n      // determine the number of bytes in this frame\n      frameSize = parseSyncSafeInteger(tag.data.subarray(frameStart + 4, frameStart + 8));\n      if (frameSize < 1) {\n        return console.log('Malformed ID3 frame encountered. Skipping metadata parsing.');\n      }\n      frameHeader = String.fromCharCode(tag.data[frameStart],\n                                        tag.data[frameStart + 1],\n                                        tag.data[frameStart + 2],\n                                        tag.data[frameStart + 3]);\n\n\n      frame = {\n        id: frameHeader,\n        data: tag.data.subarray(frameStart + 10, frameStart + frameSize + 10)\n      };\n      frame.key = frame.id;\n      if (tagParsers[frame.id]) {\n        tagParsers[frame.id](frame);\n        if (frame.owner === 'com.apple.streaming.transportStreamTimestamp') {\n          var\n            d = frame.data,\n            size = ((d[3] & 0x01)  << 30) |\n                   (d[4]  << 22) |\n                   (d[5] << 14) |\n                   (d[6] << 6) |\n                   (d[7] >>> 2);\n\n          size *= 4;\n          size += d[7] & 0x03;\n          frame.timeStamp = size;\n          this.trigger('timestamp', frame);\n        }\n      }\n      tag.frames.push(frame);\n\n      frameStart += 10; // advance past the frame header\n      frameStart += frameSize; // advance past the frame body\n    } while (frameStart < tagSize);\n    this.trigger('data', tag);\n  };\n};\nMetadataStream.prototype = new Stream();\n\nmodule.exports = MetadataStream;\n",
    "'use strict';\n\nmodule.exports = {\n  H264_STREAM_TYPE: 0x1B,\n  ADTS_STREAM_TYPE: 0x0F,\n  METADATA_STREAM_TYPE: 0x15\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) 2016 Brightcove\n * All rights reserved.\n *\n * Accepts program elementary stream (PES) data events and corrects\n * decode and presentation time stamps to account for a rollover\n * of the 33 bit value.\n */\n\n'use strict';\n\nvar Stream = require('../utils/stream');\n\nvar MAX_TS = 8589934592;\n\nvar RO_THRESH = 4294967296;\n\nvar handleRollover = function(value, reference) {\n  var direction = 1;\n\n  if (value > reference) {\n    // If the current timestamp value is greater than our reference timestamp and we detect a\n    // timestamp rollover, this means the roll over is happening in the opposite direction.\n    // Example scenario: Enter a long stream/video just after a rollover occurred. The reference\n    // point will be set to a small number, e.g. 1. The user then seeks backwards over the\n    // rollover point. In loading this segment, the timestamp values will be very large,\n    // e.g. 2^33 - 1. Since this comes before the data we loaded previously, we want to adjust\n    // the time stamp to be `value - 2^33`.\n    direction = -1;\n  }\n\n  // Note: A seek forwards or back that is greater than the RO_THRESH (2^32, ~13 hours) will\n  // cause an incorrect adjustment.\n  while (Math.abs(reference - value) > RO_THRESH) {\n    value += (direction * MAX_TS);\n  }\n\n  return value;\n};\n\nvar TimestampRolloverStream = function(type) {\n  var lastDTS, referenceDTS;\n\n  TimestampRolloverStream.prototype.init.call(this);\n\n  this.type_ = type;\n\n  this.push = function(data) {\n    if (data.type !== this.type_) {\n      return;\n    }\n\n    if (referenceDTS === undefined) {\n      referenceDTS = data.dts;\n    }\n\n    data.dts = handleRollover(data.dts, referenceDTS);\n    data.pts = handleRollover(data.pts, referenceDTS);\n\n    lastDTS = data.dts;\n\n    this.trigger('data', data);\n  };\n\n  this.flush = function() {\n    referenceDTS = lastDTS;\n    this.trigger('done');\n  };\n\n};\n\nTimestampRolloverStream.prototype = new Stream();\n\nmodule.exports = {\n  TimestampRolloverStream: TimestampRolloverStream,\n  handleRollover: handleRollover\n};\n",
    "module.exports = {\n  generator: require('./mp4-generator'),\n  Transmuxer: require('./transmuxer').Transmuxer,\n  AudioSegmentStream: require('./transmuxer').AudioSegmentStream,\n  VideoSegmentStream: require('./transmuxer').VideoSegmentStream,\n  tools: require('../tools/mp4-inspector'),\n  MP4ParserStream: require('./mp4-parser').MP4ParserStream,\n  MP4BuilderStream: require('./mp4-parser').MP4BuilderStream,\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) 2015 Brightcove\n * All rights reserved.\n *\n * Functions that generate fragmented MP4s suitable for use with Media\n * Source Extensions.\n */\n'use strict';\n\nvar UINT32_MAX = Math.pow(2, 32) - 1;\nvar box, cslg, dinf, esds, ftyp, edts, elst, mdat, mfhd, minf, moof, moov,\n    mvex, mvhd, trak, tkhd, mdia, mdhd, hdlr, sdtp, stbl, stsd, styp, traf,\n    trep, trex, trun, types, MAJOR_BRAND, MINOR_VERSION, AVC1_BRAND,\n    VIDEO_HDLR, AUDIO_HDLR, HDLR_TYPES, VMHD, SMHD, DREF, STCO, STSC, STSZ,\n    STTS, Uint8Array, DataView;\n\nUint8Array = window.Uint8Array;\nDataView = window.DataView;\n\n// pre-calculate constants\n(function() {\n  var i;\n  types = {\n    avc1: [], // codingname\n    avcC: [],\n    btrt: [],\n    cslg: [],\n    dinf: [],\n    dref: [],\n    edts: [],\n    elst: [],\n    esds: [],\n    ftyp: [],\n    hdlr: [],\n    mdat: [],\n    mdhd: [],\n    mdia: [],\n    mfhd: [],\n    minf: [],\n    moof: [],\n    moov: [],\n    mp4a: [], // codingname\n    mvex: [],\n    mvhd: [],\n    sdtp: [],\n    smhd: [],\n    stbl: [],\n    stco: [],\n    stsc: [],\n    stsd: [],\n    stsz: [],\n    stts: [],\n    styp: [],\n    tfdt: [],\n    tfhd: [],\n    traf: [],\n    trak: [],\n    trun: [],\n    trep: [],\n    trex: [],\n    tkhd: [],\n    vmhd: []\n  };\n\n  // In environments where Uint8Array is undefined (e.g., IE8), skip set up so that we\n  // don't throw an error\n  if (typeof Uint8Array === 'undefined') {\n    return;\n  }\n\n  for (i in types) {\n    if (types.hasOwnProperty(i)) {\n      types[i] = [\n        i.charCodeAt(0),\n        i.charCodeAt(1),\n        i.charCodeAt(2),\n        i.charCodeAt(3)\n      ];\n    }\n  }\n\n  MAJOR_BRAND = new Uint8Array([\n    'i'.charCodeAt(0),\n    's'.charCodeAt(0),\n    'o'.charCodeAt(0),\n    'm'.charCodeAt(0)\n  ]);\n  AVC1_BRAND = new Uint8Array([\n    'a'.charCodeAt(0),\n    'v'.charCodeAt(0),\n    'c'.charCodeAt(0),\n    '1'.charCodeAt(0)\n  ]);\n  MINOR_VERSION = new Uint8Array([0, 0, 0, 1]);\n  VIDEO_HDLR = new Uint8Array([\n    0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // pre_defined\n    0x76, 0x69, 0x64, 0x65, // handler_type: 'vide'\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x56, 0x69, 0x64, 0x65,\n    0x6f, 0x48, 0x61, 0x6e,\n    0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'VideoHandler'\n  ]);\n  AUDIO_HDLR = new Uint8Array([\n    0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // pre_defined\n    0x73, 0x6f, 0x75, 0x6e, // handler_type: 'soun'\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x53, 0x6f, 0x75, 0x6e,\n    0x64, 0x48, 0x61, 0x6e,\n    0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'SoundHandler'\n  ]);\n  HDLR_TYPES = {\n    video: VIDEO_HDLR,\n    audio: AUDIO_HDLR\n  };\n  DREF = new Uint8Array([\n    0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x01, // entry_count\n    0x00, 0x00, 0x00, 0x0c, // entry_size\n    0x75, 0x72, 0x6c, 0x20, // 'url' type\n    0x00, // version 0\n    0x00, 0x00, 0x01 // entry_flags\n  ]);\n  SMHD = new Uint8Array([\n    0x00,             // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00,       // balance, 0 means centered\n    0x00, 0x00        // reserved\n  ]);\n  STCO = new Uint8Array([\n    0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00 // entry_count\n  ]);\n  STSC = STCO;\n  STSZ = new Uint8Array([\n    0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // sample_size\n    0x00, 0x00, 0x00, 0x00, // sample_count\n  ]);\n  STTS = STCO;\n  VMHD = new Uint8Array([\n    0x00, // version\n    0x00, 0x00, 0x01, // flags\n    0x00, 0x00, // graphicsmode\n    0x00, 0x00,\n    0x00, 0x00,\n    0x00, 0x00 // opcolor\n  ]);\n}());\n\nfunction uint32_to_arr(num){\n  return [num>>>24&255, num>>>16&255, num>>>8&255, num&255];\n}\n\nfunction uint16_to_arr(num){\n  return [num>>>8&255, num&255];\n}\n\nbox = function(type) {\n  var\n    payload = [],\n    size = 0,\n    i,\n    result,\n    view;\n\n  for (i = 1; i < arguments.length; i++) {\n    payload.push(arguments[i]);\n  }\n\n  i = payload.length;\n\n  // calculate the total size we need to allocate\n  while (i--) {\n    size += payload[i].byteLength;\n  }\n  result = new Uint8Array(size + 8);\n  view = new DataView(result.buffer, result.byteOffset, result.byteLength);\n  view.setUint32(0, result.byteLength);\n  result.set(type, 4);\n\n  // copy the payload into the result\n  for (i = 0, size = 8; i < payload.length; i++) {\n    result.set(payload[i], size);\n    size += payload[i].byteLength;\n  }\n  return result;\n};\n\ncslg = function(cslg) {\n  var obj = {};\n  for (var k in cslg)\n      obj[k] = cslg[k]>>>0;\n  return box(types.cslg, new Uint8Array([\n    0x00, // version\n    0x00, 0x00, 0x00, // flags\n    (obj.ctts_shift >>> 24) & 0xFF,\n    (obj.ctts_shift >>> 16) & 0xFF,\n    (obj.ctts_shift >>>  8) & 0xFF,\n    obj.ctts_shift & 0xFF,\n    (obj.min_ctts >>> 24) & 0xFF,\n    (obj.min_ctts >>> 16) & 0xFF,\n    (obj.min_ctts >>>  8) & 0xFF,\n    obj.min_ctts & 0xFF,\n    (obj.max_ctts >>> 24) & 0xFF,\n    (obj.max_ctts >>> 16) & 0xFF,\n    (obj.max_ctts >>>  8) & 0xFF,\n    obj.max_ctts & 0xFF,\n    (obj.min_cts >>> 24) & 0xFF,\n    (obj.min_cts >>> 16) & 0xFF,\n    (obj.min_cts >>>  8) & 0xFF,\n    obj.min_cts & 0xFF,\n    (obj.max_cts >>> 24) & 0xFF,\n    (obj.max_cts >>> 16) & 0xFF,\n    (obj.max_cts >>>  8) & 0xFF,\n    obj.max_cts & 0xFF,\n  ]));\n};\n\ndinf = function() {\n  return box(types.dinf, box(types.dref, DREF));\n};\n\nedts = function(track) {\n  return box(types.edts, elst(track));\n};\n\nelst = function(track) {\n  var count = track.edit_list.length, i;\n  var bytes = [\n    0x00, // version\n    0x00, 0x00, 0x00\n  ].concat(uint32_to_arr(count)); // entries count\n  for (i = 0; i < count; i++)\n  {\n    bytes = bytes.concat(uint32_to_arr(track.edit_list[i].segment_duration))\n    .concat(uint32_to_arr(track.edit_list[i].media_time))\n    .concat(uint16_to_arr(track.edit_list[i].media_rate))\n    .concat(uint16_to_arr(0)); // reserved\n  }\n  return box(types.elst, new Uint8Array(bytes));\n};\n\nesds = function(track) {\n  return box(types.esds, new Uint8Array([\n    0x00, // version\n    0x00, 0x00, 0x00, // flags\n\n    // ES_Descriptor\n    0x03, // tag, ES_DescrTag\n    0x19, // length\n    0x00, 0x00, // ES_ID\n    0x00, // streamDependenceFlag, URL_flag, reserved, streamPriority\n\n    // DecoderConfigDescriptor\n    0x04, // tag, DecoderConfigDescrTag\n    0x11, // length\n    0x40, // object type\n    0x15,  // streamType\n    0x00, 0x06, 0x00, // bufferSizeDB\n    0x00, 0x00, 0xda, 0xc0, // maxBitrate\n    0x00, 0x00, 0xda, 0xc0, // avgBitrate\n\n    // DecoderSpecificInfo\n    0x05, // tag, DecoderSpecificInfoTag\n    0x02, // length\n    // ISO/IEC 14496-3, AudioSpecificConfig\n    // for samplingFrequencyIndex see ISO/IEC 13818-7:2006, 8.1.3.2.2, Table 35\n    (track.audioobjecttype << 3) | (track.samplingfrequencyindex >>> 1),\n    (track.samplingfrequencyindex << 7) | (track.channelcount << 3),\n    0x06, 0x01, 0x02 // GASpecificConfig\n  ]));\n};\n\nftyp = function(opt) {\n    opt = opt||{};\n    var params = opt.compatible||[MAJOR_BRAND, AVC1_BRAND];\n    params = params.slice(0);\n    params.unshift(types.ftyp, opt.major||MAJOR_BRAND, MINOR_VERSION);\n    return box.apply(null, params);\n};\n\nhdlr = function(type) {\n  return box(types.hdlr, HDLR_TYPES[type]);\n};\nmdat = function(data) {\n  return box(types.mdat, data);\n};\nmdhd = function(track) {\n  var result = new Uint8Array([\n    0x00,                   // version 0\n    0x00, 0x00, 0x00,       // flags\n    0x00, 0x00, 0x00, 0x02, // creation_time\n    0x00, 0x00, 0x00, 0x03, // modification_time\n    0x00, 0x01, 0x5f, 0x90, // timescale, 90,000 \"ticks\" per second\n\n    (track.duration >>> 24) & 0xFF,\n    (track.duration >>> 16) & 0xFF,\n    (track.duration >>>  8) & 0xFF,\n    track.duration & 0xFF,  // duration\n    0x55, 0xc4,             // 'und' language (undetermined)\n    0x00, 0x00\n  ]);\n\n  // Use the sample rate from the track metadata, when it is\n  // defined. The sample rate can be parsed out of an ADTS header, for\n  // instance.\n  if (track.samplerate) {\n    result[12] = (track.samplerate >>> 24) & 0xFF;\n    result[13] = (track.samplerate >>> 16) & 0xFF;\n    result[14] = (track.samplerate >>>  8) & 0xFF;\n    result[15] = (track.samplerate)        & 0xFF;\n  }\n\n  return box(types.mdhd, result);\n};\nmdia = function(track) {\n  return box(types.mdia, mdhd(track), hdlr(track.type), minf(track));\n};\nmfhd = function(sequenceNumber) {\n  return box(types.mfhd, new Uint8Array([\n    0x00,\n    0x00, 0x00, 0x00, // flags\n    (sequenceNumber & 0xFF000000) >> 24,\n    (sequenceNumber & 0xFF0000) >> 16,\n    (sequenceNumber & 0xFF00) >> 8,\n    sequenceNumber & 0xFF, // sequence_number\n  ]));\n};\nminf = function(track) {\n  return box(types.minf,\n    track.type === 'video' ? box(types.vmhd, VMHD) : box(types.smhd, SMHD),\n    dinf(), stbl(track));\n};\nmoof = function(sequenceNumber, tracks, opt) {\n  var\n    trackFragments = [],\n    i = tracks.length;\n  opt = opt||{};\n  // build traf boxes for each track fragment\n  while (i--) {\n    trackFragments[i] = traf(tracks[i], opt);\n  }\n  return box.apply(null, [\n    types.moof,\n    mfhd(sequenceNumber)\n  ].concat(trackFragments));\n};\n/**\n * Returns a movie box.\n * @param tracks {array} the tracks associated with this movie\n * @see ISO/IEC 14496-12:2012(E), section 8.2.1\n */\nmoov = function(tracks, opt) {\n  var\n    i = tracks.length,\n    boxes = [],\n    duration = 0;\n  opt = opt||{};\n  while (i--) {\n    boxes[i] = trak(tracks[i]);\n    if (opt.set_duration) {\n      duration = Math.max(duration,\n        Math.floor(tracks[i].duration*90000/tracks[i].samplerate));\n    }\n  }\n  duration = opt.duration||duration||0xFFFFFFFF;\n  return box.apply(null, [types.moov, mvhd(duration)].concat(boxes)\n    .concat(mvex(tracks)));\n};\nmvex = function(tracks) {\n  var\n    i = tracks.length,\n    boxes = [];\n\n  while (i--) {\n    boxes[i] = trex(tracks[i]);\n    if (tracks[i].cslg && tracks[i].cslg.max_cts) {\n      boxes.push(trep(tracks[i]));\n    }\n  }\n  return box.apply(null, [types.mvex].concat(boxes));\n};\nmvhd = function(duration) {\n  var\n    bytes = new Uint8Array([\n      0x00, // version 0\n      0x00, 0x00, 0x00, // flags\n      0x00, 0x00, 0x00, 0x01, // creation_time\n      0x00, 0x00, 0x00, 0x02, // modification_time\n      0x00, 0x01, 0x5f, 0x90, // timescale, 90,000 \"ticks\" per second\n      (duration & 0xFF000000) >> 24,\n      (duration & 0xFF0000) >> 16,\n      (duration & 0xFF00) >> 8,\n      duration & 0xFF, // duration\n      0x00, 0x01, 0x00, 0x00, // 1.0 rate\n      0x01, 0x00, // 1.0 volume\n      0x00, 0x00, // reserved\n      0x00, 0x00, 0x00, 0x00, // reserved\n      0x00, 0x00, 0x00, 0x00, // reserved\n      0x00, 0x01, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x01, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x40, 0x00, 0x00, 0x00, // transformation: unity matrix\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00, // pre_defined\n      0xff, 0xff, 0xff, 0xff // next_track_ID\n    ]);\n  return box(types.mvhd, bytes);\n};\n\nsdtp = function(track) {\n  var\n    samples = track.samples || [],\n    bytes = new Uint8Array(4 + samples.length),\n    flags,\n    i;\n\n  // leave the full box header (4 bytes) all zero\n\n  // write the sample table\n  for (i = 0; i < samples.length; i++) {\n    flags = samples[i].flags;\n\n    bytes[i + 4] = (flags.isLeading << 6) |\n      (flags.dependsOn << 4) |\n      (flags.isDependedOn << 2) |\n      (flags.hasRedundancy);\n  }\n\n  return box(types.sdtp,\n             bytes);\n};\n\nstbl = function(track) {\n  return box(types.stbl,\n             stsd(track),\n             box(types.stts, STTS),\n             box(types.stsc, STSC),\n             box(types.stsz, STSZ),\n             box(types.stco, STCO));\n};\n\n(function() {\n  var videoSample, audioSample;\n\n  stsd = function(track) {\n\n    return box(types.stsd, new Uint8Array([\n      0x00, // version 0\n      0x00, 0x00, 0x00, // flags\n      0x00, 0x00, 0x00, 0x01\n    ]), track.type === 'video' ? videoSample(track) : audioSample(track));\n  };\n\n  videoSample = function(track) {\n    var\n      sps = track.sps || [],\n      pps = track.pps || [],\n      sequenceParameterSets = [],\n      pictureParameterSets = [],\n      i;\n\n    // assemble the SPSs\n    for (i = 0; i < sps.length; i++) {\n      sequenceParameterSets.push((sps[i].byteLength & 0xFF00) >>> 8);\n      sequenceParameterSets.push((sps[i].byteLength & 0xFF)); // sequenceParameterSetLength\n      sequenceParameterSets = sequenceParameterSets.concat(Array.prototype.slice.call(sps[i])); // SPS\n    }\n\n    // assemble the PPSs\n    for (i = 0; i < pps.length; i++) {\n      pictureParameterSets.push((pps[i].byteLength & 0xFF00) >>> 8);\n      pictureParameterSets.push((pps[i].byteLength & 0xFF));\n      pictureParameterSets = pictureParameterSets.concat(Array.prototype.slice.call(pps[i]));\n    }\n\n    return box(types.avc1, new Uint8Array([\n      0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, // reserved\n      0x00, 0x01, // data_reference_index\n      0x00, 0x00, // pre_defined\n      0x00, 0x00, // reserved\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00, // pre_defined\n      (track.width & 0xff00) >> 8,\n      track.width & 0xff, // width\n      (track.height & 0xff00) >> 8,\n      track.height & 0xff, // height\n      0x00, 0x48, 0x00, 0x00, // horizresolution\n      0x00, 0x48, 0x00, 0x00, // vertresolution\n      0x00, 0x00, 0x00, 0x00, // reserved\n      0x00, 0x01, // frame_count\n      0x13,\n      0x76, 0x69, 0x64, 0x65,\n      0x6f, 0x6a, 0x73, 0x2d,\n      0x63, 0x6f, 0x6e, 0x74,\n      0x72, 0x69, 0x62, 0x2d,\n      0x68, 0x6c, 0x73, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, // compressorname\n      0x00, 0x18, // depth = 24\n      0x11, 0x11 // pre_defined = -1\n    ]), box(types.avcC, new Uint8Array([\n      0x01, // configurationVersion\n      track.profileIdc, // AVCProfileIndication\n      track.profileCompatibility, // profile_compatibility\n      track.levelIdc, // AVCLevelIndication\n      0xff // lengthSizeMinusOne, hard-coded to 4 bytes\n    ].concat([\n      sps.length|0xE0 // reserved (high 3 bits) | numOfSequenceParameterSets\n    ]).concat(sequenceParameterSets).concat([\n      pps.length // numOfPictureParameterSets\n    ]).concat(pictureParameterSets))), // \"PPS\"\n            box(types.btrt, new Uint8Array([\n              0x00, 0x1c, 0x9c, 0x80, // bufferSizeDB\n              0x00, 0x2d, 0xc6, 0xc0, // maxBitrate\n              0x00, 0x2d, 0xc6, 0xc0\n            ])) // avgBitrate\n              );\n  };\n\n  audioSample = function(track) {\n    return box(types.mp4a, new Uint8Array([\n\n      // SampleEntry, ISO/IEC 14496-12\n      0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, // reserved\n      0x00, 0x01, // data_reference_index\n\n      // AudioSampleEntry, ISO/IEC 14496-12\n      0x00, 0x00, 0x00, 0x00, // reserved\n      0x00, 0x00, 0x00, 0x00, // reserved\n      (track.channelcount & 0xff00) >> 8,\n      (track.channelcount & 0xff), // channelcount\n\n      (track.samplesize & 0xff00) >> 8,\n      (track.samplesize & 0xff), // samplesize\n      0x00, 0x00, // pre_defined\n      0x00, 0x00, // reserved\n\n      (track.samplerate & 0xff00) >> 8,\n      (track.samplerate & 0xff),\n      0x00, 0x00 // samplerate, 16.16\n\n      // MP4AudioSampleEntry, ISO/IEC 14496-14\n    ]), esds(track));\n  };\n}());\n\nstyp = function() {\n  return box(types.styp, MAJOR_BRAND, MINOR_VERSION, MAJOR_BRAND);\n};\n\ntkhd = function(track) {\n  var duration = track.duration;\n  if (track.samplerate) {\n    // tkhd duration should be in movie scale\n    duration = Math.floor(duration*90000/track.samplerate);\n  }\n  var result = new Uint8Array([\n    0x00, // version 0\n    0x00, 0x00, 0x07, // flags\n    0x00, 0x00, 0x00, 0x00, // creation_time\n    0x00, 0x00, 0x00, 0x00, // modification_time\n    (track.id & 0xFF000000) >> 24,\n    (track.id & 0xFF0000) >> 16,\n    (track.id & 0xFF00) >> 8,\n    track.id & 0xFF, // track_ID\n    0x00, 0x00, 0x00, 0x00, // reserved\n    (track.duration & 0xFF000000) >> 24,\n    (track.duration & 0xFF0000) >> 16,\n    (track.duration & 0xFF00) >> 8,\n    track.duration & 0xFF, // duration\n    0x00, 0x00, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, // layer\n    0x00, 0x00, // alternate_group\n    +(track.type=='audio'), 0x00, // non-audio track volume\n    0x00, 0x00, // reserved\n    0x00, 0x01, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00,\n    0x00, 0x01, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00,\n    0x40, 0x00, 0x00, 0x00, // transformation: unity matrix\n    (track.width & 0xFF00) >> 8,\n    track.width & 0xFF,\n    0x00, 0x00, // width\n    (track.height & 0xFF00) >> 8,\n    track.height & 0xFF,\n    0x00, 0x00 // height\n  ]);\n\n  return box(types.tkhd, result);\n};\n\n/**\n * Generate a track fragment (traf) box. A traf box collects metadata\n * about tracks in a movie fragment (moof) box.\n */\ntraf = function(track, opt) {\n  var trackFragmentHeader, trackFragmentDecodeTime,\n      trackFragmentRun, sampleDependencyTable, dataOffset,\n      upperWordBaseMediaDecodeTime, lowerWordBaseMediaDecodeTime;\n  opt = opt||{};\n  trackFragmentHeader = box(types.tfhd, new Uint8Array([\n    0x00, // version 0\n    opt.no_multi_init ? 0x02 : 0x00, 0x00, 0x3a, // flags\n    (track.id & 0xFF000000) >> 24,\n    (track.id & 0xFF0000) >> 16,\n    (track.id & 0xFF00) >> 8,\n    (track.id & 0xFF), // track_ID\n    0x00, 0x00, 0x00, 0x01, // sample_description_index\n    0x00, 0x00, 0x00, 0x00, // default_sample_duration\n    0x00, 0x00, 0x00, 0x00, // default_sample_size\n    0x00, 0x00, 0x00, 0x00  // default_sample_flags\n  ]));\n\n  upperWordBaseMediaDecodeTime = Math.floor(track.baseMediaDecodeTime / (UINT32_MAX + 1));\n  lowerWordBaseMediaDecodeTime = Math.floor(track.baseMediaDecodeTime % (UINT32_MAX + 1));\n  trackFragmentDecodeTime = box(types.tfdt, new Uint8Array([\n    0x01, // version 1\n    0x00, 0x00, 0x00, // flags\n    // baseMediaDecodeTime\n    (upperWordBaseMediaDecodeTime >>> 24) & 0xFF,\n    (upperWordBaseMediaDecodeTime >>> 16) & 0xFF,\n    (upperWordBaseMediaDecodeTime >>>  8) & 0xFF,\n    upperWordBaseMediaDecodeTime & 0xFF,\n    (lowerWordBaseMediaDecodeTime >>> 24) & 0xFF,\n    (lowerWordBaseMediaDecodeTime >>> 16) & 0xFF,\n    (lowerWordBaseMediaDecodeTime >>>  8) & 0xFF,\n    lowerWordBaseMediaDecodeTime & 0xFF\n  ]));\n\n  // the data offset specifies the number of bytes from the start of\n  // the containing moof to the first payload byte of the associated\n  // mdat\n  dataOffset = (32 + // tfhd\n                20 + // tfdt\n                8 +  // traf header\n                16 + // mfhd\n                8 +  // moof header\n                8);  // mdat header\n\n  // audio tracks require less metadata\n  if (track.type === 'audio') {\n    trackFragmentRun = trun(track, dataOffset);\n    return box(types.traf,\n               trackFragmentHeader,\n               trackFragmentDecodeTime,\n               trackFragmentRun);\n  }\n\n  // video tracks should contain an independent and disposable samples\n  // box (sdtp)\n  // generate one and adjust offsets to match\n  sampleDependencyTable = sdtp(track);\n  trackFragmentRun = trun(track,\n                          sampleDependencyTable.length + dataOffset);\n  return box(types.traf,\n             trackFragmentHeader,\n             trackFragmentDecodeTime,\n             trackFragmentRun,\n             sampleDependencyTable);\n};\n\n/**\n * Generate a track box.\n * @param track {object} a track definition\n * @return {Uint8Array} the track box\n */\ntrak = function(track) {\n  track.duration = track.duration || 0xffffffff;\n  var param = [types.trak, tkhd(track), mdia(track)];\n  if (track.edit_list && track.edit_list.length)\n      param.splice(2, 0, edts(track));\n  return box.apply(null, param);\n};\n\ntrep = function(track){\n  return box(types.trep, new Uint8Array([\n    0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    (track.id & 0xFF000000) >> 24,\n    (track.id & 0xFF0000) >> 16,\n    (track.id & 0xFF00) >> 8,\n    (track.id & 0xFF), // track_ID\n  ]), cslg(track.cslg));\n};\n\ntrex = function(track) {\n  var result = new Uint8Array([\n    0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    (track.id & 0xFF000000) >> 24,\n    (track.id & 0xFF0000) >> 16,\n    (track.id & 0xFF00) >> 8,\n    (track.id & 0xFF), // track_ID\n    0x00, 0x00, 0x00, 0x01, // default_sample_description_index\n    0x00, 0x00, 0x00, 0x00, // default_sample_duration\n    0x00, 0x00, 0x00, 0x00, // default_sample_size\n    0x00, 0x01, 0x00, 0x01 // default_sample_flags\n  ]);\n  // the last two bytes of default_sample_flags is the sample\n  // degradation priority, a hint about the importance of this sample\n  // relative to others. Lower the degradation priority for all sample\n  // types other than video.\n  if (track.type !== 'video') {\n    result[result.length - 1] = 0x00;\n  }\n\n  return box(types.trex, result);\n};\n\ntrun = function(track, offset) {\n  function get_flags(sample){\n    return ('duration' in sample&&0x1)|('size' in sample&&0x2)|\n        ('flags' in sample&&0x4)|('compositionTimeOffset' in sample&&0x8);\n  }\n  function trun_header(samples, offset, flags) {\n    return [\n      0x00, // version 0\n      0x00,\n      flags,\n      0x01, // flags\n      (samples.length & 0xFF000000) >>> 24,\n      (samples.length & 0xFF0000) >>> 16,\n      (samples.length & 0xFF00) >>> 8,\n      samples.length & 0xFF, // sample_count\n      (offset & 0xFF000000) >>> 24,\n      (offset & 0xFF0000) >>> 16,\n      (offset & 0xFF00) >>> 8,\n      offset & 0xFF // data_offset\n    ];\n  }\n  var samples = track.samples||[];\n  var flags = get_flags(samples[0]||{});\n  offset += 20+4*samples.length*((flags>>3&1)+(flags>>2&1)+(flags>>1&1)+\n    (flags&1));\n  var bytes = trun_header(samples, offset, flags);\n  var was_neg = false;\n  for (var i=0; i<samples.length; i++) {\n    var sample = samples[i];\n    if (flags&1){\n      bytes.push(sample.duration>>24&0xFF, sample.duration>>16&0xFF,\n        sample.duration>>8&0xFF, sample.duration&0xFF); // sample_duration\n    }\n    if (flags&2){\n      bytes.push(sample.size>>24&0xFF, sample.size>>16&0xFF,\n        sample.size>>8&0xFF, sample.size&0xFF); // sample_size\n    }\n    if (flags&4){\n      bytes.push(sample.flags.isLeading<<2|sample.flags.dependsOn,\n        sample.flags.isDependedOn<<6|sample.flags.hasRedundancy<<4|\n        sample.flags.paddingValue<<1|sample.flags.isNonSyncSample,\n        sample.flags.degradationPriority>>8&0xFF,\n        sample.flags.degradationPriority&0xFF); // sample_flags\n    }\n    if (flags&8){\n      was_neg = was_neg||sample.compositionTimeOffset<0;\n      bytes.push(sample.compositionTimeOffset>>24&0xFF,\n        sample.compositionTimeOffset>>16&0xFF,\n        sample.compositionTimeOffset>>8&0xFF,\n        sample.compositionTimeOffset&0xFF); // sample_composition_time_offset\n    }\n  }\n  bytes[0] = +!!was_neg;\n  return box(types.trun, new Uint8Array(bytes));\n};\n\nmodule.exports = {\n  ftyp: ftyp,\n  mdat: mdat,\n  moof: moof,\n  moov: moov,\n  initSegment: function(tracks, opt) {\n    var\n      fileType = ftyp(opt),\n      movie = moov(tracks, opt),\n      result;\n\n    result = new Uint8Array(fileType.byteLength + movie.byteLength);\n    result.set(fileType);\n    result.set(movie, fileType.byteLength);\n    return result;\n  }\n};\n",
    "'use strict';\n\nvar Stream = require('../utils/stream.js');\nvar mp4 = require('./mp4-generator.js');\nvar sample_type={vide: 'video', soun: 'audio'};\nvar full_box = ['meta', 'mvhd', 'tkhd', 'mdhd', 'smhd', 'vmhd', 'dref',\n    'hdlr', 'stsd', 'esds', 'stts', 'stps', 'stss', 'ctts', 'stsc', 'stsz',\n    'stco', 'esds', 'elst', 'nmhd', 'cslg', 'sdtp', 'co64'];\nvar raw_copy = ['udta', 'smhd', 'vmhd', 'dref', 'iods', 'btrt', 'pasp', 'clap',\n    'uuid', 'colr', 'sbgp', 'sgpd', 'gmhd', 'tref', 'nmhd', 'svcC', 'hmhd',\n    'wide', 'fiel', 'tapt', 'load', 'meta', 'sefd', 'beam'];\nvar containers = {\n    trak: {name: 'track_info', multi: 1},\n    edts: {name: 'edit_list'},\n    exts: {name: 'edit_list'},\n    mdia: {name: 'media_box'},\n    minf: {name: 'media_info'},\n    dinf: {name: 'data_info'},\n    stbl: {name: 'sample_table'},\n};\nfunction byte_to_hex(bt){ return ('0'+bt.toString(16)).slice(-2); }\nfunction int_to_str(tp){\n    return String.fromCharCode(tp>>24&255, tp>>16&255, tp>>8&255, tp&255); }\nfunction getUint64(view, ptr){\n    return view.getUint32(ptr+4)+view.getUint32(ptr)*0x100000000; }\nfunction getInt64(view, ptr){\n    var hib = view.getUint8(ptr);\n    if (hib<128)\n        return getUint64(view, ptr);\n    return view.getUint32(ptr+4)+0x100000000*(view.getUint32(ptr)-0x100000000);\n}\nfunction Bit_reader(view, ptr, size){\n    var pos = 0, len = size*8;\n    this.read = function(count, peek){\n        var ret = 0, p = pos>>3, r = 7-pos%8;\n        for (var i = 0, c = view.getUint8(p+ptr); i<count; i++, r--)\n        {\n            ret = (ret<<1)|((c>>r)&1);\n            if (r)\n                continue;\n            p++;\n            r = 8;\n            c = view.getUint8(p+ptr);\n        }\n        if (!peek)\n            pos += count;\n        return ret;\n    };\n    this.bits = function(){ return len-pos; };\n}\nvar Box_parser = function(){};\nBox_parser.prototype = {};\nBox_parser.prototype.header = function(opt){\n    while (opt.ptr+opt.buffer.b_pos>=opt.branch.last)\n    {\n        if (opt.branch._id=='movie_box')\n            opt.root.h_parsed = true;\n        opt.branch = opt.branch.parent;\n    }\n    opt.type = null;\n    opt.offset = 8;\n    if (opt.buffer.b_size-opt.ptr<8)\n        return (opt.offset = 0);\n    opt.size = opt.view.getUint32(opt.ptr);\n    if (opt.size==1)\n    {\n        opt.offset = 16;\n        if (opt.buffer.b_size-opt.ptr<16)\n            return (opt.offset = 0);\n        opt.size = (opt.view.getUint32(opt.ptr+8)<<32)+\n            opt.view.getUint32(opt.ptr+12);\n    }\n    opt.type = int_to_str(opt.view.getUint32(opt.ptr+4));\n    if (full_box.includes(opt.type))\n    {\n        opt.offset += 4;\n        if (opt.buffer.b_size-opt.ptr<opt.offset)\n            return (opt.offset = 0);\n        var extra = opt.view.getUint8(opt.ptr+opt.offset-4);\n        opt.ver = extra>>>24;\n        opt.flags = extra&&0xFFFFFF;\n    }\n    opt.size -= opt.offset;\n    opt.ptr += opt.offset;\n};\nBox_parser.prototype.parse = function(opt){\n    if (!this[opt.type])\n        throw new Error('Unknown box type: '+opt.type);\n    this[opt.type](opt);\n};\nraw_copy.forEach(function(cont){\n    Box_parser.prototype[cont] = function(opt){\n        var data = opt.branch[cont] = new Uint8Array(opt.size);\n        data.set(opt.buffer._buff.subarray(opt.ptr, opt.ptr+opt.size));\n    };\n});\nObject.keys(containers).forEach(function(cont){\n    Box_parser.prototype[cont] = function(opt){\n        var elm = containers[cont];\n        opt.branch[elm.name] = opt.branch[elm.name]||(elm.multi ? [] : {});\n        var new_branch = opt.branch[elm.name];\n        if (elm.multi)\n        {\n            new_branch.push({});\n            new_branch = new_branch[new_branch.length-1];\n        }\n        new_branch.parent = opt.branch;\n        new_branch.last = opt.buffer.b_pos+opt.ptr+opt.size;\n        new_branch._id = elm.name;\n        opt.branch = new_branch;\n        opt.size = 0;\n    };\n});\nBox_parser.prototype.moov = function(opt){\n    var new_branch = opt.branch.movie_box = opt.branch.movie_box||{};\n    new_branch.parent = opt.branch;\n    new_branch.last = opt.buffer.b_pos+opt.ptr+opt.size;\n    new_branch._id = 'movie_box';\n    // only ftyp can exist prior to moov in a file beginning\n    if (opt.buffer.b_pos<256)\n        opt.branch.start_hdr_sz = opt.size;\n    else\n        opt.branch.end_hdr_sz = opt.size;\n    opt.branch = new_branch;\n    opt.size = 0;\n};\nfunction get_hd_times(opt){\n    var view = opt.view, ptr = opt.ptr, is_tk = opt.type=='tkhd';\n    if (!opt.ver)\n    {\n        return [view.getUint32(ptr), view.getUint32(ptr+4),\n            view.getUint32(ptr+8), view.getUint32(ptr+(is_tk ? 16 : 12))];\n    }\n    return [getUint64(view, ptr), getUint64(view, ptr+8),\n        view.getUint32(ptr+16), getUint64(view, ptr+(is_tk ? 24 : 20))];\n\n}\nfunction get_table(view, ptr, cnt, tbl){\n    for (var i=0; i<cnt; i++)\n        tbl[i] = view.getUint32(ptr+i*4);\n}\nBox_parser.prototype.ftyp = function(opt){\n    opt.branch.major_brand = int_to_str(opt.view.getUint32(opt.ptr));\n    opt.branch.minor_version = opt.view.getUint32(opt.ptr+4);\n    opt.branch.compatible = [opt.branch.major_brand];\n    for (var i=8; i<opt.size; i+=4)\n        opt.branch.compatible.push(int_to_str(opt.view.getUint32(opt.ptr+i)));\n};\nBox_parser.prototype.mdat = function(){};\nBox_parser.prototype.free = function(){};\nBox_parser.prototype.mvhd = function(opt){\n    var view = opt.view, ptr = opt.ptr;\n    var offset = opt.ver ? 28 : 16;\n    var hdr = opt.branch.mv_hdr = {};\n    var times = get_hd_times(opt);\n    hdr.creation_time = times[0];\n    hdr.modification_time = times[1];\n    hdr.time_scale = times[2];\n    hdr.duration = times[3];\n    ptr += offset;\n    hdr.rate = view.getUint32(ptr)/65536.0;\n    hdr.volume = view.getUint16(ptr+4)/256.0;\n    get_table(opt.view, ptr+16, 9, hdr.matrix = []);\n    hdr.next_track = view.getUint32(ptr+76);\n};\nBox_parser.prototype.tkhd = function(opt){\n    var view = opt.view, ptr = opt.ptr;\n    var offset = opt.ver ? 40 : 28;\n    var hdr = opt.branch.tk_hdr = {};\n    var times = get_hd_times(opt);\n    hdr.enabled = !!(opt.flags&1);\n    hdr.in_movie = !!(opt.flags&2);\n    hdr.in_preview = !!(opt.flags&4);\n    hdr.creation_time = times[0];\n    hdr.modification_time = times[1];\n    hdr.track_id = times[2];\n    hdr.duration = times[3];\n    ptr += offset;\n    hdr.layer = view.getUint16(ptr);\n    hdr.alternate_group = view.getUint16(ptr+2);\n    hdr.volume = view.getInt16(ptr+4)/256.0;\n    get_table(opt.view, ptr+8, 9, hdr.matrix = []);\n    hdr.width = view.getUint32(ptr+44)/65536.0;\n    hdr.height = view.getUint32(ptr+48)/65536.0;\n};\nBox_parser.prototype.mdhd = function(opt){\n    var view = opt.view, ptr = opt.ptr;\n    var offset = opt.ver ? 28 : 16;\n    var hdr = opt.branch.md_hdr = {};\n    var times = get_hd_times(opt);\n    hdr.creation_time = times[0];\n    hdr.modification_time = times[1];\n    hdr.time_scale = times[2];\n    hdr.duration = times[3];\n    var lang = view.getUint16(ptr+offset);\n    hdr.lang = String.fromCharCode(lang>>10|96, lang>>5&31|96, lang&31|96);\n};\nBox_parser.prototype.elst = function(opt){\n    var view = opt.view, ptr = opt.ptr+4;\n    var count = view.getUint32(opt.ptr);\n    opt.branch.list = [];\n    for (var i=0; i<count; ptr += 4, i++)\n    {\n        var elm = {};\n        elm.segment_duration = opt.ver ?\n            getUint64(view, ptr) : view.getUint32(ptr);\n        elm.media_time = opt.ver ?\n            getInt64(view, ptr+8) : view.getInt32(ptr+4);\n        ptr += opt.ver ? 16 : 8;\n        elm.media_rate = view.getInt16(ptr);\n        opt.branch.list.push(elm);\n    }\n};\nBox_parser.prototype.cslg = function(opt){\n    var view = opt.view, ptr = opt.ptr;\n    opt.branch.cslg = {\n        ctts_shift: view.getInt32(ptr),\n        min_ctts: view.getInt32(ptr+4),\n        max_ctts: view.getInt32(ptr+8),\n        min_cts: view.getInt32(ptr+12),\n        max_cts: view.getInt32(ptr+16),\n    };\n};\nBox_parser.prototype.hdlr = function(opt){\n    opt.branch.handler = int_to_str(opt.view.getUint32(opt.ptr+4)); };\nBox_parser.prototype._parse_avcc = function(opt, elm){\n    var view = opt.view, ptr = opt.ptr;\n    var sps = elm.sps = [];\n    var pps = elm.pps = [];\n    elm.avc_p_i = view.getUint8(ptr+1);\n    elm.prof_compat = view.getUint8(ptr+2);\n    elm.avc_l_i = view.getUint8(ptr+3);\n    elm.l_size_m_1 = view.getUint8(ptr+4)&3;\n    elm.n_sps = view.getUint8(ptr+5)&31;\n    var offset = 6;\n    for (var i=0; i<elm.n_sps; i++)\n    {\n        sps[i] = {l: view.getUint16(ptr+offset)};\n        offset += 2;\n        sps[i].nal = new Uint8Array(opt.buffer._buff.subarray(ptr+offset,\n            ptr+offset+sps[i].l));\n        offset += sps[i].l;\n    }\n    elm.n_pps = view.getUint8(ptr+offset++);\n    for (i=0; i<elm.n_pps; i++)\n    {\n        pps[i] = {l: view.getUint16(ptr+offset)};\n        offset += 2;\n        pps[i].nal = new Uint8Array(opt.buffer._buff.subarray(ptr+offset,\n            ptr+offset+pps[i].l));\n        offset += pps[i].l;\n    }\n};\nBox_parser.prototype._parse_esds = function(opt, elm){\n    var view = opt.view, ptr = opt.ptr;\n    while (ptr<opt.ptr+opt.size)\n    {\n        var tag = view.getUint8(ptr++);\n        var sz = 0, sb;\n        do {\n            sb = view.getUint8(ptr++);\n            sz = (sz<<7)+(sb&0x7F);\n        } while (sb&0x80);\n        switch (tag)\n        {\n        case 3: // ES_DescrTag\n            elm.es_id = view.getUint16(ptr);\n            var flags = view.getUint8(ptr+2);\n            ptr += 3+(flags>>6&2)+(flags>>4&2);\n            break;\n        case 4: // DecoderConfigDescrTag\n            elm.obj_t = view.getUint8(ptr);\n            elm.str_t = view.getUint8(ptr+1)&0x3F;\n            ptr += 13;\n            break;\n        case 5: // DecoderSpecificInfoTag\n            var ext_type, br = new Bit_reader(view, ptr, sz);\n            elm.aot = br.read(5);\n            if (elm.aot==31)\n                elm.aot = 32+br.read(6);\n            elm.freq = br.read(4);\n            if (elm.freq==15)\n                elm.freq = br.read(24);\n            elm.channel = br.read(4);\n            // Read ext configuration for explicitly signaled HE-AAC profiles\n            // 5 = HEv1, 29 = HEv2\n            if (elm.aot==5 || elm.aot==29)\n            {\n                ext_type = 5;\n                if ((elm.ext_freq_index = br.read(4))==0xf)\n                    elm.ext_freq = br.read(24);\n                // With HE extensions now known, determine underlying profile.\n                elm.aot = br.read(5);\n                if (elm.aot==31)\n                    elm.aot = 32+br.read(6);\n            }\n            if (ext_type!=5 && elm.aot!=36)\n            {\n                while (br.bits()>=16)\n                {\n                    if (br.read(11, 1)==0x2b7) // sync_ext_type\n                    {\n                        br.read(11);\n                        if (br.read(5)==5) // type_ext\n                        {\n                            if (br.read(1)) // sbr\n                            {\n                                if (br.read(4)==0xf) // sr_ext\n                                    br.read(24);\n                                if (br.bits()>=12 && br.read(11)==0x548 &&\n                                    br.read(1)!=1)\n                                {\n                                    elm.dsi = 5;\n                                }\n                            }\n                        }\n                    }\n                    else\n                        br.read(1);\n                }\n            }\n            ptr += sz;\n            break;\n        default:\n            ptr += sz;\n        }\n    }\n};\nBox_parser.prototype.stsd = function(opt){\n    var view = opt.view, count = view.getUint32(opt.ptr);\n    var handler = opt.branch.parent.parent.handler, i, j;\n    opt.branch.list = {};\n    opt.ptr += 4;\n    for (i=0; i<count; i++)\n    {\n        this.header(opt);\n        var elm = {};\n        var index = view.getUint16(opt.ptr+6);\n        var last_ptr = opt.ptr+opt.size;\n        switch (handler)\n        {\n        case 'vide':\n            elm.width = view.getUint16(opt.ptr+24);\n            elm.height = view.getUint16(opt.ptr+26);\n            elm.h_res = view.getUint32(opt.ptr+28)/65536.0;\n            elm.v_res = view.getUint32(opt.ptr+32)/65536.0;\n            elm.f_count = view.getUint16(opt.ptr+40);\n            elm.compressor = '';\n            for (j=0; j<32; j++)\n            {\n                var c = view.getUint8(opt.ptr+42+j);\n                if (!c)\n                    break;\n                elm.compressor += String.fromCharCode();\n            }\n            elm.depth = view.getUint16(opt.ptr+74);\n            // 'colr', 'clap', 'pasp' & 'fiel'\n            var skip_boxes = [0x636F6C72, 0x636C6170, 0x70617370, 0x6669656C];\n            while (skip_boxes.includes(view.getUint32(opt.ptr+82)))\n                opt.ptr += view.getUint32(opt.ptr+78);\n            if (view.getUint32(opt.ptr+82)==0x61766343) // avcC\n            {\n                elm.avcc = {};\n                opt.ptr += 78;\n                this.header(opt);\n                this._parse_avcc(opt, elm.avcc);\n            }\n            // XXX pavelki: optional boxes\n            break;\n        case 'soun':\n            elm.c_count = view.getUint16(opt.ptr+16);\n            elm.s_size = view.getUint16(opt.ptr+18);\n            elm.s_rate = view.getUint32(opt.ptr+24)/65536.0;\n            for (j=32; j<opt.size-12; j++)\n            {\n                if (view.getUint32(opt.ptr+j)==0x65736473) // esds\n                {\n                    elm.esds = {};\n                    opt.ptr += j-4;\n                    this.header(opt);\n                    this._parse_esds(opt, elm.esds);\n                    break;\n                }\n            }\n            break;\n        default:\n        }\n        opt.ptr = last_ptr;\n        opt.branch.list[index] = elm;\n    }\n    opt.size = 0;\n};\nBox_parser.prototype.stts = function(opt){\n    var cnt = opt.view.getUint32(opt.ptr), ptr = opt.ptr+4;\n    opt.branch.dtts = [];\n    for (var i=0; i<cnt; i++)\n    {\n        var u_cnt = opt.view.getUint32(opt.ptr+4+i*8);\n        var data = opt.view.getUint32(ptr+i*8+4);\n        for (var j=0; j<u_cnt; j++)\n             opt.branch.dtts.push(data);\n    }\n};\nBox_parser.prototype.ctts = function(opt){\n    var cnt = opt.view.getUint32(opt.ptr), ptr = opt.ptr+4;\n    opt.branch.ctts = [];\n    for (var i=0; i<cnt; i++)\n    {\n        var u_cnt = opt.view.getUint32(ptr+i*8);\n        var data = opt.view.getInt32(ptr+i*8+4);\n        for (var j=0; j<u_cnt; j++)\n            opt.branch.ctts.push(data);\n    }\n};\nBox_parser.prototype.stsc = function(opt){\n    var count = opt.view.getUint32(opt.ptr);\n    var table = opt.branch.s_t_c = [];\n    var view = opt.view, ptr = opt.ptr+4;\n    for (var i=0; i<count; i++)\n    {\n        table[i] = {\n            f_c: view.getUint32(ptr+i*12),\n            s_p_c: view.getUint32(ptr+i*12+4),\n            s_d_i: view.getUint32(ptr+i*12+8),\n        };\n    }\n    table.sort(function(c1, c2){ return c1.f_c-c2.f_c; });\n};\nBox_parser.prototype.stss = function(opt){\n    get_table(opt.view, opt.ptr+4, opt.view.getUint32(opt.ptr),\n        opt.branch.s_sync = []);\n};\nBox_parser.prototype.stps = function(opt){\n    get_table(opt.view, opt.ptr+4, opt.view.getUint32(opt.ptr),\n        opt.branch.s_psync = []);\n};\nBox_parser.prototype.sdtp = function(opt){\n    opt.branch.s_dep = [];\n    for (var i=0; i<opt.size; i++)\n    {\n        var bt = opt.view.getUint8(opt.ptr+i);\n        opt.branch.s_dep[i] = {\n            red: bt&3,\n            is_dep: bt>>2&3,\n            dep: bt>>4&3,\n            lead: bt>>6&3,\n        };\n    }\n};\nBox_parser.prototype.stsz = function(opt){\n    var size = opt.view.getUint32(opt.ptr);\n    opt.branch.s_sz = [];\n    opt.branch.s_count = opt.view.getUint32(opt.ptr+4);\n    if (!size)\n        get_table(opt.view, opt.ptr+8, opt.branch.s_count, opt.branch.s_sz);\n    else\n    {\n        for (var i=0; i<opt.branch.s_count; i++)\n            opt.branch.s_sz.push(size);\n    }\n};\nBox_parser.prototype.stco = function(opt){\n    get_table(opt.view, opt.ptr+4, opt.view.getUint32(opt.ptr),\n        opt.branch.c_off = []);\n};\nBox_parser.prototype.co64 = function(opt){\n    var cnt = opt.view.getUint32(opt.ptr);\n    opt.branch.c_off = [];\n    for (var i=0; i<cnt; i++)\n        opt.branch.c_off[i] = getUint64(opt.view, opt.ptr+4+i*8);\n};\n\nvar Chunk_parser = function(opt){\n    this.conf_update(opt);\n};\nChunk_parser.prototype = {};\nChunk_parser.prototype.conf_update = function(conf){\n    this.break_on_count = conf.break_on_count;\n    this.frag_size = conf.frag_size||10;\n};\nChunk_parser.prototype.process = function(opt){\n    var event = {\n        type: 'metadata',\n        tracks: [],\n        brands: ['iso5', 'iso6'],\n        matrix: opt.root.movie_box.mv_hdr.matrix,\n        start_hdr_sz: opt.root.start_hdr_sz,\n        end_hdr_sz: opt.root.end_hdr_sz,\n    };\n    var _this = this;\n    event.duration = Math.floor(opt.root.movie_box.mv_hdr.duration*90000/\n        opt.root.movie_box.mv_hdr.time_scale);\n    event.timescale = 90000;\n    event.s_info = this.s_info = [];\n    event.s_p = this.s_p = [];\n    opt.root.movie_box.track_info.forEach(function(tr){\n        if (!['vide', 'soun'].includes(tr.media_box.handler))\n            return;\n        var elm = {\n            id: tr.tk_hdr.track_id,\n            ts: tr.media_box.md_hdr.time_scale,\n            type: tr.media_box.handler,\n            s_off: [],\n            s_time: [],\n            s_dri: [],\n            s_sync: tr.media_box.media_info.sample_table.s_sync||[],\n            s_psync: tr.media_box.media_info.sample_table.s_psync||[],\n            s_sz: tr.media_box.media_info.sample_table.s_sz,\n            s_dep: tr.media_box.media_info.sample_table.s_dep||[],\n            s_ctts: tr.media_box.media_info.sample_table.ctts||[],\n            s_cslg: tr.media_box.media_info.sample_table.cslg||{},\n            s_list: tr.media_box.media_info.sample_table.list,\n        };\n        if (tr.edit_list && tr.edit_list.list.length)\n            elm.elst = tr.edit_list.list;\n        var c_off = tr.media_box.media_info.sample_table.c_off;\n        var s_t_c = tr.media_box.media_info.sample_table.s_t_c;\n        var dtts = tr.media_box.media_info.sample_table.dtts;\n        var c_n = 1;\n        var sn = 0;\n        var dt = 0;\n        var is_sz_arr = Array.isArray(elm.s_sz);\n        for (var i = 0; i<s_t_c.length; i++)\n        {\n            for (; c_n<(s_t_c[i+1] ? s_t_c[i+1].f_c : c_off.length+1); c_n++)\n            {\n                var off = c_off[c_n-1];\n                for (var j=0; j<s_t_c[i].s_p_c; j++)\n                {\n                    elm.s_off[sn] = off;\n                    elm.s_time[sn] = dt;\n                    elm.s_dri[sn] = s_t_c[i].s_d_i;\n                    dt += dtts[sn];\n                    off += is_sz_arr ? elm.s_sz[sn++] : elm.s_sz;\n                }\n            }\n        }\n        _this.s_info.push(elm);\n        _this.s_p.push({s: 0, max_t: 0});\n        if (elm.type=='vide')\n            event.v_idx = _this.v_idx = _this.s_info.length-1;\n        var dr = elm.s_list[1];\n        var event_elm = {\n            id: elm.id,\n            type: sample_type[elm.type],\n            edit_list: elm.elst,\n            cslg: elm.s_cslg,\n            dr: dr,\n            timelineStartInfo: {baseMediaDecodeTime: 0},\n            bitrate: Math.floor(elm.s_sz.reduce(function(a, b){ return a+b; })*\n                8*elm.ts/tr.media_box.md_hdr.duration),\n            duration: elm.type=='soun' ?\n                tr.media_box.md_hdr.duration :\n                Math.floor(tr.media_box.md_hdr.duration*90000/elm.ts),\n            samplerate: elm.type=='soun' ? elm.ts : 90000,\n            matrix: tr.tk_hdr.matrix,\n            track_width: tr.tk_hdr.width,\n            track_height: tr.tk_hdr.height,\n            nb_samples: elm.s_time.length,\n        };\n        if (elm.type=='soun')\n        {\n            var aot = dr.esds.dsi||dr.esds.aot;\n            event_elm.codec = 'mp4a.'+byte_to_hex(dr.esds.obj_t.toString(16))+\n                (aot ? '.'+aot : '');\n            event_elm.s_i = new Uint8Array([dr.esds.aot<<3|dr.esds.freq>>>1,\n                dr.esds.freq<<7|dr.esds.channel<<3]);\n        }\n        else\n        {\n            event_elm.codec = 'avc1.'+byte_to_hex(dr.avcc.avc_p_i)+\n                byte_to_hex(dr.avcc.prof_compat)+byte_to_hex(dr.avcc.avc_l_i);\n            var info = [1, dr.avcc.avc_p_i, dr.avcc.avc_prof_compat,\n                dr.avcc.avc_l_i, 255, dr.avcc.sps.length+224];\n            dr.avcc.sps.forEach(function(e){\n                info = info.concat([e.nal.length>>8, e.nal.length&255]);\n                Array.prototype.push.apply(info, e.nal);\n            });\n            info.push(dr.avcc.pps.length);\n            dr.avcc.pps.forEach(function(e){\n                info = info.concat([e.nal.length>>8, e.nal.length&255]);\n                Array.prototype.push.apply(info, e.nal);\n            });\n            event_elm.s_i = new Uint8Array(info);\n        }\n        if (event_elm.edit_list)\n        {\n            event_elm.edit_list.forEach(function(e){\n                if (elm.type!='soun')\n                    e.media_time = Math.floor(e.media_time*90000/elm.ts);\n                e.segment_duration = Math.floor(e.segment_duration*90000/\n                    opt.root.movie_box.mv_hdr.time_scale);\n            });\n        }\n        if (event_elm.cslg)\n        {\n            for (var k in event_elm.cslg)\n                event_elm.cslg[k] = Math.floor(event_elm.cslg[k]*90000/elm.ts);\n        }\n        event.tracks.push(event_elm);\n    });\n    opt.stream.trigger('data', event);\n};\nChunk_parser.prototype.parse = function(opt){\n    if (!this.s_info)\n        this.process(opt);\n    var b_start = opt.buffer.b_pos;\n    var b_end = opt.buffer.b_size+b_start;\n    var pc = -1, max_dcd = 0, i;\n    var v_fin = false;\n    while (pc)\n    {\n        pc = 0;\n        for (i=0; i<this.s_p.length; i++)\n        {\n            var sinfo = this.s_info[i];\n            var sn = this.s_p[i].s;\n            var pos = sinfo.s_off[sn];\n            var sz = sinfo.s_sz[sn];\n            var time = sinfo.s_time;\n            if (pos>=b_start && pos+sz<=b_end)\n            {\n                this.s_p[i].s++;\n                pc++;\n                var sample = {trackId: sinfo.id};\n                sample.type = sample_type[sinfo.type];\n                sample.dts = time[sn];\n                sample.pts = sample.dts+(sinfo.s_ctts[sn]||0);\n                sample.duration = sn==time.length-1 ?\n                    time[sn]-time[sn-1] : time[sn+1]-time[sn];\n                sample.size = sz;\n                this.s_p[i].max_t = sample.dts/sinfo.ts;\n                sample.data = opt.buffer._buff.subarray(pos-b_start,\n                    pos+sz-b_start);\n                sample.dr = sinfo.s_list[sinfo.s_dri[sn]];\n                sample.ts = sinfo.ts;\n                sample.synced =  !sinfo.s_sync.length ||\n                    sinfo.s_sync.includes(sn+1);\n                sample.sn = sn;\n                sample.dep = sinfo.s_dep[sn];\n                if (sinfo.type=='vide' && (this.break_on_count ?\n                    sn%this.frag_size===0 : sn&&sample.synced))\n                {\n                    opt.stream.flush();\n                }\n                opt.stream.trigger('data', sample);\n                max_dcd = pos+sz-b_start;\n            }\n            else if (pos+sz>b_end&&i==this.v_idx)\n                v_fin = true;\n        }\n    }\n    if (max_dcd)\n        opt.buffer.advance(max_dcd);\n    var new_pos = Infinity;\n    for (i=0; i<this.s_p.length; i++)\n    {\n        if (this.s_p[i].s==this.s_info[i].s_off.length)\n        {\n            this.s_p[i].finish = true;\n            continue;\n        }\n        new_pos = Math.min(new_pos, this.s_info[i].s_off[this.s_p[i].s]);\n    }\n    if (new_pos==Infinity)\n        opt.stream.flush();\n    if (new_pos==Infinity || new_pos>=b_start&&new_pos<b_end)\n        new_pos = b_end;\n    return new_pos;\n};\nChunk_parser.prototype.seek = function(time, use_ss){\n    if (!this.s_info)\n        throw new Error('No metadata information for seeking');\n    var target = time*90000;\n    var m_pos = Infinity;\n    function get_frame(target, elm, use_ss){\n        var l, r, sn, m, m_time, tt;\n        var i_ss = use_ss&&elm.s_sync.length>0;\n        var i_soun = elm.type=='soun';\n        var scale = elm.ts/90000;\n        l = 0;\n        r = i_ss ? elm.s_sync.length-1 : elm.s_time.length-1;\n        tt = Math.floor(target*scale);\n        while (l<r-1)\n        {\n            m = (l+r)>>1;\n            sn = i_ss ? elm.s_sync[m]-1 : m;\n            if ((m_time = elm.s_time[sn]+(elm.s_ctts[sn]|0))>tt)\n                r = m;\n            else\n            {\n                l = m;\n                if (m_time==tt)\n                    break;\n            }\n        }\n        var res_sn = i_ss ? elm.s_sync[l]-1 : l;\n        tt = m_time = elm.s_time[res_sn]+(elm.s_ctts[res_sn]|0);\n        if (!i_ss&&elm.s_ctts.length)\n        {\n            for (sn=l-1; sn>l-10; sn--)\n            {\n                if (elm.s_time[sn]+(elm.s_ctts[sn]|0)>tt)\n                    res_sn = sn;\n            }\n            for (sn=res_sn; sn<l+10; sn++)\n            {\n                m_time = elm.s_time[sn]+(elm.s_ctts[sn]|0);\n                if (m_time > ((elm.s_cslg&&elm.s_cslg.min_ctts)|0) &&\n                    m_time<tt)\n                {\n                    tt = m_time;\n                }\n            }\n        }\n        return {sn: res_sn, min_t: tt/elm.ts};\n    }\n    if (this.v_idx!==undefined)\n    {\n        var elm = this.s_info[this.v_idx];\n        var v_fr = get_frame(target, elm, use_ss);\n        var v_sn = v_fr.sn;\n        this.s_p[this.v_idx].s = v_sn;\n        this.s_p[this.v_idx].max_t =\n            (elm.s_time[v_sn]+(elm.s_ctts[v_sn]|0))/elm.ts;\n        // sync audio track(s) to video\n        target = v_fr.min_t*90000;\n        m_pos = elm.s_off[v_sn];\n    }\n    var _this = this;\n    this.s_info.forEach(function(elm, idx){\n        if (idx==_this.v_idx)\n            return;\n        var s_sn = get_frame(target, elm, use_ss).sn;\n        _this.s_p[idx].s = s_sn;\n        _this.s_p[idx].max_t = (elm.s_time[s_sn]+(elm.s_ctts[s_sn]|0))/elm.ts;\n        m_pos = Math.min(elm.s_off[s_sn], m_pos);\n    });\n    return {\n        offset: m_pos,\n        time: this.s_p[this.v_idx!==undefined ? this.v_idx : 0].max_t,\n    };\n};\n\nvar Buffer = function(){\n    this._buff = new Uint8Array(3*1048576);\n    this.b_pos = 0;\n    this.b_size = 0;\n    this.pos = 0;\n};\nBuffer.prototype = {};\nBuffer.prototype.advance = function(ptr){\n    this._buff.set(this._buff.subarray(ptr, this.b_size));\n    this.b_pos += ptr;\n    this.b_size -= ptr;\n};\nBuffer.prototype.push = function(chunk){\n    var _newbuff;\n    var c_len = chunk.length;\n    while (c_len+this.b_size>this._buff.length)\n    {\n        _newbuff = new Uint8Array(2*this._buff.length);\n        _newbuff.set(this._buff);\n        this._buff = _newbuff;\n    }\n    if (this.pos<this.b_pos+this.b_size && this.pos+c_len>=this.b_pos)\n    {\n        _newbuff = new Uint8Array(Math.max(this.pos+c_len,\n            this.b_pos+this.b_size)-Math.min(this.pos, this.b_pos));\n        if (this.pos<=this.b_pos)\n        {\n            _newbuff.set(chunk);\n            if (this.pos+c_len<this.b_pos+this.b_size)\n            {\n                _newbuff.set(this._buff.subarray(this.pos+c_len-this.b_pos,\n                    this.b_size), c_len);\n            }\n        }\n        else\n        {\n            _newbuff.set(this._buff.subarray(0, this.pos-this.b_pos));\n            _newbuff.set(chunk, this.pos-this.b_pos);\n        }\n        this._buff.set(_newbuff);\n        this.b_size = _newbuff.length;\n        _newbuff = null;\n        this.b_pos = Math.min(this.b_pos, this.pos);\n    }\n    else if (this.pos==this.b_pos+this.b_size)\n    {\n        this._buff.set(chunk, this.b_size);\n        this.b_size += c_len;\n    }\n    else\n    {\n        this._buff.set(chunk);\n        this.b_size = c_len;\n        this.b_pos = this.pos;\n    }\n    this.view = new DataView(this._buff.buffer, this._buff.byteOffset,\n        this.b_size);\n};\n\nvar MP4ParserStream = function(opt){\n    if (!(this instanceof MP4ParserStream))\n        return new MP4ParserStream(opt);\n    MP4ParserStream.prototype.init.call(this);\n    this.buffer = new Buffer();\n    this.b_parser = new Box_parser();\n    this.c_parser = new Chunk_parser(opt);\n    this.on('confupdate', function(conf){\n        this.c_parser.conf_update(conf);\n    });\n    this.metadata = {};\n    this.buffer.pos = opt.pos||0;\n    if (opt.metadata)\n    {\n        this.metadata.h_parsed = true;\n        this.c_parser.s_info = opt.metadata.s_info.slice();\n        this.c_parser.s_p = opt.metadata.s_p.slice();\n        this.c_parser.v_idx = opt.metadata.v_idx;\n    }\n};\nMP4ParserStream.prototype = new Stream();\nMP4ParserStream.prototype.constructor = MP4ParserStream;\nMP4ParserStream.prototype.get_tl = function(id){\n    if (!this.metadata.h_parsed)\n        throw new Error('No metadata information for time map');\n    var t_i = this.c_parser.s_info.filter(function(e){ return e.id==id; });\n    if (!t_i.length)\n        throw new Error('No track information for time map');\n    return {\n        offset: t_i[0].s_off.slice(0),\n        time: t_i[0].s_time.map(function(e){ return e/t_i[0].ts; }),\n    };\n};\nMP4ParserStream.prototype.push = function(chunk){\n    this.buffer.push(chunk);\n    var opt = {\n        root: this.metadata,\n        branch: this.metadata,\n        buffer: this.buffer,\n        view: this.buffer.view,\n        stream: this,\n        ptr: 0,\n    };\n    while (!this.metadata.h_parsed)\n    {\n        this.b_parser.header(opt);\n        if (!opt.type || opt.size+opt.ptr>this.buffer.b_size)\n            break;\n        this.b_parser.parse(opt);\n        opt.ptr += opt.size;\n    }\n    if (this.metadata.h_parsed)\n        this.buffer.pos = this.c_parser.parse(opt);\n    else\n    {\n        this.buffer.advance(opt.ptr-opt.offset);\n        this.buffer.pos = opt.type=='mdat' ?\n            opt.ptr+opt.size : this.buffer.b_pos+this.buffer.b_size;\n    }\n    return this.buffer.pos;\n};\nMP4ParserStream.prototype.seek = function(time, use_ssync){\n    this.trigger('data', {type: 'seek'});\n    var seek_info = this.c_parser.seek(time, use_ssync);\n    this.buffer.pos = seek_info.offset;\n    return seek_info;\n};\n\nvar AudioFilterStream = function(){\n    if (!(this instanceof AudioFilterStream))\n        return new AudioFilterStream();\n    AudioFilterStream.prototype.init.call(this);\n};\nAudioFilterStream.prototype = new Stream();\nAudioFilterStream.prototype.constructor = AudioFilterStream;\nAudioFilterStream.prototype.push = function(packet){\n    if (packet.type!='audio')\n        return;\n    var scale = 90000/packet.ts;\n    packet.pts = Math.floor(packet.pts*scale);\n    packet.dts = Math.floor(packet.dts*scale);\n    this.trigger('data', {\n        type: 'audio',\n        samplerate: packet.dr.s_rate,\n        samplesize: packet.dr.s_size,\n        audioobjecttype: packet.dr.esds.aot,\n        samplingfrequencyindex: packet.dr.esds.freq,\n        channelcount: packet.dr.esds.channel,\n        ts: packet.ts,\n        dts: packet.dts,\n        pts: packet.pts,\n        data: new Uint8Array(packet.data),\n    });\n};\n\nvar VideoFilterStream = function(){\n    if (!(this instanceof VideoFilterStream))\n        return new VideoFilterStream();\n    VideoFilterStream.prototype.init.call(this);\n    this.synced = false;\n    this.au = new Uint8Array([0x09, 0xF0]);\n};\nVideoFilterStream.prototype = new Stream();\nVideoFilterStream.prototype.constructor = VideoFilterStream;\nVideoFilterStream.prototype.flush = function(){\n    this.dr = null;\n    this.synced = false;\n    this.trigger('done');\n};\nVideoFilterStream.prototype.push = function(packet){\n    if (packet.type!='video')\n        return;\n    var pos = 0, i;\n    var view = new DataView(packet.data.buffer, packet.data.byteOffset,\n        packet.data.byteLength);\n    var scale = 90000/packet.ts;\n    packet.pts = Math.floor(packet.pts*scale);\n    packet.dts = Math.floor(packet.dts*scale);\n    this.trigger('data', {\n        trackId: packet.trackId,\n        pts: packet.pts,\n        dts: packet.dts,\n        data: this.au,\n        nalUnitType: 'access_unit_delimiter_rbsp',\n    });\n    if (this.dr!=packet.dr||!this.synced)\n    {\n        this.dr = packet.dr;\n        // pseudo-nals for config info\n        if (this.dr.avcc.n_sps)\n        {\n            for (i=0; i<this.dr.avcc.n_sps; i++)\n            {\n                this.trigger('data', {\n                    trackId: packet.trackId,\n                    pts: packet.pts,\n                    dts: packet.dts,\n                    nalUnitType: 'seq_parameter_set_rbsp',\n                    data: this.dr.avcc.sps[i].nal,\n                    config: {\n                        profileIdc: this.dr.avcc.avc_p_i,\n                        levelIdc: this.dr.avcc.avc_l_i,\n                        profileCompatibility: this.dr.avcc.prof_compat,\n                        width: this.dr.width,\n                        height: this.dr.height,\n                    },\n                });\n            }\n        }\n        if (this.dr.avcc.n_pps)\n        {\n            for (i=0; i<this.dr.avcc.n_pps; i++)\n            {\n                this.trigger('data', {\n                    trackId: packet.trackId,\n                    pts: packet.pts,\n                    dts: packet.dts,\n                    nalUnitType: 'pic_parameter_set_rbsp',\n                    data: this.dr.avcc.pps[0].nal,\n                });\n            }\n        }\n        this.synced = true;\n    }\n    while (pos<packet.data.length)\n    {\n        var sz = view.getUint32(pos);\n        var event = {\n            trackId: packet.trackId,\n            pts: packet.pts,\n            dts: packet.dts,\n            data: new Uint8Array(packet.data.subarray(pos+4, pos+sz+4)),\n        };\n        if ((event.data[0]&0x1f)==5)\n            event.nalUnitType = 'slice_layer_without_partitioning_rbsp_idr';\n        event.synced = !pos && packet.synced;\n        pos += sz+4;\n        this.trigger('data', event);\n    }\n};\n\nvar MP4BuilderStream = function(opt){\n    if (!(this instanceof MP4BuilderStream))\n        return new MP4BuilderStream(opt);\n    MP4BuilderStream.prototype.init.call(this);\n    this.options = opt||{};\n    this.tracks = {};\n    this.options.no_multi_init = true;\n    this.options.major = new Uint8Array([105, 115, 111, 53]); // 'iso5'\n    this.options.compatible = [new Uint8Array([105, 115, 111, 54])]; // 'iso6'\n    this.options.set_duration = true;\n    this.on('confupdate', function(conf){\n        this.options.break_on_count = conf.break_on_count; });\n    this.metadata = opt.metadata;\n    this.inited = !!this.metadata;\n};\nMP4BuilderStream.prototype = new Stream();\nMP4BuilderStream.prototype.constructor = MP4BuilderStream;\nMP4BuilderStream.prototype.push = function(packet){\n    var id;\n    if (packet.type=='metadata')\n        return void (this.metadata = packet);\n    if (packet.type=='seek')\n    {\n        for (id in this.tracks)\n            this.tracks[id].samples = [];\n        return;\n    }\n    id = packet.trackId;\n    this.tracks[id] = this.tracks[id]||{samples: [], seqno: 0, sc: 0,\n        type: packet.type};\n    var sample = {\n        duration: packet.duration,\n        size: packet.size,\n        dts: packet.dts,\n        pts: packet.pts,\n        data: new Uint8Array(packet.data),\n        sn: packet.sn,\n    };\n    if (packet.type=='video')\n    {\n        var scale = 90000/packet.ts;\n        sample.duration = Math.floor(sample.duration*scale);\n        sample.pts = Math.floor(sample.pts*scale);\n        sample.dts = Math.floor(sample.dts*scale);\n        sample.flags = {\n            dependsOn: (sample.dep&&sample.dep.dep)|0,\n            isDependedOn: (sample.dep&&sample.dep.is_dep)|0,\n            hasRedundancy: ((sample.dep&&sample.dep.red)|0) || 2*packet.synced,\n            isLeading: (sample.dep&&sample.dep.lead)|0,\n        };\n        if (!this.options.break_on_count)\n            sample.flags.isNonSyncSample = +!packet.synced;\n        sample.compositionTimeOffset = sample.pts-sample.dts;\n    }\n    packet.data = null;\n    this.tracks[id].samples.push(sample);\n};\nMP4BuilderStream.prototype.flush = function(){\n    var moof, mdat, seg_sz, _this = this;\n    if (!this.inited)\n    {\n        // build and emit init segments\n        this.inited = true;\n        var inits = [];\n        this.metadata.tracks.forEach(function(tr){\n            switch (tr.type)\n            {\n            case 'video':\n                tr.profileIdc = tr.dr.avcc.avc_p_i;\n                tr.levelIdc = tr.dr.avcc.avc_l_i;\n                tr.profileCompatibility = tr.dr.avcc.prof_compat;\n                tr.width = tr.track_width;\n                tr.height = tr.track_height;\n                tr.sps = tr.dr.avcc.sps.map(function(e){ return e.nal; });\n                tr.pps = tr.dr.avcc.pps.map(function(e){ return e.nal; });\n                break;\n            case 'audio':\n                tr.samplesize = tr.dr.s_size;\n                tr.audioobjecttype = tr.dr.esds.aot;\n                tr.samplingfrequencyindex = tr.dr.esds.freq;\n                tr.channelcount = tr.dr.esds.channel;\n            }\n            inits.push({\n                id: tr.id,\n                buffer: mp4.initSegment([tr], _this.options),\n            });\n        });\n        this.trigger('data', {init: true, inits: inits});\n    }\n    for (var id in this.tracks)\n    {\n        var track = this.tracks[id];\n        if (!track.samples.length)\n            continue;\n        var seg_slice = track.samples;\n        seg_sz = seg_slice.reduce(function(a, b){\n            return a+b.data.length; }, 0);\n        moof = mp4.moof(++track.seqno, [{\n            id: id,\n            baseMediaDecodeTime: seg_slice[0].dts,\n            samples: seg_slice,\n            type: track.type,\n        }], _this.options);\n        var segment = new Uint8Array(8+seg_sz+moof.length);\n        var sd = new Uint8Array(seg_sz);\n        var offset = 0;\n        for (var i=0; i<seg_slice.length; i++)\n        {\n            sd.set(seg_slice[i].data, offset);\n            offset += seg_slice[i].data.length;\n        }\n        mdat = mp4.mdat(sd);\n        segment.set(moof);\n        segment.set(mdat, moof.length);\n        segment.sn = seg_slice[seg_slice.length-1].sn;\n        sd = mdat = moof = null;\n        this.tracks[id].sc += seg_slice.length;\n        this.trigger('data', {id: id, data: segment,\n            sc: this.tracks[id].sc});\n        this.tracks[id].samples = [];\n    }\n    this.trigger('done');\n};\n\nmodule.exports = {\n  MP4ParserStream: MP4ParserStream,\n  AudioFilterStream: AudioFilterStream,\n  VideoFilterStream: VideoFilterStream,\n  MP4BuilderStream: MP4BuilderStream,\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) 2015 Brightcove\n * All rights reserved.\n *\n * A stream-based mp2t to mp4 converter. This utility can be used to\n * deliver mp4s to a SourceBuffer on platforms that support native\n * Media Source Extensions.\n */\n'use strict';\n\nvar Stream = require('../utils/stream.js');\nvar mp4 = require('./mp4-generator.js');\nvar mp4p = require('./mp4-parser.js');\nvar m2ts = require('../m2ts/m2ts.js');\nvar codecs = require('../codecs');\nvar AdtsStream = codecs.adts;\nvar H264Stream = codecs.h264.H264Stream;\nvar AacStream = require('../aac');\n\n// constants\nvar AUDIO_PROPERTIES = [\n  'audioobjecttype',\n  'channelcount',\n  'samplerate',\n  'samplingfrequencyindex',\n  'samplesize'\n];\n\nvar VIDEO_PROPERTIES = [\n  'width',\n  'height',\n  'profileIdc',\n  'levelIdc',\n  'profileCompatibility'\n];\n\nvar ONE_SECOND_IN_TS = 90000; // 90kHz clock\n\n// object types\nvar VideoSegmentStream, AudioSegmentStream, Transmuxer, CoalesceStream;\n\n// Helper functions\nvar\n  createDefaultSample,\n  isLikelyAacData,\n  collectDtsInfo,\n  clearDtsInfo,\n  calculateTrackBaseMediaDecodeTime,\n  arrayEquals,\n  sumFrameByteLengths;\n\n/**\n * Default sample object\n * see ISO/IEC 14496-12:2012, section 8.6.4.3\n */\ncreateDefaultSample = function() {\n  return {\n    size: 0,\n    flags: {\n      isLeading: 0,\n      dependsOn: 1,\n      isDependedOn: 0,\n      hasRedundancy: 0,\n      degradationPriority: 0\n    }\n  };\n};\n\nisLikelyAacData = function(data) {\n  if ((data[0] === 'I'.charCodeAt(0)) &&\n      (data[1] === 'D'.charCodeAt(0)) &&\n      (data[2] === '3'.charCodeAt(0))) {\n    return true;\n  }\n  return false;\n};\n\n/**\n * Compare two arrays (even typed) for same-ness\n */\narrayEquals = function(a, b) {\n  var\n    i;\n\n  if (a.length !== b.length) {\n    return false;\n  }\n\n  // compare the value of each element in the array\n  for (i = 0; i < a.length; i++) {\n    if (a[i] !== b[i]) {\n      return false;\n    }\n  }\n\n  return true;\n};\n\n/**\n * Sum the `byteLength` properties of the data in each AAC frame\n */\nsumFrameByteLengths = function(array) {\n  var\n    i,\n    currentObj,\n    sum = 0;\n\n  // sum the byteLength's all each nal unit in the frame\n  for (i = 0; i < array.length; i++) {\n    currentObj = array[i];\n    sum += currentObj.data.byteLength;\n  }\n\n  return sum;\n};\n\n/**\n * Constructs a single-track, ISO BMFF media segment from AAC data\n * events. The output of this stream can be fed to a SourceBuffer\n * configured with a suitable initialization segment.\n */\nAudioSegmentStream = function(track) {\n  var\n    adtsFrames = [],\n    sequenceNumber = 0,\n    earliestAllowedDts = 0;\n\n  AudioSegmentStream.prototype.init.call(this);\n\n  this.push = function(data) {\n    collectDtsInfo(track, data);\n\n    if (track) {\n      AUDIO_PROPERTIES.forEach(function(prop) {\n        track[prop] = data[prop];\n      });\n    }\n\n    // buffer audio data until end() is called\n    adtsFrames.push(data);\n  };\n\n  this.setEarliestDts = function(earliestDts) {\n    earliestAllowedDts = earliestDts - track.timelineStartInfo.baseMediaDecodeTime;\n  };\n\n  this.flush = function() {\n    var\n      frames,\n      moof,\n      mdat,\n      boxes;\n\n    // return early if no audio data has been observed\n    if (adtsFrames.length === 0) {\n      this.trigger('done', 'AudioSegmentStream');\n      return;\n    }\n\n    frames = this.trimAdtsFramesByEarliestDts_(adtsFrames);\n\n    // we have to build the index from byte locations to\n    // samples (that is, adts frames) in the audio data\n    track.samples = this.generateSampleTable_(frames);\n\n    // concatenate the audio data to constuct the mdat\n    mdat = mp4.mdat(this.concatenateFrameData_(frames));\n\n    adtsFrames = [];\n\n    calculateTrackBaseMediaDecodeTime(track);\n    moof = mp4.moof(sequenceNumber, [track]);\n    boxes = new Uint8Array(moof.byteLength + mdat.byteLength);\n\n    // bump the sequence number for next time\n    sequenceNumber++;\n\n    boxes.set(moof);\n    boxes.set(mdat, moof.byteLength);\n\n    clearDtsInfo(track);\n\n    this.trigger('data', {track: track, boxes: boxes});\n    this.trigger('done', 'AudioSegmentStream');\n  };\n\n  // If the audio segment extends before the earliest allowed dts\n  // value, remove AAC frames until starts at or after the earliest\n  // allowed DTS so that we don't end up with a negative baseMedia-\n  // DecodeTime for the audio track\n  this.trimAdtsFramesByEarliestDts_ = function(adtsFrames) {\n    if (track.minSegmentDts >= earliestAllowedDts) {\n      return adtsFrames;\n    }\n\n    // We will need to recalculate the earliest segment Dts\n    track.minSegmentDts = Infinity;\n\n    return adtsFrames.filter(function(currentFrame) {\n      // If this is an allowed frame, keep it and record it's Dts\n      if (currentFrame.dts >= earliestAllowedDts) {\n        track.minSegmentDts = Math.min(track.minSegmentDts, currentFrame.dts);\n        track.minSegmentPts = track.minSegmentDts;\n        return true;\n      }\n      // Otherwise, discard it\n      return false;\n    });\n  };\n\n  // generate the track's raw mdat data from an array of frames\n  this.generateSampleTable_ = function(frames) {\n    var\n      i,\n      currentFrame,\n      samples = [];\n\n    for (i = 0; i < frames.length; i++) {\n      currentFrame = frames[i];\n      samples.push({\n        size: currentFrame.data.byteLength,\n        duration: 1024 // For AAC audio, all samples contain 1024 samples\n      });\n    }\n    return samples;\n  };\n\n  // generate the track's sample table from an array of frames\n  this.concatenateFrameData_ = function(frames) {\n    var\n      i,\n      currentFrame,\n      dataOffset = 0,\n      data = new Uint8Array(sumFrameByteLengths(frames));\n\n    for (i = 0; i < frames.length; i++) {\n      currentFrame = frames[i];\n\n      data.set(currentFrame.data, dataOffset);\n      dataOffset += currentFrame.data.byteLength;\n    }\n    return data;\n  };\n};\n\nAudioSegmentStream.prototype = new Stream();\n\n/**\n * Constructs a single-track, ISO BMFF media segment from H264 data\n * events. The output of this stream can be fed to a SourceBuffer\n * configured with a suitable initialization segment.\n * @param track {object} track metadata configuration\n */\nVideoSegmentStream = function(track) {\n  var\n    sequenceNumber = 0,\n    nalUnits = [],\n    config,\n    pps;\n\n  VideoSegmentStream.prototype.init.call(this);\n\n  delete track.minPTS;\n\n  this.gopCache_ = [];\n\n  this.push = function(nalUnit) {\n    collectDtsInfo(track, nalUnit);\n\n    // record the track config\n    if (nalUnit.nalUnitType === codecs.h264.unitTypes.seq_parameter_set_rbsp && !config) {\n      config = nalUnit.config;\n      track.sps = [nalUnit.data];\n      VIDEO_PROPERTIES.forEach(function(prop) {\n        track[prop] = config[prop];\n      }, this);\n    }\n\n    if (nalUnit.nalUnitType === codecs.h264.unitTypes.pic_parameter_set_rbsp &&\n        !pps) {\n      pps = nalUnit.data;\n      track.pps = [nalUnit.data];\n    }\n\n    // buffer video until flush() is called\n    nalUnits.push(nalUnit);\n  };\n\n  this.flush = function() {\n    var\n      frames,\n      gopForFusion,\n      gops,\n      moof,\n      mdat,\n      boxes;\n\n    // Throw away nalUnits at the start of the byte stream until\n    // we find the first AUD\n    while (nalUnits.length && nalUnits[0].nalUnitType !== codecs.h264.unitTypes.access_unit_delimiter_rbsp) {\n      nalUnits.shift();\n    }\n\n    // Return early if no video data has been observed\n    if (nalUnits.length === 0) {\n      this.resetStream_();\n      this.trigger('done', 'VideoSegmentStream');\n      return;\n    }\n\n    // Organize the raw nal-units into arrays that represent\n    // higher-level constructs such as frames and gops\n    // (group-of-pictures)\n    frames = this.groupNalsIntoFrames_(nalUnits);\n    gops = this.groupFramesIntoGops_(frames);\n\n    // If the first frame of this fragment is not a keyframe we have\n    // a problem since MSE (on Chrome) requires a leading keyframe.\n    //\n    // We have two approaches to repairing this situation:\n    // 1) GOP-FUSION:\n    //    This is where we keep track of the GOPS (group-of-pictures)\n    //    from previous fragments and attempt to find one that we can\n    //    prepend to the current fragment in order to create a valid\n    //    fragment.\n    // 2) KEYFRAME-PULLING:\n    //    Here we search for the first keyframe in the fragment and\n    //    throw away all the frames between the start of the fragment\n    //    and that keyframe. We then extend the duration and pull the\n    //    PTS of the keyframe forward so that it covers the time range\n    //    of the frames that were disposed of.\n    //\n    // #1 is far prefereable over #2 which can cause \"stuttering\" but\n    // requires more things to be just right.\n    if (!gops[0][0].keyFrame) {\n      // Search for a gop for fusion from our gopCache\n      gopForFusion = this.getGopForFusion_(nalUnits[0], track);\n\n      if (gopForFusion) {\n        gops.unshift(gopForFusion);\n        // Adjust Gops' metadata to account for the inclusion of the\n        // new gop at the beginning\n        gops.byteLength += gopForFusion.byteLength;\n        gops.nalCount += gopForFusion.nalCount;\n        gops.pts = gopForFusion.pts;\n        gops.dts = gopForFusion.dts;\n        gops.duration += gopForFusion.duration;\n      } else {\n        // If we didn't find a candidate gop fall back to keyrame-pulling\n        gops = this.extendFirstKeyFrame_(gops);\n      }\n    }\n    collectDtsInfo(track, gops);\n\n    // First, we have to build the index from byte locations to\n    // samples (that is, frames) in the video data\n    track.samples = this.generateSampleTable_(gops);\n\n    // Concatenate the video data and construct the mdat\n    mdat = mp4.mdat(this.concatenateNalData_(gops));\n\n    // save all the nals in the last GOP into the gop cache\n    this.gopCache_.unshift({\n      gop: gops.pop(),\n      pps: track.pps,\n      sps: track.sps\n    });\n\n    // Keep a maximum of 6 GOPs in the cache\n    this.gopCache_.length = Math.min(6, this.gopCache_.length);\n\n    // Clear nalUnits\n    nalUnits = [];\n\n    calculateTrackBaseMediaDecodeTime(track);\n\n    this.trigger('timelineStartInfo', track.timelineStartInfo);\n\n    moof = mp4.moof(sequenceNumber, [track]);\n\n    // it would be great to allocate this array up front instead of\n    // throwing away hundreds of media segment fragments\n    boxes = new Uint8Array(moof.byteLength + mdat.byteLength);\n\n    // Bump the sequence number for next time\n    sequenceNumber++;\n\n    boxes.set(moof);\n    boxes.set(mdat, moof.byteLength);\n\n    this.trigger('data', {track: track, boxes: boxes});\n\n    this.resetStream_();\n\n    // Continue with the flush process now\n    this.trigger('done', 'VideoSegmentStream');\n  };\n\n  this.resetStream_ = function() {\n    clearDtsInfo(track);\n\n    // reset config and pps because they may differ across segments\n    // for instance, when we are rendition switching\n    config = undefined;\n    pps = undefined;\n  };\n\n  // Search for a candidate Gop for gop-fusion from the gop cache and\n  // return it or return null if no good candidate was found\n  this.getGopForFusion_ = function(nalUnit) {\n    var\n      halfSecond = 45000, // Half-a-second in a 90khz clock\n      allowableOverlap = 10000, // About 3 frames @ 30fps\n      nearestDistance = Infinity,\n      dtsDistance,\n      nearestGopObj,\n      currentGop,\n      currentGopObj,\n      i;\n\n    // Search for the GOP nearest to the beginning of this nal unit\n    for (i = 0; i < this.gopCache_.length; i++) {\n      currentGopObj = this.gopCache_[i];\n      currentGop = currentGopObj.gop;\n\n      // Reject Gops with different SPS or PPS\n      if (!(track.pps && arrayEquals(track.pps[0], currentGopObj.pps[0])) ||\n          !(track.sps && arrayEquals(track.sps[0], currentGopObj.sps[0]))) {\n        continue;\n      }\n\n      // Reject Gops that would require a negative baseMediaDecodeTime\n      if (currentGop.dts < track.timelineStartInfo.dts) {\n        continue;\n      }\n\n      // The distance between the end of the gop and the start of the nalUnit\n      dtsDistance = (nalUnit.dts - currentGop.dts) - currentGop.duration;\n\n      // Only consider GOPS that start before the nal unit and end within\n      // a half-second of the nal unit\n      if (dtsDistance >= -allowableOverlap &&\n          dtsDistance <= halfSecond) {\n\n        // Always use the closest GOP we found if there is more than\n        // one candidate\n        if (!nearestGopObj ||\n            nearestDistance > dtsDistance) {\n          nearestGopObj = currentGopObj;\n          nearestDistance = dtsDistance;\n        }\n      }\n    }\n\n    if (nearestGopObj) {\n      return nearestGopObj.gop;\n    }\n    return null;\n  };\n\n  this.extendFirstKeyFrame_ = function(gops) {\n    var currentGop;\n\n    if (!gops[0][0].keyFrame && gops.length > 1) {\n      // Remove the first GOP\n      currentGop = gops.shift();\n\n      gops.byteLength -=  currentGop.byteLength;\n      gops.nalCount -= currentGop.nalCount;\n\n      // Extend the first frame of what is now the\n      // first gop to cover the time period of the\n      // frames we just removed\n      gops[0][0].dts = currentGop.dts;\n      gops[0][0].pts = currentGop.pts;\n      gops[0][0].duration += currentGop.duration;\n    }\n\n    return gops;\n  };\n\n  // Convert an array of nal units into an array of frames with each frame being\n  // composed of the nal units that make up that frame\n  // Also keep track of cummulative data about the frame from the nal units such\n  // as the frame duration, starting pts, etc.\n  this.groupNalsIntoFrames_ = function(nalUnits) {\n    var\n      i,\n      currentNal,\n      currentFrame = [],\n      frames = [];\n\n    currentFrame.byteLength = 0;\n\n    for (i = 0; i < nalUnits.length; i++) {\n      currentNal = nalUnits[i];\n\n      // Split on 'aud'-type nal units\n      if (currentNal.nalUnitType === codecs.h264.unitTypes.access_unit_delimiter_rbsp) {\n        // Since the very first nal unit is expected to be an AUD\n        // only push to the frames array when currentFrame is not empty\n        if (currentFrame.length) {\n          currentFrame.duration = currentNal.dts - currentFrame.dts;\n          frames.push(currentFrame);\n        }\n        currentFrame = [currentNal];\n        currentFrame.byteLength = currentNal.data.byteLength;\n        currentFrame.pts = currentNal.pts;\n        currentFrame.dts = currentNal.dts;\n      } else {\n        // Specifically flag key frames for ease of use later\n        if (currentNal.nalUnitType === codecs.h264.unitTypes.slice_layer_without_partitioning_rbsp_idr) {\n          currentFrame.keyFrame = true;\n        }\n        currentFrame.duration = currentNal.dts - currentFrame.dts;\n        currentFrame.byteLength += currentNal.data.byteLength;\n        currentFrame.push(currentNal);\n      }\n    }\n\n    // For the last frame, use the duration of the previous frame if we\n    // have nothing better to go on\n    if (frames.length &&\n        (!currentFrame.duration ||\n         currentFrame.duration <= 0)) {\n      currentFrame.duration = frames[frames.length - 1].duration;\n    }\n\n    // Push the final frame\n    frames.push(currentFrame);\n    return frames;\n  };\n\n  // Convert an array of frames into an array of Gop with each Gop being composed\n  // of the frames that make up that Gop\n  // Also keep track of cummulative data about the Gop from the frames such as the\n  // Gop duration, starting pts, etc.\n  this.groupFramesIntoGops_ = function(frames) {\n    var\n      i,\n      currentFrame,\n      currentGop = [],\n      gops = [];\n\n    // We must pre-set some of the values on the Gop since we\n    // keep running totals of these values\n    currentGop.byteLength = 0;\n    currentGop.nalCount = 0;\n    currentGop.duration = 0;\n    currentGop.pts = frames[0].pts;\n    currentGop.dts = frames[0].dts;\n\n    // store some metadata about all the Gops\n    gops.byteLength = 0;\n    gops.nalCount = 0;\n    gops.duration = 0;\n    gops.pts = frames[0].pts;\n    gops.dts = frames[0].dts;\n\n    for (i = 0; i < frames.length; i++) {\n      currentFrame = frames[i];\n\n      if (currentFrame.keyFrame) {\n        // Since the very first frame is expected to be an keyframe\n        // only push to the gops array when currentGop is not empty\n        if (currentGop.length) {\n          gops.push(currentGop);\n          gops.byteLength += currentGop.byteLength;\n          gops.nalCount += currentGop.nalCount;\n          gops.duration += currentGop.duration;\n        }\n\n        currentGop = [currentFrame];\n        currentGop.nalCount = currentFrame.length;\n        currentGop.byteLength = currentFrame.byteLength;\n        currentGop.pts = currentFrame.pts;\n        currentGop.dts = currentFrame.dts;\n        currentGop.duration = currentFrame.duration;\n      } else {\n        currentGop.duration += currentFrame.duration;\n        currentGop.nalCount += currentFrame.length;\n        currentGop.byteLength += currentFrame.byteLength;\n        currentGop.push(currentFrame);\n      }\n    }\n\n    if (gops.length && currentGop.duration <= 0) {\n      currentGop.duration = gops[gops.length - 1].duration;\n    }\n    gops.byteLength += currentGop.byteLength;\n    gops.nalCount += currentGop.nalCount;\n    gops.duration += currentGop.duration;\n\n    // push the final Gop\n    gops.push(currentGop);\n    return gops;\n  };\n\n  // generate the track's sample table from an array of gops\n  this.generateSampleTable_ = function(gops, baseDataOffset) {\n    var\n      h, i,\n      sample,\n      currentGop,\n      currentFrame,\n      dataOffset = baseDataOffset || 0,\n      samples = [];\n\n    for (h = 0; h < gops.length; h++) {\n      currentGop = gops[h];\n\n      for (i = 0; i < currentGop.length; i++) {\n        currentFrame = currentGop[i];\n\n        sample = createDefaultSample();\n\n        sample.dataOffset = dataOffset;\n        sample.compositionTimeOffset = currentFrame.pts - currentFrame.dts;\n        sample.duration = currentFrame.duration;\n        sample.size = 4 * currentFrame.length; // Space for nal unit size\n        sample.size += currentFrame.byteLength;\n\n        if (currentFrame.keyFrame) {\n          sample.flags.dependsOn = 2;\n        }\n\n        dataOffset += sample.size;\n\n        samples.push(sample);\n      }\n    }\n    return samples;\n  };\n\n  // generate the track's raw mdat data from an array of gops\n  this.concatenateNalData_ = function(gops) {\n    var\n      h, i, j,\n      currentGop,\n      currentFrame,\n      currentNal,\n      dataOffset = 0,\n      nalsByteLength = gops.byteLength,\n      numberOfNals = gops.nalCount,\n      totalByteLength = nalsByteLength + 4 * numberOfNals,\n      data = new Uint8Array(totalByteLength),\n      view = new DataView(data.buffer);\n\n    // For each Gop..\n    for (h = 0; h < gops.length; h++) {\n      currentGop = gops[h];\n\n      // For each Frame..\n      for (i = 0; i < currentGop.length; i++) {\n        currentFrame = currentGop[i];\n\n        // For each NAL..\n        for (j = 0; j < currentFrame.length; j++) {\n          currentNal = currentFrame[j];\n\n          view.setUint32(dataOffset, currentNal.data.byteLength);\n          dataOffset += 4;\n          data.set(currentNal.data, dataOffset);\n          dataOffset += currentNal.data.byteLength;\n        }\n      }\n    }\n    return data;\n  };\n};\n\nVideoSegmentStream.prototype = new Stream();\n\n/**\n * Store information about the start and end of the track and the\n * duration for each frame/sample we process in order to calculate\n * the baseMediaDecodeTime\n */\ncollectDtsInfo = function(track, data) {\n  if (typeof data.pts === 'number') {\n    if (track.timelineStartInfo.pts === undefined) {\n      track.timelineStartInfo.pts = data.pts;\n    }\n\n    if (track.minSegmentPts === undefined) {\n      track.minSegmentPts = data.pts;\n    } else {\n      track.minSegmentPts = Math.min(track.minSegmentPts, data.pts);\n    }\n\n    if (track.maxSegmentPts === undefined) {\n      track.maxSegmentPts = data.pts;\n    } else {\n      track.maxSegmentPts = Math.max(track.maxSegmentPts, data.pts);\n    }\n  }\n\n  if (typeof data.dts === 'number') {\n    if (track.timelineStartInfo.dts === undefined) {\n      track.timelineStartInfo.dts = data.dts;\n    }\n\n    if (track.minSegmentDts === undefined) {\n      track.minSegmentDts = data.dts;\n    } else {\n      track.minSegmentDts = Math.min(track.minSegmentDts, data.dts);\n    }\n\n    if (track.maxSegmentDts === undefined) {\n      track.maxSegmentDts = data.dts;\n    } else {\n      track.maxSegmentDts = Math.max(track.maxSegmentDts, data.dts);\n    }\n  }\n};\n\n/**\n * Clear values used to calculate the baseMediaDecodeTime between\n * tracks\n */\nclearDtsInfo = function(track) {\n  delete track.minSegmentDts;\n  delete track.maxSegmentDts;\n  delete track.minSegmentPts;\n  delete track.maxSegmentPts;\n};\n\n/**\n * Calculate the track's baseMediaDecodeTime based on the earliest\n * DTS the transmuxer has ever seen and the minimum DTS for the\n * current track\n */\ncalculateTrackBaseMediaDecodeTime = function(track) {\n  var\n    oneSecondInPTS = 90000, // 90kHz clock\n    scale,\n    // Calculate the distance, in time, that this segment starts from the start\n    // of the timeline (earliest time seen since the transmuxer initialized)\n    timeSinceStartOfTimeline = track.minSegmentDts - track.timelineStartInfo.dts,\n    // Calculate the first sample's effective compositionTimeOffset\n    firstSampleCompositionOffset = track.minSegmentPts - track.minSegmentDts;\n\n  // track.timelineStartInfo.baseMediaDecodeTime is the location, in time, where\n  // we want the start of the first segment to be placed\n  track.baseMediaDecodeTime = track.timelineStartInfo.baseMediaDecodeTime;\n\n  // Add to that the distance this segment is from the very first\n  track.baseMediaDecodeTime += timeSinceStartOfTimeline;\n\n  // Subtract this segment's \"compositionTimeOffset\" so that the first frame of\n  // this segment is displayed exactly at the `baseMediaDecodeTime` or at the\n  // end of the previous segment\n  track.baseMediaDecodeTime -= firstSampleCompositionOffset;\n\n  // baseMediaDecodeTime must not become negative\n  track.baseMediaDecodeTime = Math.max(0, track.baseMediaDecodeTime);\n\n  if (track.type === 'audio') {\n    // Audio has a different clock equal to the sampling_rate so we need to\n    // scale the PTS values into the clock rate of the track\n    scale = track.samplerate / oneSecondInPTS;\n    track.baseMediaDecodeTime *= scale;\n    track.baseMediaDecodeTime = Math.floor(track.baseMediaDecodeTime);\n  }\n\n  return track.baseMediaDecodeTime;\n};\n\n/**\n * A Stream that can combine multiple streams (ie. audio & video)\n * into a single output segment for MSE. Also supports audio-only\n * and video-only streams.\n */\nCoalesceStream = function(options, metadataStream) {\n  // Number of Tracks per output segment\n  // If greater than 1, we combine multiple\n  // tracks into a single segment\n  this.numberOfTracks = 0;\n  this.metadataStream = metadataStream;\n\n  if (typeof options.remux !== 'undefined') {\n    this.remuxTracks = !!options.remux;\n  } else {\n    this.remuxTracks = true;\n  }\n\n  this.pendingTracks = [];\n  this.videoTrack = null;\n  this.pendingBoxes = [];\n  this.pendingCaptions = [];\n  this.pendingMetadata = [];\n  this.pendingBytes = 0;\n  this.emittedTracks = 0;\n\n  CoalesceStream.prototype.init.call(this);\n\n  // Take output from multiple\n  this.push = function(output) {\n    // buffer incoming captions until the associated video segment\n    // finishes\n    if (output.text) {\n      return this.pendingCaptions.push(output);\n    }\n    // buffer incoming id3 tags until the final flush\n    if (output.frames) {\n      return this.pendingMetadata.push(output);\n    }\n\n    // Add this track to the list of pending tracks and store\n    // important information required for the construction of\n    // the final segment\n    this.pendingTracks.push(output.track);\n    this.pendingBoxes.push(output.boxes);\n    this.pendingBytes += output.boxes.byteLength;\n\n    if (output.track.type === 'video') {\n      this.videoTrack = output.track;\n    }\n    if (output.track.type === 'audio') {\n      this.audioTrack = output.track;\n    }\n  };\n};\n\nCoalesceStream.prototype = new Stream();\nCoalesceStream.prototype.flush = function(flushSource) {\n  var\n    offset = 0,\n    event = {\n      captions: [],\n      metadata: [],\n      info: {}\n    },\n    caption,\n    id3,\n    initSegment,\n    timelineStartPts = 0,\n    i;\n\n  if (this.pendingTracks.length < this.numberOfTracks) {\n    if (flushSource !== 'VideoSegmentStream' &&\n        flushSource !== 'AudioSegmentStream') {\n      // Return because we haven't received a flush from a data-generating\n      // portion of the segment (meaning that we have only recieved meta-data\n      // or captions.)\n      return;\n    } else if (this.remuxTracks) {\n      // Return until we have enough tracks from the pipeline to remux (if we\n      // are remuxing audio and video into a single MP4)\n      return;\n    } else if (this.pendingTracks.length === 0) {\n      // In the case where we receive a flush without any data having been\n      // received we consider it an emitted track for the purposes of coalescing\n      // `done` events.\n      // We do this for the case where there is an audio and video track in the\n      // segment but no audio data. (seen in several playlists with alternate\n      // audio tracks and no audio present in the main TS segments.)\n      this.emittedTracks++;\n\n      if (this.emittedTracks >= this.numberOfTracks) {\n        this.trigger('done');\n        this.emittedTracks = 0;\n      }\n      return;\n    }\n  }\n\n  if (this.videoTrack) {\n    timelineStartPts = this.videoTrack.timelineStartInfo.pts;\n    VIDEO_PROPERTIES.forEach(function(prop) {\n      event.info[prop] = this.videoTrack[prop];\n    }, this);\n  } else if (this.audioTrack) {\n    timelineStartPts = this.audioTrack.timelineStartInfo.pts;\n    AUDIO_PROPERTIES.forEach(function(prop) {\n      event.info[prop] = this.audioTrack[prop];\n    }, this);\n  }\n\n  if (this.pendingTracks.length === 1) {\n    event.type = this.pendingTracks[0].type;\n  } else {\n    event.type = 'combined';\n  }\n\n  this.emittedTracks += this.pendingTracks.length;\n\n  initSegment = mp4.initSegment(this.pendingTracks, this.options);\n  this.pendingBytes += initSegment.byteLength;\n  this.pendingBoxes.unshift(initSegment);\n\n  // Create a new typed array large enough to hold the init\n  // segment and all tracks\n  event.data = new Uint8Array(this.pendingBytes);\n\n  // Append each moof+mdat (one per track) after the init segment\n  for (i = 0; i < this.pendingBoxes.length; i++) {\n    event.data.set(this.pendingBoxes[i], offset);\n    offset += this.pendingBoxes[i].byteLength;\n  }\n\n  // Translate caption PTS times into second offsets into the\n  // video timeline for the segment\n  for (i = 0; i < this.pendingCaptions.length; i++) {\n    caption = this.pendingCaptions[i];\n    caption.startTime = (caption.startPts - timelineStartPts);\n    caption.startTime /= 90e3;\n    caption.endTime = (caption.endPts - timelineStartPts);\n    caption.endTime /= 90e3;\n    event.captions.push(caption);\n  }\n\n  // Translate ID3 frame PTS times into second offsets into the\n  // video timeline for the segment\n  for (i = 0; i < this.pendingMetadata.length; i++) {\n    id3 = this.pendingMetadata[i];\n    id3.cueTime = (id3.pts - timelineStartPts);\n    id3.cueTime /= 90e3;\n    event.metadata.push(id3);\n  }\n  // We add this to every single emitted segment even though we only need\n  // it for the first\n  event.metadata.dispatchType = this.metadataStream.dispatchType;\n\n  // Reset stream state\n  this.pendingTracks.length = 0;\n  this.videoTrack = null;\n  this.pendingBoxes.length = 0;\n  this.pendingCaptions.length = 0;\n  this.pendingBytes = 0;\n  this.pendingMetadata.length = 0;\n\n  // Emit the built segment\n  this.trigger('data', event);\n\n  // Only emit `done` if all tracks have been flushed and emitted\n  if (this.emittedTracks >= this.numberOfTracks) {\n    this.trigger('done');\n    this.emittedTracks = 0;\n  }\n};\n/**\n * A Stream that expects MP2T binary data as input and produces\n * corresponding media segments, suitable for use with Media Source\n * Extension (MSE) implementations that support the ISO BMFF byte\n * stream format, like Chrome.\n */\nTransmuxer = function(options) {\n  var\n    self = this,\n    hasFlushed = true,\n    videoTrack,\n    audioTrack;\n\n  Transmuxer.prototype.init.call(this);\n\n  options = options || {};\n  options.input_type = options.input_type||'ts';\n  if (options.break_on_count===undefined) {\n    options.break_on_count = true;\n  }\n  this.baseMediaDecodeTime = options.baseMediaDecodeTime || 0;\n  this.transmuxPipeline_ = {};\n\n  this.setupAacPipeline = function() {\n    var pipeline = {};\n    this.transmuxPipeline_ = pipeline;\n\n    pipeline.type = 'aac';\n    pipeline.metadataStream = new m2ts.MetadataStream();\n\n    // set up the parsing pipeline\n    pipeline.aacStream = new AacStream();\n    pipeline.audioTimestampRolloverStream = new m2ts.TimestampRolloverStream('audio');\n    pipeline.timedMetadataTimestampRolloverStream = new m2ts.TimestampRolloverStream('timed-metadata');\n    pipeline.adtsStream = new AdtsStream();\n    pipeline.coalesceStream = new CoalesceStream(options, pipeline.metadataStream);\n    pipeline.headOfPipeline = pipeline.aacStream;\n\n    pipeline.aacStream\n      .pipe(pipeline.audioTimestampRolloverStream)\n      .pipe(pipeline.adtsStream);\n    pipeline.aacStream\n      .pipe(pipeline.timedMetadataTimestampRolloverStream)\n      .pipe(pipeline.metadataStream)\n      .pipe(pipeline.coalesceStream);\n\n    pipeline.metadataStream.on('timestamp', function(frame) {\n      pipeline.aacStream.setTimestamp(frame.timeStamp);\n    });\n\n    pipeline.aacStream.on('data', function(data) {\n      if (data.type === 'timed-metadata' && !pipeline.audioSegmentStream) {\n        audioTrack = audioTrack || {\n          timelineStartInfo: {\n            baseMediaDecodeTime: self.baseMediaDecodeTime\n          },\n          codec: 'adts',\n          type: 'audio'\n        };\n        // hook up the audio segment stream to the first track with aac data\n        pipeline.coalesceStream.numberOfTracks++;\n        pipeline.audioSegmentStream = new AudioSegmentStream(audioTrack);\n        // Set up the final part of the audio pipeline\n        pipeline.adtsStream\n          .pipe(pipeline.audioSegmentStream)\n          .pipe(pipeline.coalesceStream);\n      }\n    });\n\n    // Re-emit any data coming from the coalesce stream to the outside world\n    pipeline.coalesceStream.on('data', this.trigger.bind(this, 'data'));\n    // Let the consumer know we have finished flushing the entire pipeline\n    pipeline.coalesceStream.on('done', this.trigger.bind(this, 'done'));\n  };\n\n  this.setupTsPipeline = function() {\n    var pipeline = {};\n    this.transmuxPipeline_ = pipeline;\n\n    pipeline.type = options.input_type;\n    if (pipeline.type=='ts')\n    {\n      options.metadataStream = pipeline.metadataStream =\n        new m2ts.MetadataStream();\n      // set up the parsing pipeline\n      pipeline.packetStream = new m2ts.TransportPacketStream();\n      pipeline.parseStream = new m2ts.TransportParseStream();\n      pipeline.elementaryStream = new m2ts.ElementaryStream();\n      pipeline.videoTimestampRolloverStream = new m2ts.TimestampRolloverStream('video');\n      pipeline.audioTimestampRolloverStream = new m2ts.TimestampRolloverStream('audio');\n      pipeline.timedMetadataTimestampRolloverStream = new m2ts.TimestampRolloverStream('timed-metadata');\n      pipeline.adtsStream = new AdtsStream();\n      pipeline.h264Stream = new H264Stream();\n      pipeline.captionStream = new m2ts.CaptionStream();\n      pipeline.coalesceStream = new CoalesceStream(options,\n        pipeline.metadataStream);\n      pipeline.headOfPipeline = pipeline.packetStream;\n      // disassemble MPEG2-TS packets into elementary streams\n      pipeline.packetStream.pipe(pipeline.parseStream)\n        .pipe(pipeline.elementaryStream);\n      // !!THIS ORDER IS IMPORTANT!!\n      // demux the streams\n      pipeline.elementaryStream\n        .pipe(pipeline.videoTimestampRolloverStream)\n        .pipe(pipeline.h264Stream);\n      pipeline.elementaryStream\n        .pipe(pipeline.audioTimestampRolloverStream)\n        .pipe(pipeline.adtsStream);\n\n      pipeline.elementaryStream\n        .pipe(pipeline.timedMetadataTimestampRolloverStream)\n        .pipe(pipeline.metadataStream)\n        .pipe(pipeline.coalesceStream);\n      // Hook up CEA-608/708 caption stream\n      pipeline.h264Stream.pipe(pipeline.captionStream)\n        .pipe(pipeline.coalesceStream);\n    }\n    else\n    {\n      pipeline.headOfPipeline = pipeline.elementaryStream =\n        new mp4p.MP4ParserStream(options);\n      pipeline.mp4BuilderStream = new mp4p.MP4BuilderStream(options);\n      pipeline.elementaryStream.pipe(pipeline.mp4BuilderStream);\n      this.seek = function(pos, ss){\n        return pipeline.elementaryStream.seek(pos, ss); };\n      this.get_tl = function(id){\n        return pipeline.elementaryStream.get_tl(id); };\n      this.conf_update = function(conf){\n        pipeline.elementaryStream.trigger('confupdate', conf);\n        pipeline.mp4BuilderStream.trigger('confupdate', conf);\n      };\n    }\n\n    pipeline.elementaryStream.on('data', function(data) {\n      var i;\n\n      if (data.type === 'metadata') {\n        if (options.input_type === 'mp4') {\n          return void self.trigger('metadata', data);\n        }\n        i = data.tracks.length;\n\n        // scan the tracks listed in the metadata\n        while (i--) {\n          if (!videoTrack && data.tracks[i].type === 'video') {\n            videoTrack = data.tracks[i];\n            videoTrack.timelineStartInfo.baseMediaDecodeTime = self.baseMediaDecodeTime;\n          } else if (!audioTrack && data.tracks[i].type === 'audio') {\n            audioTrack = data.tracks[i];\n            audioTrack.timelineStartInfo.baseMediaDecodeTime = self.baseMediaDecodeTime;\n          }\n        }\n\n        // hook up the video segment stream to the first track with h264 data\n        if (videoTrack && !pipeline.videoSegmentStream) {\n          pipeline.coalesceStream.numberOfTracks++;\n          pipeline.videoSegmentStream = new VideoSegmentStream(videoTrack);\n\n          pipeline.videoSegmentStream.on('timelineStartInfo', function(timelineStartInfo) {\n          // When video emits timelineStartInfo data after a flush, we forward that\n          // info to the AudioSegmentStream, if it exists, because video timeline\n          // data takes precedence.\n            if (audioTrack) {\n              audioTrack.timelineStartInfo = timelineStartInfo;\n              // On the first segment we trim AAC frames that exist before the\n              // very earliest DTS we have seen in video because Chrome will\n              // interpret any video track with a baseMediaDecodeTime that is\n              // non-zero as a gap.\n              pipeline.audioSegmentStream.setEarliestDts(timelineStartInfo.dts);\n            }\n          });\n\n          // Set up the final part of the video pipeline\n          pipeline.h264Stream\n            .pipe(pipeline.videoSegmentStream)\n            .pipe(pipeline.coalesceStream);\n        }\n\n        if (audioTrack && !pipeline.audioSegmentStream) {\n          // hook up the audio segment stream to the first track with aac data\n          pipeline.coalesceStream.numberOfTracks++;\n          pipeline.audioSegmentStream = new AudioSegmentStream(audioTrack);\n\n          // Set up the final part of the audio pipeline\n          pipeline.adtsStream\n            .pipe(pipeline.audioSegmentStream)\n            .pipe(pipeline.coalesceStream);\n        }\n      }\n    });\n    if (options.input_type==='mp4')\n    {\n      pipeline.mp4BuilderStream.on('data', this.trigger.bind(this, 'data'));\n      pipeline.mp4BuilderStream.on('done', this.trigger.bind(this, 'done'));\n    }\n    else\n    {\n      // Re-emit any data coming from the coalesce stream to the outside world\n      pipeline.coalesceStream.on('data', this.trigger.bind(this, 'data'));\n      // Let the consumer know we have finished flushing the entire pipeline\n      pipeline.coalesceStream.on('done', this.trigger.bind(this, 'done'));\n    }\n  };\n\n  // hook up the segment streams once track metadata is delivered\n  this.setBaseMediaDecodeTime = function (baseMediaDecodeTime) {\n    var pipeline = this.transmuxPipeline_;\n\n    this.baseMediaDecodeTime = baseMediaDecodeTime;\n    if (audioTrack) {\n      audioTrack.timelineStartInfo.dts = undefined;\n      audioTrack.timelineStartInfo.pts = undefined;\n      clearDtsInfo(audioTrack);\n      audioTrack.timelineStartInfo.baseMediaDecodeTime = baseMediaDecodeTime;\n    }\n    // XXX pavelki: to check how to act if mp4\n    if (videoTrack) {\n      if (pipeline.videoSegmentStream) {\n        pipeline.videoSegmentStream.gopCache_ = [];\n      }\n      videoTrack.timelineStartInfo.dts = undefined;\n      videoTrack.timelineStartInfo.pts = undefined;\n      clearDtsInfo(videoTrack);\n      videoTrack.timelineStartInfo.baseMediaDecodeTime = baseMediaDecodeTime;\n    }\n  };\n\n  // feed incoming data to the front of the parsing pipeline\n  this.push = function(data) {\n    if (hasFlushed) {\n      var isAac = isLikelyAacData(data) && options.input_type!='mp4';\n\n      if (isAac && this.transmuxPipeline_.type !== 'aac') {\n        this.setupAacPipeline();\n      }\n      else if (!isAac && this.transmuxPipeline_.type !== options.input_type)\n      {\n        this.setupTsPipeline();\n      }\n      hasFlushed = false;\n    }\n    return this.transmuxPipeline_.headOfPipeline.push(data);\n  };\n\n  this.appendBuffer = function(data) {\n      return this.push(new Uint8Array(data));\n  };\n\n  // flush any buffered data\n  this.flush = function() {\n    hasFlushed = true;\n    // Start at the top of the pipeline and flush all pending work\n    this.transmuxPipeline_.headOfPipeline.flush();\n  };\n};\nTransmuxer.prototype = new Stream();\n\nmodule.exports = {\n  Transmuxer: Transmuxer,\n  VideoSegmentStream: VideoSegmentStream,\n  AudioSegmentStream: AudioSegmentStream,\n  AUDIO_PROPERTIES: AUDIO_PROPERTIES,\n  VIDEO_PROPERTIES: VIDEO_PROPERTIES\n};\n",
    "'use strict';\n\nvar\n  tagTypes = {\n    0x08: 'audio',\n    0x09: 'video',\n    0x12: 'metadata'\n  },\n  hex = function (val) {\n    return '0x' + ('00' + val.toString(16)).slice(-2).toUpperCase();\n  },\n  hexStringList = function (data) {\n    var arr = [], i;\n    /* jshint -W086 */\n    while(data.byteLength > 0) {\n      i = 0;\n      switch(data.byteLength) {\n        default:\n          arr.push(hex(data[i++]));\n        case 7:\n          arr.push(hex(data[i++]));\n        case 6:\n          arr.push(hex(data[i++]));\n        case 5:\n          arr.push(hex(data[i++]));\n        case 4:\n          arr.push(hex(data[i++]));\n        case 3:\n          arr.push(hex(data[i++]));\n        case 2:\n          arr.push(hex(data[i++]));\n        case 1:\n          arr.push(hex(data[i++]));\n      }\n      data = data.subarray(i);\n    }\n    /* jshint +W086 */\n    return arr.join(' ');\n  },\n  parseAVCTag = function (tag, obj) {\n    var\n      avcPacketTypes = [\n        'AVC Sequence Header',\n        'AVC NALU',\n        'AVC End-of-Sequence'\n      ],\n      nalUnitTypes = [\n        'unspecified',\n        'slice_layer_without_partitioning',\n        'slice_data_partition_a_layer',\n        'slice_data_partition_b_layer',\n        'slice_data_partition_c_layer',\n        'slice_layer_without_partitioning_idr',\n        'sei',\n        'seq_parameter_set',\n        'pic_parameter_set',\n        'access_unit_delimiter',\n        'end_of_seq',\n        'end_of_stream',\n        'filler',\n        'seq_parameter_set_ext',\n        'prefix_nal_unit',\n        'subset_seq_parameter_set',\n        'reserved',\n        'reserved',\n        'reserved'\n      ],\n      compositionTime = (tag[1] & parseInt('01111111', 2) << 16) | (tag[2] << 8) | tag[3];\n\n    obj = obj || {};\n\n    obj.avcPacketType = avcPacketTypes[tag[0]];\n    obj.CompositionTime = (tag[1] & parseInt('10000000', 2)) ? -compositionTime : compositionTime;\n\n    if (tag[0] === 1) {\n      obj.nalUnitTypeRaw = hexStringList(tag.subarray(4, 100));\n    } else {\n      obj.data = hexStringList(tag.subarray(4));\n    }\n\n    return obj;\n  },\n  parseVideoTag = function (tag, obj) {\n    var\n      frameTypes = [\n        'Unknown',\n        'Keyframe (for AVC, a seekable frame)',\n        'Inter frame (for AVC, a nonseekable frame)',\n        'Disposable inter frame (H.263 only)',\n        'Generated keyframe (reserved for server use only)',\n        'Video info/command frame'\n      ],\n      codecIDs = [\n        'JPEG (currently unused)',\n        'Sorenson H.263',\n        'Screen video',\n        'On2 VP6',\n        'On2 VP6 with alpha channel',\n        'Screen video version 2',\n        'AVC'\n      ],\n      codecID = tag[0] & parseInt('00001111', 2);\n\n    obj = obj || {};\n\n    obj.frameType = frameTypes[(tag[0] & parseInt('11110000', 2)) >>> 4];\n    obj.codecID = codecID;\n\n    if (codecID === 7) {\n      return parseAVCTag(tag.subarray(1), obj);\n    }\n    return obj;\n  },\n  parseAACTag = function (tag, obj) {\n    var packetTypes = [\n      'AAC Sequence Header',\n      'AAC Raw'\n    ];\n\n    obj = obj || {};\n\n    obj.aacPacketType = packetTypes[tag[0]];\n    obj.data = hexStringList(tag.subarray(1));\n\n    return obj;\n  },\n  parseAudioTag = function (tag, obj) {\n    var\n      formatTable = [\n        'Linear PCM, platform endian',\n        'ADPCM',\n        'MP3',\n        'Linear PCM, little endian',\n        'Nellymoser 16-kHz mono',\n        'Nellymoser 8-kHz mono',\n        'Nellymoser',\n        'G.711 A-law logarithmic PCM',\n        'G.711 mu-law logarithmic PCM',\n        'reserved',\n        'AAC',\n        'Speex',\n        'MP3 8-Khz',\n        'Device-specific sound'\n      ],\n      samplingRateTable = [\n        '5.5-kHz',\n        '11-kHz',\n        '22-kHz',\n        '44-kHz'\n      ],\n      soundFormat = (tag[0] & parseInt('11110000', 2)) >>> 4;\n\n    obj = obj || {};\n\n    obj.soundFormat = formatTable[soundFormat];\n    obj.soundRate = samplingRateTable[(tag[0] & parseInt('00001100', 2)) >>> 2];\n    obj.soundSize = ((tag[0] & parseInt('00000010', 2)) >>> 1) ? '16-bit' : '8-bit';\n    obj.soundType = (tag[0] & parseInt('00000001', 2)) ? 'Stereo' : 'Mono';\n\n    if (soundFormat === 10) {\n      return parseAACTag(tag.subarray(1), obj);\n    }\n    return obj;\n  },\n  parseGenericTag = function (tag) {\n    return {\n      tagType: tagTypes[tag[0]],\n      dataSize: (tag[1] << 16) | (tag[2] << 8) | tag[3],\n      timestamp: (tag[7] << 24) | (tag[4] << 16) | (tag[5] << 8) | tag[6],\n      streamID: (tag[8] << 16) | (tag[9] << 8) | tag[10]\n    };\n  },\n  inspectFlvTag = function (tag) {\n    var header = parseGenericTag(tag);\n    switch (tag[0]) {\n      case 0x08:\n        parseAudioTag(tag.subarray(11), header);\n        break;\n      case 0x09:\n        parseVideoTag(tag.subarray(11), header);\n        break;\n      case 0x12:\n    }\n    return header;\n  },\n  inspectFlv = function (bytes) {\n    var i = 9, // header\n        dataSize,\n        parsedResults = [],\n        tag;\n\n    // traverse the tags\n    i += 4; // skip previous tag size\n    while (i < bytes.byteLength) {\n      dataSize = bytes[i + 1] << 16;\n      dataSize |= bytes[i + 2] << 8;\n      dataSize |= bytes[i + 3];\n      dataSize += 11;\n\n      tag = bytes.subarray(i, i + dataSize);\n      parsedResults.push(inspectFlvTag(tag));\n      i += dataSize + 4;\n    }\n    return parsedResults;\n  },\n  textifyFlv = function (flvTagArray) {\n    return JSON.stringify(flvTagArray, null, 2);\n  };\n\nmodule.exports = {\n  inspectTag: inspectFlvTag,\n  inspect: inspectFlv,\n  textify: textifyFlv\n};\n",
    "'use strict';\n\nvar\n  inspectMp4,\n  textifyMp4,\n  /**\n   * Returns the string representation of an ASCII encoded four byte buffer.\n   * @param buffer {Uint8Array} a four-byte buffer to translate\n   * @return {string} the corresponding string\n   */\n  parseType = function(buffer) {\n    var result = '';\n    result += String.fromCharCode(buffer[0]);\n    result += String.fromCharCode(buffer[1]);\n    result += String.fromCharCode(buffer[2]);\n    result += String.fromCharCode(buffer[3]);\n    return result;\n  },\n  parseMp4Date = function(seconds) {\n    return new Date(seconds * 1000 - 2082844800000);\n  },\n  parseSampleFlags = function(flags) {\n    return {\n      isLeading: (flags[0] & 0x0c) >>> 2,\n      dependsOn: flags[0] & 0x03,\n      isDependedOn: (flags[1] & 0xc0) >>> 6,\n      hasRedundancy: (flags[1] & 0x30) >>> 4,\n      paddingValue: (flags[1] & 0x0e) >>> 1,\n      isNonSyncSample: flags[1] & 0x01,\n      degradationPriority: (flags[2] << 8) | flags[3]\n    };\n  },\n  nalParse = function(avcStream) {\n    var\n      avcView = new DataView(avcStream.buffer, avcStream.byteOffset, avcStream.byteLength),\n      result = [],\n      i,\n      length;\n    for (i = 0; i + 4 < avcStream.length; i += length) {\n      length = avcView.getUint32(i);\n      i += 4;\n\n      // bail if this doesn't appear to be an H264 stream\n      if (length <= 0) {\n        result.push('<span style=\\'color:red;\\'>MALFORMED DATA</span>');\n        continue;\n      }\n\n      switch(avcStream[i] & 0x1F) {\n      case 0x01:\n        result.push('slice_layer_without_partitioning_rbsp');\n        break;\n      case 0x05:\n        result.push('slice_layer_without_partitioning_rbsp_idr');\n        break;\n      case 0x06:\n        result.push('sei_rbsp');\n        break;\n      case 0x07:\n        result.push('seq_parameter_set_rbsp');\n        break;\n      case 0x08:\n        result.push('pic_parameter_set_rbsp');\n        break;\n      case 0x09:\n        result.push('access_unit_delimiter_rbsp');\n        break;\n      default:\n        result.push('UNKNOWN NAL - ' + avcStream[i] & 0x1F);\n        break;\n      }\n    }\n    return result;\n  },\n\n  // registry of handlers for individual mp4 box types\n  parse = {\n    // codingname, not a first-class box type. stsd entries share the\n    // same format as real boxes so the parsing infrastructure can be\n    // shared\n    avc1: function(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        dataReferenceIndex: view.getUint16(6),\n        width:  view.getUint16(24),\n        height: view.getUint16(26),\n        horizresolution: view.getUint16(28) + (view.getUint16(30) / 16),\n        vertresolution: view.getUint16(32) + (view.getUint16(34) / 16),\n        frameCount: view.getUint16(40),\n        depth: view.getUint16(74),\n        config: inspectMp4(data.subarray(78, data.byteLength))\n      };\n    },\n    avcC: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          configurationVersion: data[0],\n          avcProfileIndication: data[1],\n          profileCompatibility: data[2],\n          avcLevelIndication: data[3],\n          lengthSizeMinusOne: data[4] & 0x03,\n          sps: [],\n          pps: []\n        },\n        numOfSequenceParameterSets = data[5] & 0x1f,\n        numOfPictureParameterSets,\n        nalSize,\n        offset,\n        i;\n\n      // iterate past any SPSs\n      offset = 6;\n      for (i = 0; i < numOfSequenceParameterSets; i++) {\n        nalSize = view.getUint16(offset);\n        offset += 2;\n        result.sps.push(new Uint8Array(data.subarray(offset, offset + nalSize)));\n        offset += nalSize;\n      }\n      // iterate past any PPSs\n      numOfPictureParameterSets = data[offset];\n      offset++;\n      for (i = 0; i < numOfPictureParameterSets; i++) {\n        nalSize = view.getUint16(offset);\n        offset += 2;\n        result.pps.push(new Uint8Array(data.subarray(offset, offset + nalSize)));\n        offset += nalSize;\n      }\n      return result;\n    },\n    btrt: function(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        bufferSizeDB: view.getUint32(0),\n        maxBitrate: view.getUint32(4),\n        avgBitrate: view.getUint32(8)\n      };\n    },\n    esds: function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        esId: (data[6] << 8) | data[7],\n        streamPriority: data[8] & 0x1f,\n        decoderConfig: {\n          objectProfileIndication: data[11],\n          streamType: (data[12] >>> 2) & 0x3f,\n          bufferSize: (data[13] << 16) | (data[14] << 8) | data[15],\n          maxBitrate: (data[16] << 24) |\n            (data[17] << 16) |\n            (data[18] <<  8) |\n            data[19],\n          avgBitrate: (data[20] << 24) |\n            (data[21] << 16) |\n            (data[22] <<  8) |\n            data[23],\n          decoderConfigDescriptor: {\n            tag: data[24],\n            length: data[25],\n            audioObjectType: (data[26] >>> 3) & 0x1f,\n            samplingFrequencyIndex: ((data[26] & 0x07) << 1) |\n              ((data[27] >>> 7) & 0x01),\n            channelConfiguration: (data[27] >>> 3) & 0x0f\n          }\n        }\n      };\n    },\n    ftyp: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          majorBrand: parseType(data.subarray(0, 4)),\n          minorVersion: view.getUint32(4),\n          compatibleBrands: []\n        },\n        i = 8;\n      while (i < data.byteLength) {\n        result.compatibleBrands.push(parseType(data.subarray(i, i + 4)));\n        i += 4;\n      }\n      return result;\n    },\n    dinf: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    dref: function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        dataReferences: inspectMp4(data.subarray(8))\n      };\n    },\n    hdlr: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        language,\n        result = {\n          version: view.getUint8(0),\n          flags: new Uint8Array(data.subarray(1, 4)),\n          handlerType: parseType(data.subarray(8, 12)),\n          name: ''\n        },\n        i = 8;\n\n      // parse out the name field\n      for (i = 24; i < data.byteLength; i++) {\n        if (data[i] === 0x00) {\n          // the name field is null-terminated\n          i++;\n          break;\n        }\n        result.name += String.fromCharCode(data[i]);\n      }\n      // decode UTF-8 to javascript's internal representation\n      // see http://ecmanaut.blogspot.com/2006/07/encoding-decoding-utf8-in-javascript.html\n      result.name = decodeURIComponent(global.escape(result.name));\n\n      return result;\n    },\n    mdat: function(data) {\n      return {\n        byteLength: data.byteLength,\n        nals: nalParse(data)\n      };\n    },\n    mdhd: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        i = 4,\n        language,\n        result = {\n          version: view.getUint8(0),\n          flags: new Uint8Array(data.subarray(1, 4)),\n          language: ''\n        };\n      if (result.version === 1) {\n        i += 4;\n        result.creationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n        i += 8;\n        result.modificationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n        i += 4;\n        result.timescale = view.getUint32(i);\n        i += 8;\n        result.duration = view.getUint32(i); // truncating top 4 bytes\n      } else {\n        result.creationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.modificationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.timescale = view.getUint32(i);\n        i += 4;\n        result.duration = view.getUint32(i);\n      }\n      i += 4;\n      // language is stored as an ISO-639-2/T code in an array of three 5-bit fields\n      // each field is the packed difference between its ASCII value and 0x60\n      language = view.getUint16(i);\n      result.language += String.fromCharCode((language >> 10) + 0x60);\n      result.language += String.fromCharCode(((language & 0x03c0) >> 5) + 0x60);\n      result.language += String.fromCharCode((language & 0x1f) + 0x60);\n\n      return result;\n    },\n    mdia: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    mfhd: function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        sequenceNumber: (data[4] << 24) |\n          (data[5] << 16) |\n          (data[6] << 8) |\n          (data[7])\n      };\n    },\n    minf: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    // codingname, not a first-class box type. stsd entries share the\n    // same format as real boxes so the parsing infrastructure can be\n    // shared\n    mp4a: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          // 6 bytes reserved\n          dataReferenceIndex: view.getUint16(6),\n          // 4 + 4 bytes reserved\n          channelcount: view.getUint16(16),\n          samplesize: view.getUint16(18),\n          // 2 bytes pre_defined\n          // 2 bytes reserved\n          samplerate: view.getUint16(24) + (view.getUint16(26) / 65536)\n        };\n\n      // if there are more bytes to process, assume this is an ISO/IEC\n      // 14496-14 MP4AudioSampleEntry and parse the ESDBox\n      if (data.byteLength > 28) {\n        result.streamDescriptor = inspectMp4(data.subarray(28))[0];\n      }\n      return result;\n    },\n    moof: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    moov: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    mvex: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    mvhd: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        i = 4,\n        result = {\n          version: view.getUint8(0),\n          flags: new Uint8Array(data.subarray(1, 4))\n        };\n\n      if (result.version === 1) {\n        i += 4;\n        result.creationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n        i += 8;\n        result.modificationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n        i += 4;\n        result.timescale = view.getUint32(i);\n        i += 8;\n        result.duration = view.getUint32(i); // truncating top 4 bytes\n      } else {\n        result.creationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.modificationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.timescale = view.getUint32(i);\n        i += 4;\n        result.duration = view.getUint32(i);\n      }\n      i += 4;\n\n      // convert fixed-point, base 16 back to a number\n      result.rate = view.getUint16(i) + (view.getUint16(i + 2) / 16);\n      i += 4;\n      result.volume = view.getUint8(i) + (view.getUint8(i + 1) / 8);\n      i += 2;\n      i += 2;\n      i += 2 * 4;\n      result.matrix = new Uint32Array(data.subarray(i, i + (9 * 4)));\n      i += 9 * 4;\n      i += 6 * 4;\n      result.nextTrackId = view.getUint32(i);\n      return result;\n    },\n    pdin: function(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        version: view.getUint8(0),\n        flags: new Uint8Array(data.subarray(1, 4)),\n        rate: view.getUint32(4),\n        initialDelay: view.getUint32(8)\n      };\n    },\n    sdtp: function(data) {\n      var\n        result = {\n          version: data[0],\n          flags: new Uint8Array(data.subarray(1, 4)),\n          samples: []\n        }, i;\n\n      for (i = 4; i < data.byteLength; i++) {\n        result.samples.push({\n          dependsOn: (data[i] & 0x30) >> 4,\n          isDependedOn: (data[i] & 0x0c) >> 2,\n          hasRedundancy: data[i] & 0x03\n        });\n      }\n      return result;\n    },\n    sidx: function(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          result = {\n            version: data[0],\n            flags: new Uint8Array(data.subarray(1, 4)),\n            references: [],\n            referenceId: view.getUint32(4),\n            timescale: view.getUint32(8),\n            earliestPresentationTime: view.getUint32(12),\n            firstOffset: view.getUint32(16)\n          },\n          referenceCount = view.getUint16(22),\n          i;\n\n      for (i = 24; referenceCount; i += 12, referenceCount-- ) {\n        result.references.push({\n          referenceType: (data[i] & 0x80) >>> 7,\n          referencedSize: view.getUint32(i) & 0x7FFFFFFF,\n          subsegmentDuration: view.getUint32(i + 4),\n          startsWithSap: !!(data[i + 8] & 0x80),\n          sapType: (data[i + 8] & 0x70) >>> 4,\n          sapDeltaTime: view.getUint32(i + 8) & 0x0FFFFFFF\n        });\n      }\n\n      return result;\n    },\n    smhd: function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        balance: data[4] + (data[5] / 256)\n      };\n    },\n    stbl: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    stco: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          version: data[0],\n          flags: new Uint8Array(data.subarray(1, 4)),\n          chunkOffsets: []\n        },\n        entryCount = view.getUint32(4),\n        i;\n      for (i = 8; entryCount; i += 4, entryCount--) {\n        result.chunkOffsets.push(view.getUint32(i));\n      }\n      return result;\n    },\n    stsc: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        entryCount = view.getUint32(4),\n        result = {\n          version: data[0],\n          flags: new Uint8Array(data.subarray(1, 4)),\n          sampleToChunks: []\n        },\n        i;\n      for (i = 8; entryCount; i += 12, entryCount--) {\n        result.sampleToChunks.push({\n          firstChunk: view.getUint32(i),\n          samplesPerChunk: view.getUint32(i + 4),\n          sampleDescriptionIndex: view.getUint32(i + 8)\n        });\n      }\n      return result;\n    },\n    stsd: function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        sampleDescriptions: inspectMp4(data.subarray(8))\n      };\n    },\n    stsz: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          version: data[0],\n          flags: new Uint8Array(data.subarray(1, 4)),\n          sampleSize: view.getUint32(4),\n          entries: []\n        },\n        i;\n      for (i = 12; i < data.byteLength; i += 4) {\n        result.entries.push(view.getUint32(i));\n      }\n      return result;\n    },\n    stts: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          version: data[0],\n          flags: new Uint8Array(data.subarray(1, 4)),\n          timeToSamples: []\n        },\n        entryCount = view.getUint32(4),\n        i;\n\n      for (i = 8; entryCount; i += 8, entryCount--) {\n        result.timeToSamples.push({\n          sampleCount: view.getUint32(i),\n          sampleDelta: view.getUint32(i + 4)\n        });\n      }\n      return result;\n    },\n    styp: function(data) {\n      return parse.ftyp(data);\n    },\n    tfdt: function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        baseMediaDecodeTime: data[4] << 24 | data[5] << 16 | data[6] << 8 | data[7]\n      };\n    },\n    tfhd: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          version: data[0],\n          flags: new Uint8Array(data.subarray(1, 4)),\n          trackId: view.getUint32(4)\n        },\n        baseDataOffsetPresent = result.flags[2] & 0x01,\n        sampleDescriptionIndexPresent = result.flags[2] & 0x02,\n        defaultSampleDurationPresent = result.flags[2] & 0x08,\n        defaultSampleSizePresent = result.flags[2] & 0x10,\n        defaultSampleFlagsPresent = result.flags[2] & 0x20,\n        i;\n\n      i = 8;\n      if (baseDataOffsetPresent) {\n        i += 4; // truncate top 4 bytes\n        result.baseDataOffset = view.getUint32(12);\n        i += 4;\n      }\n      if (sampleDescriptionIndexPresent) {\n        result.sampleDescriptionIndex = view.getUint32(i);\n        i += 4;\n      }\n      if (defaultSampleDurationPresent) {\n        result.defaultSampleDuration = view.getUint32(i);\n        i += 4;\n      }\n      if (defaultSampleSizePresent) {\n        result.defaultSampleSize = view.getUint32(i);\n        i += 4;\n      }\n      if (defaultSampleFlagsPresent) {\n        result.defaultSampleFlags = view.getUint32(i);\n      }\n      return result;\n    },\n    tkhd: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        i = 4,\n        result = {\n          version: view.getUint8(0),\n          flags: new Uint8Array(data.subarray(1, 4)),\n        };\n      if (result.version === 1) {\n        i += 4;\n        result.creationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n        i += 8;\n        result.modificationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n        i += 4;\n        result.trackId = view.getUint32(i);\n        i += 4;\n        i += 8;\n        result.duration = view.getUint32(i); // truncating top 4 bytes\n      } else {\n        result.creationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.modificationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.trackId = view.getUint32(i);\n        i += 4;\n        i += 4;\n        result.duration = view.getUint32(i);\n      }\n      i += 4;\n      i += 2 * 4;\n      result.layer = view.getUint16(i);\n      i += 2;\n      result.alternateGroup = view.getUint16(i);\n      i += 2;\n      // convert fixed-point, base 16 back to a number\n      result.volume = view.getUint8(i) + (view.getUint8(i + 1) / 8);\n      i += 2;\n      i += 2;\n      result.matrix = new Uint32Array(data.subarray(i, i + (9 * 4)));\n      i += 9 * 4;\n      result.width = view.getUint16(i) + (view.getUint16(i + 2) / 16);\n      i += 4;\n      result.height = view.getUint16(i) + (view.getUint16(i + 2) / 16);\n      return result;\n    },\n    traf: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    trak: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    trex: function(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        trackId: view.getUint32(4),\n        defaultSampleDescriptionIndex: view.getUint32(8),\n        defaultSampleDuration: view.getUint32(12),\n        defaultSampleSize: view.getUint32(16),\n        sampleDependsOn: data[20] & 0x03,\n        sampleIsDependedOn: (data[21] & 0xc0) >> 6,\n        sampleHasRedundancy: (data[21] & 0x30) >> 4,\n        samplePaddingValue: (data[21] & 0x0e) >> 1,\n        sampleIsDifferenceSample: !!(data[21] & 0x01),\n        sampleDegradationPriority: view.getUint16(22)\n      };\n    },\n    trun: function(data) {\n      var\n        result = {\n          version: data[0],\n          flags: new Uint8Array(data.subarray(1, 4)),\n          samples: []\n        },\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        dataOffsetPresent = result.flags[2] & 0x01,\n        firstSampleFlagsPresent = result.flags[2] & 0x04,\n        sampleDurationPresent = result.flags[1] & 0x01,\n        sampleSizePresent = result.flags[1] & 0x02,\n        sampleFlagsPresent = result.flags[1] & 0x04,\n        sampleCompositionTimeOffsetPresent = result.flags[1] & 0x08,\n        sampleCount = view.getUint32(4),\n        offset = 8,\n        sample;\n\n      if (dataOffsetPresent) {\n        result.dataOffset = view.getUint32(offset);\n        offset += 4;\n      }\n\n      if (firstSampleFlagsPresent && sampleCount) {\n        sample = {\n          flags: parseSampleFlags(data.subarray(offset, offset + 4))\n        };\n        offset += 4;\n        if (sampleDurationPresent) {\n          sample.duration = view.getUint32(offset);\n          offset += 4;\n        }\n        if (sampleSizePresent) {\n          sample.size = view.getUint32(offset);\n          offset += 4;\n        }\n        if (sampleCompositionTimeOffsetPresent) {\n          sample.compositionTimeOffset = view.getUint32(offset);\n          offset += 4;\n        }\n        result.samples.push(sample);\n        sampleCount--;\n      }\n\n      while (sampleCount--) {\n        sample = {};\n        if (sampleDurationPresent) {\n          sample.duration = view.getUint32(offset);\n          offset += 4;\n        }\n        if (sampleSizePresent) {\n          sample.size = view.getUint32(offset);\n          offset += 4;\n        }\n        if (sampleFlagsPresent) {\n          sample.flags = parseSampleFlags(data.subarray(offset, offset + 4));\n          offset += 4;\n        }\n        if (sampleCompositionTimeOffsetPresent) {\n          sample.compositionTimeOffset = view.getUint32(offset);\n          offset += 4;\n        }\n        result.samples.push(sample);\n      }\n      return result;\n    },\n    'url ': function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4))\n      };\n    },\n    vmhd: function(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        graphicsmode: view.getUint16(4),\n        opcolor: new Uint16Array([view.getUint16(6),\n                                  view.getUint16(8),\n                                  view.getUint16(10)])\n      };\n    }\n  };\n\n\n/**\n * Return a javascript array of box objects parsed from an ISO base\n * media file.\n * @param data {Uint8Array} the binary data of the media to be inspected\n * @return {array} a javascript array of potentially nested box objects\n */\ninspectMp4 = function(data) {\n  var\n    i = 0,\n    result = [],\n    view,\n    size,\n    type,\n    end,\n    box;\n\n  // Convert data from Uint8Array to ArrayBuffer, to follow Dataview API\n  var ab = new ArrayBuffer(data.length);\n  var v = new Uint8Array(ab);\n  for (var z = 0; z < data.length; ++z) {\n      v[z] = data[z];\n  }\n  view = new DataView(ab);\n\n\n  while (i < data.byteLength) {\n    // parse box data\n    size = view.getUint32(i);\n    type =  parseType(data.subarray(i + 4, i + 8));\n    end = size > 1 ? i + size : data.byteLength;\n\n    // parse type-specific data\n    box = (parse[type] || function(data) {\n      return {\n        data: data\n      };\n    })(data.subarray(i + 8, end));\n    box.size = size;\n    box.type = type;\n\n    // store this box and move to the next\n    result.push(box);\n    i = end;\n  }\n  return result;\n};\n\n/**\n * Returns a textual representation of the javascript represtentation\n * of an MP4 file. You can use it as an alternative to\n * JSON.stringify() to compare inspected MP4s.\n * @param inspectedMp4 {array} the parsed array of boxes in an MP4\n * file\n * @param depth {number} (optional) the number of ancestor boxes of\n * the elements of inspectedMp4. Assumed to be zero if unspecified.\n * @return {string} a text representation of the parsed MP4\n */\ntextifyMp4 = function(inspectedMp4, depth) {\n  var indent;\n  depth = depth || 0;\n  indent = new Array(depth * 2 + 1).join(' ');\n\n  // iterate over all the boxes\n  return inspectedMp4.map(function(box, index) {\n\n    // list the box type first at the current indentation level\n    return indent + box.type + '\\n' +\n\n      // the type is already included and handle child boxes separately\n      Object.keys(box).filter(function(key) {\n        return key !== 'type' && key !== 'boxes';\n\n      // output all the box properties\n      }).map(function(key) {\n        var prefix = indent + '  ' + key + ': ',\n            value = box[key];\n\n        // print out raw bytes as hexademical\n        if (value instanceof Uint8Array || value instanceof Uint32Array) {\n          var bytes = Array.prototype.slice.call(new Uint8Array(value.buffer, value.byteOffset, value.byteLength))\n              .map(function(byte) {\n                return ' ' + ('00' + byte.toString(16)).slice(-2);\n              }).join('').match(/.{1,24}/g);\n          if (!bytes) {\n            return prefix + '<>';\n          }\n          if (bytes.length === 1) {\n            return prefix + '<' + bytes.join('').slice(1) + '>';\n          }\n          return prefix + '<\\n' + bytes.map(function(line) {\n            return indent + '  ' + line;\n          }).join('\\n') + '\\n' + indent + '  >';\n        }\n\n        // stringify generic objects\n        return prefix +\n            JSON.stringify(value, null, 2)\n              .split('\\n').map(function(line, index) {\n                if (index === 0) {\n                  return line;\n                }\n                return indent + '  ' + line;\n              }).join('\\n');\n      }).join('\\n') +\n\n    // recursively textify the child boxes\n    (box.boxes ? '\\n' + textifyMp4(box.boxes, depth + 1) : '');\n  }).join('\\n');\n};\n\nmodule.exports = {\n  inspect: inspectMp4,\n  textify: textifyMp4\n};\n",
    "'use strict';\n\nvar ExpGolomb;\n\n/**\n * Parser for exponential Golomb codes, a variable-bitwidth number encoding\n * scheme used by h264.\n */\nExpGolomb = function(workingData) {\n  var\n    // the number of bytes left to examine in workingData\n    workingBytesAvailable = workingData.byteLength,\n\n    // the current word being examined\n    workingWord = 0, // :uint\n\n    // the number of bits left to examine in the current word\n    workingBitsAvailable = 0; // :uint;\n\n  // ():uint\n  this.length = function() {\n    return (8 * workingBytesAvailable);\n  };\n\n  // ():uint\n  this.bitsAvailable = function() {\n    return (8 * workingBytesAvailable) + workingBitsAvailable;\n  };\n\n  // ():void\n  this.loadWord = function() {\n    var\n      position = workingData.byteLength - workingBytesAvailable,\n      workingBytes = new Uint8Array(4),\n      availableBytes = Math.min(4, workingBytesAvailable);\n\n    if (availableBytes === 0) {\n      throw new Error('no bytes available');\n    }\n\n    workingBytes.set(workingData.subarray(position,\n                                          position + availableBytes));\n    workingWord = new DataView(workingBytes.buffer).getUint32(0);\n\n    // track the amount of workingData that has been processed\n    workingBitsAvailable = availableBytes * 8;\n    workingBytesAvailable -= availableBytes;\n  };\n\n  // (count:int):void\n  this.skipBits = function(count) {\n    var skipBytes; // :int\n    if (workingBitsAvailable > count) {\n      workingWord          <<= count;\n      workingBitsAvailable -= count;\n    } else {\n      count -= workingBitsAvailable;\n      skipBytes = Math.floor(count / 8);\n\n      count -= (skipBytes * 8);\n      workingBytesAvailable -= skipBytes;\n\n      this.loadWord();\n\n      workingWord <<= count;\n      workingBitsAvailable -= count;\n    }\n  };\n\n  // (size:int):uint\n  this.readBits = function(size) {\n    var\n      bits = Math.min(workingBitsAvailable, size), // :uint\n      valu = workingWord >>> (32 - bits); // :uint\n    // if size > 31, handle error\n    workingBitsAvailable -= bits;\n    if (workingBitsAvailable > 0) {\n      workingWord <<= bits;\n    } else if (workingBytesAvailable > 0) {\n      this.loadWord();\n    }\n\n    bits = size - bits;\n    return bits > 0 && workingBitsAvailable ? valu << bits | this.readBits(bits) : valu;\n  };\n\n  // ():uint\n  this.skipLeadingZeros = function() {\n    var leadingZeroCount; // :uint\n    for (leadingZeroCount = 0 ; leadingZeroCount < workingBitsAvailable ; ++leadingZeroCount) {\n      if (0 !== (workingWord & (0x80000000 >>> leadingZeroCount))) {\n        // the first bit of working word is 1\n        workingWord <<= leadingZeroCount;\n        workingBitsAvailable -= leadingZeroCount;\n        return leadingZeroCount;\n      }\n    }\n\n    // we exhausted workingWord and still have not found a 1\n    this.loadWord();\n    return leadingZeroCount + this.skipLeadingZeros();\n  };\n\n  // ():void\n  this.skipUnsignedExpGolomb = function() {\n    this.skipBits(1 + this.skipLeadingZeros());\n  };\n\n  // ():void\n  this.skipExpGolomb = function() {\n    this.skipBits(1 + this.skipLeadingZeros());\n  };\n\n  // ():uint\n  this.readUnsignedExpGolomb = function() {\n    var clz = this.skipLeadingZeros(); // :uint\n    return this.readBits(clz + 1) - 1;\n  };\n\n  // ():int\n  this.readExpGolomb = function() {\n    var valu = this.readUnsignedExpGolomb(); // :int\n    return valu & 0x01 ? (1 + valu) >>> 1 : -(valu >>> 1);\n  };\n\n  // Some convenience functions\n  // :Boolean\n  this.readBoolean = function() {\n    return 1 === this.readBits(1);\n  };\n\n  // ():int\n  this.readUnsignedByte = function() {\n    return this.readBits(8);\n  };\n\n  this.loadWord();\n};\n\nmodule.exports = ExpGolomb;\n",
    "/**\n * mux.js\n *\n * Copyright (c) 2014 Brightcove\n * All rights reserved.\n *\n * A lightweight readable stream implemention that handles event dispatching.\n * Objects that inherit from streams should call init in their constructors.\n */\n'use strict';\n\nvar Stream = function() {\n  this.init = function() {\n    var listeners = {};\n    /**\n     * Add a listener for a specified event type.\n     * @param type {string} the event name\n     * @param listener {function} the callback to be invoked when an event of\n     * the specified type occurs\n     */\n    this.on = function(type, listener) {\n      if (!listeners[type]) {\n        listeners[type] = [];\n      }\n      listeners[type].push(listener);\n    };\n    /**\n     * Remove a listener for a specified event type.\n     * @param type {string} the event name\n     * @param listener {function} a function previously registered for this\n     * type of event through `on`\n     */\n    this.off = function(type, listener) {\n      var index;\n      if (!listeners[type]) {\n        return false;\n      }\n      index = listeners[type].indexOf(listener);\n      listeners[type].splice(index, 1);\n      return index > -1;\n    };\n    /**\n     * Trigger an event of the specified type on this stream. Any additional\n     * arguments to this function are passed as parameters to event listeners.\n     * @param type {string} the event name\n     */\n    this.trigger = function(type) {\n      var callbacks, i, length, args;\n      callbacks = listeners[type];\n      if (!callbacks) {\n        return;\n      }\n      // Copy handlers so if handlers are added/removed during the process it\n      // doesn't throw everything off.\n      callbacks = callbacks.slice(0);\n      // Slicing the arguments on every invocation of this method\n      // can add a significant amount of overhead. Avoid the\n      // intermediate object creation for the common case of a\n      // single callback argument\n      if (arguments.length === 2) {\n        length = callbacks.length;\n        for (i = 0; i < length; ++i) {\n          callbacks[i].call(this, arguments[1]);\n        }\n      } else {\n        args = [];\n        i = arguments.length;\n        for (i = 1; i < arguments.length; ++i) {\n          args.push(arguments[i]);\n        }\n        length = callbacks.length;\n        for (i = 0; i < length; ++i) {\n          callbacks[i].apply(this, args);\n        }\n      }\n    };\n    /**\n     * Destroys the stream and cleans up.\n     */\n    this.dispose = function() {\n      listeners = {};\n    };\n  };\n};\n\n/**\n * Forwards all `data` events on this stream to the destination stream. The\n * destination stream should provide a method `push` to receive the data\n * events as they arrive.\n * @param destination {stream} the stream that will receive all `data` events\n * @param autoFlush {boolean} if false, we will not call `flush` on the destination\n *                            when the current stream emits a 'done' event\n * @see http://nodejs.org/api/stream.html#stream_readable_pipe_destination_options\n */\nStream.prototype.pipe = function(destination) {\n  this.on('data', function(data) {\n    destination.push(data);\n  });\n\n  this.on('done', function(flushSource) {\n    destination.flush(flushSource);\n  });\n\n  return destination;\n};\n\n// Default stream functions that are expected to be overridden to perform\n// actual work. These are provided by the prototype as a sort of no-op\n// implementation so that we don't have to check for their existence in the\n// `pipe` function above.\nStream.prototype.push = function(data) {\n  this.trigger('data', data);\n};\n\nStream.prototype.flush = function(flushSource) {\n  this.trigger('done', flushSource);\n};\n\nmodule.exports = Stream;\n",
    "module.exports = require('@hola.org/mux.js');\n"
  ]
}